\chapter{Deploying Liferay DXP}\label{deploying-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay DXP is one of the most flexible applications on the market today
with respect to database and application server support. It supports a
wide variety of databases and application servers, freeing you to use
the ones you want. Liferay DXP also scales very well. You can install it
on a shared hosting account, on a multi-node cluster running a
commercial application server, or on anything in between. In fact,
Liferay DXP is used successfully in all of these scenarios every day.

You'll find that because of Liferay DXP's flexibility in its deployment
options, it is also easy to install. If you already have an application
server, you can use your application server's deployment tools to
install Liferay DXP. If you don't already have an application server,
Liferay provides several application server bundles from which to
choose. These are pre-configured application servers with Liferay DXP
already installed on them. With a small amount of configuration, these
can be made into production-ready systems.

There are some preparations to make before installing. You must create a
database and install a supported Java Development Kit (JDK). It can also
be worthwhile to pre-configure or gather information for configuring a
data source, mail session, and more. You'll get guidance for these
preparations.

Lastly, you'll install and deploy Liferay DXP for the first time and
then set up Marketplace. You can continue configuring and tuning as you
desire.

Read on to obtain the Liferay DXP installer that's right for you.

\chapter{Obtaining Liferay DXP}\label{obtaining-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Before you begin, you should answer a few questions.

\begin{itemize}
\tightlist
\item
  Which version of Liferay DXP will you install?
\item
  Is your installation for development purposes or are you preparing to
  run in production?
\item
  Are you installing Liferay DXP in a clustered environment?
\item
  Which application server do you want Liferay DXP to run on?
\item
  Are you installing on an existing application server?
\end{itemize}

Here you'll determine the installation that's best for you and download
it.

Anyone can download Liferay DXP from
\href{https://www.liferay.com}{liferay.com}. Clicking \emph{Resources →
Community Downloads} takes you to the
\href{https://www.liferay.com/downloads-community}{Community Downloads
page}, where you can access Liferay Portal CE or a trial of the
enterprise supported Liferay DXP. The installers are available in
several different formats. The formats include a Liferay Tomcat bundle
(Liferay DXP bundled with Tomcat) as well as a Liferay DXP \texttt{.war}
(WAR) file for installing @product@ on an existing application server of
choice.

Liferay enterprise subscribers can download Liferay DXP from the
\href{https://help.liferay.com/hc}{Help Center}.

Liferay DXP runs on a wide variety of application servers (Check the
\href{https://help.liferay.com/hc/categories/360000894391-Product-Support}{Support
page} for a complete listing). Here are the ways to install Liferay DXP:

\begin{itemize}
\item
  \hyperref[liferay-tomcat-bundle]{Install a Liferay Tomcat bundle}
  (Tomcat application server with Liferay DXP pre-installed).
\item
  \hyperref[downloading-the-liferay-war-and-dependency-jars]{Install the
  Liferay WAR} (and supporting libraries) onto an existing application
  server.
\end{itemize}

Since the Liferay Tomcat bundle is the easiest way, it's described
first.

\section{Liferay Tomcat Bundle}\label{liferay-tomcat-bundle}

The Liferay Tomcat bundle includes the Tomcat application server with
Liferay DXP pre-installed. If you prefer using another application
server with Liferay DXP, you must install it manually. If you don't
currently have an application server preference, consider starting with
the Tomcat bundle. Tomcat is one of the most lightweight and
straightforward bundles to configure.

\noindent\hrulefill

\textbf{Note:} Application server bundles for proprietary application
servers such as WebLogic or WebSphere aren't available because the
licenses for these servers don't allow for redistribution. Liferay DXP's
commercial offering, however, runs just as well on these application
servers as it does on the others.

\noindent\hrulefill

Bundles are released as 7-Zip (\texttt{.7z}) and gzipped
(\texttt{.tar.gz}) compressed file archive formats.
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-product}{Installing
Liferay DXP} demonstrates installing Liferay DXP from a bundle. Follow
its instructions once you've prepared for installing Liferay DXP (see
the next article).

Liferay DXP bundles might not be appropriate for you. Here are some
reasons for installing the Liferay DXP WAR manually instead of using a
bundle.

\begin{itemize}
\item
  There is no Liferay DXP bundle for the application server you want to
  use.
\item
  You're installing Liferay DXP in a clustered environment.
\item
  You're installing to an existing application server.
\end{itemize}

Manual installation is described next.

\section{Downloading the Liferay WAR and Dependency
JARs}\label{downloading-the-liferay-war-and-dependency-jars}

Manual installation requires installing the Liferay DXP WAR and
dependency JARs onto the application server. These files are available
to download for \href{https://customer.liferay.com/downloads}{DXP} or
\href{https://www.liferay.com/downloads-community}{Portal CE}:

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file
\item
  Dependencies ZIP file
\item
  OSGi Dependencies ZIP file
\end{itemize}

After preparing for install (next), follow the Liferay DXP installation
steps for your application server. There are specific configuration and
script changes required on each application. The installation article
titles follow this format, with \emph{{[}Application Server{]}} replaced
by the application server name.

\emph{Installing Liferay DXP on {[}Application Server{]}}

\chapter{Preparing for Install}\label{preparing-for-install}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay DXP doesn't require much to deploy. You need a Java Development
Kit (JDK) and a database. Several configuration topics (e.g.,
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-a-search-engine}{search
engine integration},
\href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{document
repository configuration},
\href{/docs/7-2/deploy/-/knowledge_base/d/securing-product}{security
management},
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{clustering},
and more) can be addressed \emph{after} deploying Liferay DXP.

\noindent\hrulefill

\textbf{Note:} If you are installing Liferay DXP to multiple machines
(e.g., in a
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{cluster})
or prefer centralizing configuration in a file, using portal properties
in a
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{{[}LIFERAY\_HOME{]}/portal-ext.properties}
file} is the recommended way to configure. The install preparation
topics here and the configuration topics throughout this guide
demonstrate using applicable portal properties.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} \texttt{LIFERAY\_HOME} is the location from which Liferay
DXP launches applications, applies configurations, loads JAR files, and
generates logs. Liferay Home is customizable and can differ between
application servers. The
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home
reference} describes its folder structure.

\noindent\hrulefill

Start preparing for Liferay DXP install by installing a supported Java
Development Kit.

\section{JDK Requirements}\label{jdk-requirements}

Liferay DXP deployment requires a JDK. The
\href{https://help.liferay.com/hc/categories/360000894391-Product-Support}{Support
page} lists the supported JDKs from various vendors. You must use one of
these JDK versions:

\begin{itemize}
\tightlist
\item
  JDK 8
\item
  JDK 11
\end{itemize}

JDK 11 is backwards compatible with JDK 8 applications. Applications and
customizations developed on JDK 8 run on JDK 8 or JDK 11 runtimes. This
makes JDK 8 best for developing on 7.0.

\section{JVM Requirements}\label{jvm-requirements}

Liferay DXP requires that the application server JVM use the GMT time
zone and UTF-8 file encoding. Include these JVM arguments to set the
required values.

\begin{verbatim}
-Dfile.encoding=UTF8 -Duser.timezone=GMT
\end{verbatim}

On JDK 11, it's recommended to add this JVM argument to display
four-digit years.

\begin{verbatim}
-Djava.locale.providers=JRE,COMPAT,CLDR
\end{verbatim}

\noindent\hrulefill

\textbf{Note:} Since JDK 9, the Unicode Common Locale Data Repository
(CLDR) is the default locales provider. CLDR, however, is not providing
years in a four-digit format (see
\href{https://issues.liferay.com/browse/LPS-87191}{LPS-87191}). The
setting \texttt{java.locale.providers=JRE,COMPAT,CLDR} works around this
issue by using JDK 8's default locales provider.

\noindent\hrulefill

The recommended maximum heap size is 2GB. Setting the minimum heap size
to the maximum heap size value minimizes garbage collections.

\begin{verbatim}
-Xms2560m -Xmx2560m
\end{verbatim}

If you're using JDK 11, you may see \emph{Illegal Access} warnings like
these:

\begin{verbatim}
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.liferay.petra.reflect.ReflectionUtil (file:/Users/malei/dev/project/bundles/master-bundles/tomcat-9.0.10/lib/ext/com.liferay.petra.reflect.jar) to field java.lang.reflect.Field.modifiers
WARNING: Please consider reporting this to the maintainers of com.liferay.petra.reflect.ReflectionUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
\end{verbatim}

This is a known issue:
\href{https://issues.liferay.com/browse/LPS-87421}{LPS-87421}. As a
workaround, you can eliminate these warnings by adding these properties
after your application server JVM options:

\begin{verbatim}
 --add-opens=java.base/java.io=ALL-UNNAMED \
 --add-opens=java.base/java.lang.reflect=ALL-UNNAMED \
 --add-opens=java.base/java.lang=ALL-UNNAMED \
 --add-opens=java.base/java.net=ALL-UNNAMED \
 --add-opens=java.base/java.nio=ALL-UNNAMED \
 --add-opens=java.base/java.text=ALL-UNNAMED \
 --add-opens=java.base/java.util=ALL-UNNAMED \
 --add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
 --add-opens=java.desktop/java.awt.font=ALL-UNNAMED \
 --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED \
 --add-opens=java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
\end{verbatim}

If you're using JDK 11 on Linux or UNIX and are activating Liferay DXP
using an LCS 5.0.0 client, you may see an error like this:

\begin{verbatim}
ERROR [LCS Worker 2][BaseScheduledTask:92] java.lang.reflect.InaccessibleObjectException: Unable to make public long com.sun.management.internal.OperatingSystemImpl.getOpenFileDescriptorCount() accessible: module jdk.management does not
 "opens com.sun.management.internal" to unnamed module @1a3325e5
java.lang.reflect.InaccessibleObjectException: Unable to make public long com.sun.management.internal.OperatingSystemImpl.getOpenFileDescriptorCount() accessible: module jdk.management does not "opens com.sun.management.internal" to unnamed module @1a3325e5
at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:
at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:
at java.base/java.lang.reflect.Method.checkCanSetAccessible(Method.java:198)
at java.base/java.lang.reflect.Method.setAccessible(Method.java:192)
\end{verbatim}

To workaround this issue, add this property after your application
server JVM options:

\begin{verbatim}
 --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED
\end{verbatim}

It's time to prepare your database.

\section{Preparing a Database}\label{preparing-a-database}

The recommended way to set up your Liferay DXP database is also the
simplest. Liferay DXP takes care of just about everything. Here are the
steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a blank database encoded with the character set UTF-8. Liferay
  DXP is a multilingual application and needs UTF-8 encoding to display
  all of its supported character sets.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** If you plan to migrate from one database vendor to another,
 [configure the database to use the default query result order you expect for entities Liferay DXP lists](/docs/7-2/deploy/-/knowledge_base/d/sort-order-changed-with-a-different-database). 
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a database user for accessing this database. Grant this
  database user all rights, including the rights to create and drop
  tables, to the blank Liferay DXP database.
\end{enumerate}

Liferay DXP uses this database user's credentials to connect to the
database either \hyperref[using-the-built-in-data-source]{directly} or
\hyperref[using-a-data-source-on-your-application-server]{through its
application server}. After you've configured the database connection,
Liferay DXP creates its tables in the database automatically, complete
with indexes.

This is the recommended way to set up Liferay DXP. It enables @product@
to maintain its database automatically during upgrades or when various
Liferay DXP plugins that create database tables of their own are
installed. This method is by far the best way to set up your database.

\noindent\hrulefill

\textbf{Warning:} If you're using an Oracle database, use the
\texttt{ojdbc8.jar} driver library with at least Oracle 12.2.0.1.0 JDBC
4.2 versioning because
\href{https://issues.liferay.com/browse/LPS-79229}{data truncation
issues} have been detected reading data from CLOB columns.

\noindent\hrulefill

You can connect Liferay DXP with your database using @product@'s
built-in data source (recommended) or using a data source you create on
your app server.

\section{Using the Built-in Data
Source}\label{using-the-built-in-data-source}

You can configure the built-in data source from the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-product\#using-the-setup-wizard}{Basic
Configuration page} (available when Liferay DXP starts up the first
time) or by specifying it using portal properties.

Here's how set it using portal properties:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}
  file} if you haven't created one already.
\item
  Copy a set of \texttt{jdbc.*} properties from one of the
  \href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{JDBC
  templates} into your \texttt{portal-ext.properties} file.
\item
  Modify the \texttt{jdbc.*} property values to specify your database
  and database user credentials.
\item
  Put the \texttt{portal-ext.properties} file into your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{LIFERAY\_HOME}
  once you've established it based on your installation.
\end{enumerate}

Liferay DXP connects to the data source on startup.

As an alternative to the built-in data source, you can use your
application server's data source.

\section{Using a Data Source on Your Application
Server}\label{using-a-data-source-on-your-application-server}

Here's how to use your application server's data source:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create your data source based on the instructions in the
  \emph{Installing Liferay DXP on {[}Application Server{]}} article (for
  your application server) and your application server's documentation.
\item
  Create a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}
  file}, if you haven't created one already.
\item
  Add the \texttt{jdbc.default.jndi.name} property set to the data
  source's JNDI name. Here's an example:

\begin{verbatim}
jdbc.default.jndi.name=jdbc/LiferayPool
\end{verbatim}
\item
  Put the \texttt{portal-ext.properties} file into your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{LIFERAY\_HOME},
  once you've established your LIFERAY\_HOME based on your installation.
\end{enumerate}

Liferay DXP connects to your data source on startup.

Allowing the database user you're using to initialize the Liferay DXP
database to continue with all database rights is recommended. If you're
fine with that user having the recommended permissions, skip the next
section on limiting database access.

\section{Limiting Database Access}\label{limiting-database-access}

\noindent\hrulefill

\textbf{Warning:} The instructions below are not ideal for Liferay DXP
installations The following procedure is documented so that enterprises
with more restrictive standards can install Liferay DXP with stricter
(but sub-optimal) database settings. If it's at all possible, allow the
database user that initializes the database to continue using the
database with the same recommended permissions. The start of this
section (\hyperref[preparing-a-database]{Database Preparation})
describes the recommended procedure for initializing the Liferay DXP
database and preserving that user's permissions for maintaining the
Liferay DXP database and updating the database as plugin installations
and plugin updates require.

\noindent\hrulefill

Even though it's recommended for Liferay DXP to use the same database
user to create and maintain its database automatically, your
organizations might insist on revoking database initialization and
maintenance permissions from that user once the database is initialized.
If permissions for Select, Insert, Update and Delete operations are the
only ones you allow for that user, you must initialize and maintain the
database manually (even though it's not recommended). Here is the manual
procedure:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a new, blank, database for Liferay DXP.
\item
  Grant full rights for the Liferay DXP database user to do anything to
  the database.
\item
  Install Liferay DXP and start it so that it automatically populates
  the database.
\item
  Once the database has been populated with the Liferay DXP tables,
  remove all permissions from that user except permissions to perform
  Select, Insert, Update and Delete operations.
\end{enumerate}

There are some caveats to running Liferay DXP like this. Many plugins
create new tables when they're deployed. Additionally, you must run the
database upgrade function to upgrade Liferay DXP. If the @product@
database user doesn't have adequate rights to create/modify/drop tables
in the database, you must grant those rights to that user before you
deploy one of these plugins or start upgrading Liferay DXP. Once the
tables are created or the upgrade completes, you can remove those rights
until the next deploy or upgrade. Additionally, your own developers
might create plugins that must create their own tables. These are just
like Liferay DXP plugins that do the same thing, and they can only be
installed if Liferay DXP can create database tables. Installing these
plugins requires granting the Liferay DXP database user rights to create
tables in the database before you attempt to install the plugins.

Liferay DXP has many more configurable features; but they can wait until
\emph{after} deployment. The
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-product}{Configuring
Liferay DXP} section explains them.

Now it's time to install Liferay DXP.

\chapter{Installing Liferay DXP}\label{installing-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Now that you've
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install}{prepared
for installing Liferay DXP}, you can install and deploy it! This
involves uncompressing the archive (the 7-Zip or gzip bundle file),
possibly copying a JDBC driver to your application server, and starting
the application server. Lastly, Liferay DXP provides a setup wizard to
configure portal essentials.

\noindent\hrulefill

\textbf{Note:} Since bundles are the easiest way to complete an
installation, the installation steps here assume you're installing a
Liferay DXP bundle. If you plan to install Liferay DXP manually, please
refer to the \emph{Installing @product@ on {[}Application Server{]}}
article for the application server you're installing on.

\noindent\hrulefill

\section{Extracting a Liferay DXP
Bundle}\label{extracting-a-liferay-dxp-bundle}

Extract your Liferay DXP bundle to the appropriate location on your
server. This folder is the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
Home}}.

\section{Installing the JDBC Driver}\label{installing-the-jdbc-driver}

If you're using a supported open source database or if you're setting up
Liferay DXP to use the embedded HSQL database for demo purposes, you can
skip this step. Otherwise, copy your database's JDBC driver
\texttt{.jar} file to the folder your application server documentation
specifies. On Tomcat, for example, the driver belongs in the
\texttt{{[}Tomcat{]}/lib/ext} folder.

\section{Running Liferay DXP for the First
Time}\label{running-liferay-dxp-for-the-first-time}

Start your application server using the start script bundled with your
application server. For example, the Tomcat bundle provides the
\texttt{startup.sh} script in \texttt{\$CATALINA\_HOME/bin}.

\noindent\hrulefill

\textbf{Note:} Liferay DXP writes log files to folder
\texttt{{[}Liferay\ Home{]}/logs}.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Important:} Liferay DXP requires that the application server JVM
use the GMT time zone and UTF-8 file encoding. They're preset in your
Liferay DXP bundle.

\noindent\hrulefill

The first time Liferay DXP starts, it creates all of its database
tables. On completing startup, it launches a web browser that displays
the Basic Configuration page (the setup wizard). If for some reason your
browser doesn't load the Basic Configuration page automatically, open
your browser and navigate to your app server's address and port (for
example, http://localhost:8080).

\section{Using the Setup Wizard}\label{using-the-setup-wizard}

The Basic Configuration page provides a convenient way to configure
these things:

\begin{itemize}
\tightlist
\item
  Portal name and default locale
\item
  Administrator user
\item
  Database
\end{itemize}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/basic-configuration1.png}}
\caption{Supply the information for your portal and your portal's
default administrator user on the Basic Configuration page.}
\end{figure}

\section{Portal}\label{portal}

Supply this basic portal information:

\textbf{Portal Name:} name the installation you're powering with Liferay
DXP.

\textbf{Default Language:} choose your portal's default locale and click
the \emph{Change} button. This immediately localizes your portal
content, including the Basic Configuration page.

\textbf{Time Zone:} select your Liferay DXP instance's default time
zone.

\section{Administrator User}\label{administrator-user}

For the administrator, supply the following information:

\textbf{First Name:} the default administrator user's first name

\textbf{Last Name:} the default administrator user's last name

\textbf{Email:} the default administrator user's email address

\noindent\hrulefill

\textbf{Note:} the administrator user's email domain is used as the
Liferay DXP instance's default domain (i.e., the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Company}{\texttt{company.default.web.id}}
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{portal
property}).

\noindent\hrulefill

\section{Database}\label{database}

This section lets you connect to Liferay DXP's built-in data source.

\noindent\hrulefill

\textbf{Important:} If you haven't created a database for Liferay DXP,
create one now following
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#preparing-a-database}{database
preparation instructions} in the preceding article.

\noindent\hrulefill

HSQL is selected as the default database, but it's primarily for
demonstration or trial purposes.

Click the \emph{Change} link if you want to use Liferay DXP's built-in
data source and configure it to use the
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#preparing-a-database}{database
you created earlier}.

The database configuration section also has an \emph{Add Sample Data}
checkbox for adding sample data to your database. This data includes
Users, Sites, and Organizations for demo purposes. If you're installing
Liferay DXP on your own machine to explore features, the sample data may
be useful. If, however, you're installing Liferay DXP on a real server,
start with a clean system by leaving this checkbox unselected.

\noindent\hrulefill

\textbf{Warning:} HSQL should not be used in production Liferay DXP
instances. Configure Liferay DXP to use a different database; specify
that database via the Basic Configuration page here or using portal
properties. See
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#preparing-a-database}{Database
Preparation} for details.

\noindent\hrulefill

Once you've filled out the Basic Configuration form, click \emph{Finish
Configuration}. The setup wizard creates a
\texttt{{[}LIFERAY\_HOME{]}/portal-setup-wizard.properties} file which
stores the settings that you entered. When you begin customizing your
portal's configuration, however, use a
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}
file}. The \href{@platform-ref@/7.2-latest/propertiesdoc}{Portal
properties reference documentation} lists the default properties and
describes all the properties you can set for Liferay DXP.

\noindent\hrulefill

\textbf{Tip:} The wizard is a helpful tool, especially if you're setting
up Liferay DXP for the first time. If you're a veteran and you already
have your various properties set up, you can disable the setup wizard.
If you disable the setup wizard, you must configure everything manually
from a portal properties file (e.g.,
\texttt{{[}LIFERAY\_HOME{]}/portal-ext.properties}). To disable the
setup wizard, set \texttt{setup.wizard.enabled=false} in your portal
properties file. Note that property values in
\texttt{portal-setup-wizard.properties} (the file the setup wizards
creates in Liferay Home) override property values in
\texttt{portal-ext.properties}.

\noindent\hrulefill

On finishing basic configuration, Liferay DXP prompts you to restart
your server. When you restart your application server, Liferay DXP
initializes the database you specified.

Now that Liferay DXP is up and running, you can continue configuring it
as desired. Here are some suggestions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/configuring-mail}{Configure
  your mail session}, if you haven't already configured it.
\item
  Install the Marketplace plugin, if it isn't already installed. If your
  machine has restricted access to the public network or if you
  restricted the Liferay DXP database user's permissions after
  initializing the database (not recommended), you can still set up
  Marketplace by following the
  \href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-marketplace-and-portal-security}{Marketplace
  setup instructions}.
\item
  Read the
  \href{/docs/7-2/deploy/-/knowledge_base/d/configuring-product}{Configuring
  Liferay DXP} articles for guidance in configuring Liferay DXP's
  default time zone, locales, logging, search engine, document
  repository, and more.
\end{enumerate}

You're on your way to providing your organization with terrific
experiences on Liferay DXP.

\chapter{Installing Liferay DXP on
Tomcat}\label{installing-liferay-dxp-on-tomcat}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

7.0 bundled with Tomcat 9 is available on the
\href{https://customer.liferay.com/downloads}{Help Center} (DXP) or the
\href{https://www.liferay.com/downloads-community}{Community Downloads
page} (Portal CE). The Tomcat bundle contains JARs, scripts, and
configuration files required for deploying Liferay DXP. Copying these
files from the @product@ Tomcat bundle facilitates installing Liferay
DXP on an existing Tomcat application server.

Whether you copy bundle files (recommended) or download and create the
files, you must download these files for
\href{https://customer.liferay.com/downloads}{DXP} or
\href{https://www.liferay.com/downloads-community}{Portal CE}:

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file
\item
  Dependencies ZIP file
\item
  OSGi Dependencies ZIP file
\end{itemize}

\noindent\hrulefill

\textbf{Important:}
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install}{Prepare
for the install} before continuing.

\noindent\hrulefill

Here are the basic steps for installing Liferay DXP on Tomcat:

\begin{itemize}
\tightlist
\item
  \hyperref[installing-dependencies]{Installing dependencies to your
  application server}
\item
  \hyperref[configuring-tomcat]{Configuring your application server for
  Liferay DXP}
\item
  \hyperref[deploying-product]{Deploying the Liferay DXP WAR file to
  your application server}
\end{itemize}

\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
Home}} is Tomcat server's parent folder. \texttt{\$TOMCAT\_HOME} refers
to your Tomcat server folder. It is usually named
\texttt{tomcat-{[}version{]}} or \texttt{apache-tomcat-{[}version{]}}.

\section{Installing Dependencies}\label{installing-dependencies}

Liferay DXP depends on many JARs included by @product@ Tomcat bundle.
Some of the bundle's JARs are not strictly required but can still be
useful. If you don't have a bundle, you can download the Liferay JARs by
downloading the \emph{Dependencies} archive and the \emph{OSGi
Dependencies} archive, and you can download the third-party JARs as
described below.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create the folder \texttt{\$TOMCAT\_HOME/lib/ext} if it doesn't exist
  and extract the JARs from the dependencies ZIP to it.
\item
  Copy the following JARs from a Liferay DXP Tomcat bundle (or download
  them) to the \texttt{\$TOMCAT\_HOME/lib/ext} folder:

  \begin{itemize}
  \tightlist
  \item
    \href{http://www.oracle.com/technetwork/java/javase/jaf-136260.html}{\texttt{activation.jar}}
  \item
    \href{http://mvnrepository.com/artifact/javax.ccpp/ccpp/1.0}{\texttt{ccpp.jar}}
  \item
    \href{http://www.oracle.com/technetwork/java/docs-136352.html}{\texttt{jms.jar}}
  \item
    \href{http://www.oracle.com/technetwork/java/javaee/jta/index.html}{\texttt{jta.jar}}
  \item
    \href{http://mvnrepository.com/artifact/com.beetstra.jutf7/jutf7}{\texttt{jutf7.jar}}
  \item
    \href{http://www.oracle.com/technetwork/java/index-138643.html}{\texttt{mail.jar}}
  \item
    \href{http://mvnrepository.com/artifact/org.eclipse.persistence/javax.persistence/2.1.1}{\texttt{persistence.jar}}
  \item
    \href{http://mvnrepository.com/artifact/com.liferay.portal/com.liferay.support.tomcat}{\texttt{support-tomcat.jar}}
  \end{itemize}
\item
  Copy the JDBC driver for your database to the
  \texttt{\$CATALINA\_BASE/lib/ext} folder.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** The [Liferay DXP Compatibility Matrix](https://web.liferay.com/documents/14/21598941/Liferay+DXP+7.2+Compatibility+Matrix/b6e0f064-db31-49b4-8317-a29d1d76abf7?) specifies supported databases and environments.
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create an \texttt{osgi} folder in your Liferay Home. Extract the
  folders (i.e., \texttt{configs}, \texttt{core}, and more) from OSGi
  ZIP file to the \texttt{osgi} folder. The \texttt{osgi} folder
  provides the necessary modules for Liferay DXP's OSGi runtime.
\end{enumerate}

\section{Configuring Tomcat}\label{configuring-tomcat}

Configuring Tomcat to run Liferay DXP includes

\begin{itemize}
\tightlist
\item
  Setting environment variables
\item
  Specifying a web application context for Liferay DXP
\item
  Setting properties and descriptors
\end{itemize}

Optionally, if you're not using Liferay DXP's built-in data source or
mail session, you can configure Tomcat to manage them:

\begin{itemize}
\tightlist
\item
  \hyperref[database-configuration]{Data source}
\item
  \hyperref[mail-configuration]{Mail session}
\end{itemize}

Start with configuring Tomcat to run Liferay DXP.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If you have a Liferay DXP Tomcat bundle, copy the \texttt{setenv.bat},
  \texttt{setenv.sh}, \texttt{startup.bat}, \texttt{startup.sh},
  \texttt{shutdown.bat}, and \texttt{shutdown.sh} files from it to your
  \texttt{\$CATALINA\_BASE/bin} folder. If not, create the
  \texttt{setenv.bat} and \texttt{setenv.sh}scripts.

  The scripts set JVM options for Catalina, which is Tomcat's servlet
  container. Among these options is the location of the Java runtime
  environment. If this environment is not available on your server
  globally, you must set its location in in these files so Tomcat can
  run. Do this by pointing the \texttt{JAVA\_HOME} environment variable
  to a Liferay DXP-supported JRE:

\begin{verbatim}
export JAVA_HOME=/usr/lib/jvm/java-8-jdk
export PATH=$JAVA_HOME/bin:$PATH
\end{verbatim}

  Then configure Catalina's JVM options to support Liferay DXP.

  Unix:

\begin{verbatim}
CATALINA_OPTS="$CATALINA_OPTS -Dfile.encoding=UTF-8 -Djava.net.preferIPv4Stack=true -Dorg.apache.catalina.loader.WebappClassLoader.ENABLE_CLEAR_REFERENCES=false -Duser.timezone=GMT -Xms2560m -Xmx2560m -XX:MaxMetaspaceSize=512m"
\end{verbatim}

  Windows:

\begin{verbatim}
set "CATALINA_OPTS=%CATALINA_OPTS% -Dfile.encoding=UTF-8 -Djava.net.preferIPv4Stack=true -Dorg.apache.catalina.loader.WebappClassLoader.ENABLE_CLEAR_REFERENCES=false -Duser.timezone=GMT -Xms2560m -Xmx2560m -XX:MaxMetaspaceSize=512m"
\end{verbatim}

  This sets the file encoding to UTF-8, prefers an IPv4 stack over IPv6,
  prevents Tomcat from working around garbage collection bugs relating
  to static or final fields (these bugs don't exist in Liferay DXP and
  working around them causes problems with the logging system), sets the
  time zone to GMT, gives the JVM 2GB of RAM, and limits Metaspace to
  512MB.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Important:** Liferay DXP requires that the application server JVM use the
 GMT time zone and UTF-8 file encoding.
\end{verbatim}

\noindent\hrulefill

\noindent\hrulefill

\begin{verbatim}
 **Note:** On JDK 11, it's recommended to add this JVM argument to display
 four-digit years.

 ```properties
 -Djava.locale.providers=JRE,COMPAT,CLDR
 ```
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
After installation, tune your system (including these JVM options) for
performance.
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  If you have a Liferay DXP Tomcat bundle, copy its
  \texttt{\$CATALINA\_BASE/conf/Catalina/localhost/ROOT.xml} file to the
  corresponding location in your application server. Create the file
  path if it doesn't exist. If you don't have a Liferay DXP Tomcat
  bundle, create a \texttt{ROOT.xml} file.

  The \texttt{ROOT.xml} file specifies a web application context for
  Liferay DXP. \texttt{ROOT.xml} looks like this:

\begin{verbatim}
<Context crossContext="true" path="">

    <!-- JAAS -->

    <!--<Realm
        className="org.apache.catalina.realm.JAASRealm"
        appName="PortalRealm"
        userClassNames="com.liferay.portal.kernel.security.jaas.PortalPrincipal"
        roleClassNames="com.liferay.portal.kernel.security.jaas.PortalRole"
    />-->

    <!--
    Uncomment the following to disable persistent sessions across reboots.
    -->

    <!--<Manager pathname="" />-->

    <!--
    Uncomment the following to not use sessions. See the property
    "session.disabled" in portal.properties.
    -->

    <!--<Manager className="com.liferay.support.tomcat.session.SessionLessManagerBase" />-->

    <Resources>
        <PreResources
            base="${catalina.base}/lib/ext/portal"
            className="com.liferay.support.tomcat.webresources.ExtResourceSet"
            webAppMount="/WEB-INF/lib"
        />
    </Resources>
</Context>
\end{verbatim}

  Setting \texttt{crossContext="true"} lets multiple web applications
  use the same class loader. This configuration includes commented
  instructions and tags for configuring a JAAS realm, disabling
  persistent sessions, and disabling sessions entirely.
\item
  Provide Catalina access to the JARs in
  \texttt{\$CATALINA\_BASE/lib/ext} by opening your
  \texttt{\$CATALINA\_BASE/conf/catalina.properties} file and appending
  this value to the \texttt{common.loader} property:

\begin{verbatim}
,"${catalina.home}/lib/ext/global","${catalina.home}/lib/ext/global/*.jar","${catalina.home}/lib/ext","${catalina.home}/lib/ext/*.jar"
\end{verbatim}
\item
  Make sure to use UTF-8 URI encoding consistently. If you have a
  Liferay DXP Tomcat bundle, copy the
  \texttt{\$CATALINA\_BASE/conf/server.xml} file to your server. If not,
  open your \texttt{\$CATALINA\_BASE/conf/server.xml} file and add the
  attribute \texttt{URIEncoding="UTF-8"} to HTTP and AJP connectors that
  use \texttt{redirectPort=8443}. Here are examples:

  Old:

\begin{verbatim}
<Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" />
\end{verbatim}

  New:

\begin{verbatim}
<Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" URIEncoding="UTF-8" />
\end{verbatim}

  Old:

\begin{verbatim}
<Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />
\end{verbatim}

  New:

\begin{verbatim}
<Connector port="8009" protocol="AJP/1.3" redirectPort="8443" URIEncoding="UTF-8" />
\end{verbatim}
\item
  Refrain from writing access logs (optional) by commenting out the
  access log \texttt{Valve} element in
  \texttt{\$CATALINA\_BASE/conf/server.xml}. It's commented out here:

\begin{verbatim}
<!-- <Valve className="org.apache.catalina.valves.AccessLogValve"
       directory="logs"
       prefix="localhost_access_log" suffix=".txt"
       pattern="%h %l %u %t &quot;%r&quot; %s %b" /> -->
\end{verbatim}
\item
  Optionally, set the following log levels in your
  \texttt{\$CATALINA\_HOME/conf/logging.properties} file:

\begin{verbatim}
org.apache.catalina.startup.Catalina.level=INFO
org.apache.catalina.startup.ClassLoaderFactory.level=SEVERE
org.apache.catalina.startup.VersionLoggerListener.level=WARNING
org.apache.level=WARNING
\end{verbatim}
\item
  In \texttt{\$CATALINA\_HOME/conf/web.xml}, set the JSP compiler to
  Java 8 and set Liferay DXP's \texttt{TagHandlerPool} class to manage
  the JSP tag pool. Do this by adding the following elements above the
  \texttt{jsp} servlet element's
  \texttt{\textless{}load-on-startup\textgreater{}} element.

\begin{verbatim}
<init-param>
    <param-name>compilerSourceVM</param-name>
    <param-value>1.8</param-value>
</init-param>
<init-param>
    <param-name>compilerTargetVM</param-name>
    <param-value>1.8</param-value>
</init-param>
<init-param>
    <param-name>tagpoolClassName</param-name>
    <param-value>com.liferay.support.tomcat.jasper.runtime.TagHandlerPool</param-value>
</init-param>
\end{verbatim}
\item
  In \texttt{\$CATALINA\_HOME/conf/web.xml}, specify whether the
  application server should look for extra metadata, such as annotations
  in the application's JARs and classes. Setting \texttt{web-app}
  element's attribute \texttt{metadata-complete="true"} tells the
  application server there's no extra metadata. The application server
  starts up faster this way. The default is to check for extra metadata.
\item
  If you're on Unix, Linux, or Mac OS, make the shell scripts in your
  \texttt{\$CATALINA\_HOME/bin} and \texttt{\$CATALINA\_BASE/bin}
  folders executable by running this command in each folder:

\begin{verbatim}
chmod a+x *.sh
\end{verbatim}
\end{enumerate}

\textbf{Checkpoint:}

Your application server is configured to run Liferay DXP.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The file encoding, user time-zone, and preferred protocol stack are
  set in your \texttt{setenv.sh}.
\item
  The default memory available and Metaspace limit are set.
\item
  \texttt{\$CATALINA\_BASE/conf/Catalina/localhost/ROOT.xml} declares
  the web application context.
\item
  The \texttt{common.loader} property in
  \texttt{\$CATALINA\_BASE/conf/catalina.properties} grants Catalina
  access to the JARs in \texttt{\$CATALINA\_BASE/lib/ext}.
\item
  \texttt{\$CATALINA\_BASE/conf/server.xml} sets UTF-8 encoding.
\item
  \texttt{\$CATALINA\_BASE/conf/server.xml} doesn't declare any valve
  for writing host access logs. (optional)
\item
  \texttt{\$CATALINA\_HOME/conf/logging.properties} sets the desired log
  levels.
\item
  \texttt{\$CATALINA\_HOME/conf/web.xml} sets the tag handler pool and
  sets Java 8 as the JSP compiler.
\item
  \texttt{\$CATALINA\_HOME/conf/web.xml} specifies for the application
  server to refrain from looking for extra metadata. (optional)
\item
  The scripts in Tomcat's \texttt{bin} folders are executable.
\end{enumerate}

\section{Database Configuration}\label{database-configuration}

The easiest way to handle your database configuration is to let Liferay
DXP manage your data source. If you want to use the
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#using-the-built-in-data-source}{built-in
data source (recommended)}, skip this section.

If you want Tomcat to manage your data source, follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Make sure your database server is installed and working. If it's
  installed on a different machine, make sure your Liferay DXP machine
  can access it.
\item
  Open \texttt{\$CATALINA\_BASE/conf/Catalina/localhost/ROOT.xml} and
  add your data source as a \texttt{Resource} in your web application
  \texttt{Context}:

\begin{verbatim}
<Context...>
    ...
    <Resource
        name="jdbc/LiferayPool"
        auth="Container"
        type="javax.sql.DataSource"
        driverClassName="[place the database driver class here]"
        url="[place the URL to your database here]"
        username="[place your user name here]"
        password="[place your password here]"
        maxTotal="100"
        maxIdle="30"
        maxWaitMillis="10000"
    />
</Context>
\end{verbatim}
\end{enumerate}

Make sure to replace the database URL, user name, and password with the
appropriate values. For example JDBC connection values, please see
\href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
Templates}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  In a \texttt{portal-ext.properties} file in your Liferay Home, specify
  your data source:

\begin{verbatim}
jdbc.default.jndi.name=jdbc/LiferayPool
\end{verbatim}
\end{enumerate}

You created a data source for Tomcat to manage and configured Liferay
DXP to use it. Mail session configuration is next.

\section{Mail Configuration}\label{mail-configuration}

As with database configuration, the easiest way to configure mail is to
let Liferay DXP handle your mail session. If you want to use @product@'s
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-mail}{built-in
mail session}, skip this section.

If you want to manage your mail session with Tomcat, follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open \texttt{\$CATALINA\_BASE/conf/Catalina/localhost/ROOT.xml} and
  add your mail session as a \texttt{Resource} in your web application
  \texttt{Context}. Make sure to replace the example mail session values
  with your own.

\begin{verbatim}
<Context...>
    ...
    <Resource
        name="mail/MailSession"
        auth="Container"
        type="javax.mail.Session"
        mail.pop3.host="pop.gmail.com"
        mail.pop3.port="110"
        mail.smtp.host="smtp.gmail.com"
        mail.smtp.port="465"
        mail.smtp.user="user"
        mail.smtp.password="password"
        mail.smtp.auth="true"
        mail.smtp.starttls.enable="true"
        mail.smtp.socketFactory.class="javax.net.ssl.SSLSocketFactory"
        mail.imap.host="imap.gmail.com"
        mail.imap.port="993"
        mail.transport.protocol="smtp"
        mail.store.protocol="imap"
    />
</Context>
\end{verbatim}
\item
  In your \texttt{portal-ext.properties} file in Liferay Home, reference
  your mail session:

\begin{verbatim}
mail.session.jndi.name=mail/MailSession
\end{verbatim}
\end{enumerate}

You've created a mail session for Tomcat to manage and configured
Liferay DXP to use it.

\section{Deploying Liferay DXP}\label{deploying-liferay-dxp-1}

Now you're ready to deploy Liferay DXP using the @product@ WAR file.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If you are manually installing Liferay DXP on a clean Tomcat server,
  delete the contents of the \texttt{\$CATALINA\_BASE/webapps/ROOT}
  folder. This removes the default Tomcat home page.
\item
  Extract the Liferay DXP \texttt{.war} file contents to
  \texttt{\$CATALINA\_BASE/webapps/ROOT}.

  It's time to launch Liferay DXP on Tomcat!
\item
  Start Tomcat by navigating to \texttt{\$CATALINA\_HOME/bin} and
  executing \texttt{./startup.sh}. Alternatively, execute
  \texttt{./catalina.sh\ run} to tail Liferay DXP's log file. The log
  audits startup activities and is useful for debugging deployment.
\end{enumerate}

Congratulations on successfully installing and deploying Liferay DXP on
Tomcat!

\chapter{Installing Liferay DXP on
Wildfly}\label{installing-liferay-dxp-on-wildfly}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Installing Liferay DXP on Wildfly 11 takes three steps:

\begin{itemize}
\tightlist
\item
  \hyperref[installing-dependencies]{Installing dependencies to your
  application server}
\item
  \hyperref[configuring-wildfly]{Configuring your application server for
  Liferay DXP}
\item
  \hyperref[deploying-product]{Deploying the Liferay DXP WAR file to
  your application server}
\end{itemize}

\noindent\hrulefill

\textbf{Important:} Before installing Liferay DXP, familiarize yourself
with
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install}{preparing
for install}.

\noindent\hrulefill

Now,
\href{/docs/7-2/deploy/-/knowledge_base/d/obtaining-product\#downloading-the-liferay-war-and-dependency-jars}{download
the Liferay DXP WAR and Dependency JARs}:

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file
\item
  Dependencies ZIP file
\item
  OSGi Dependencies ZIP file
\end{itemize}

Note that
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
Home}} is the folder containing your Wildfly server folder. After
installing and deploying Liferay DXP, the Liferay Home folder contains
the Wildfly server folder as well as \texttt{data}, \texttt{deploy},
\texttt{logs}, and \texttt{osgi} folders. \texttt{\$WILDFLY\_HOME}
refers to your Wildfly server folder. It is usually named
\texttt{wildfly-{[}version{]}}.

\section{Installing Dependencies}\label{installing-dependencies-1}

Liferay DXP depends on a driver for your database and the JARs in the
Dependencies ZIP and OSGi Dependencies ZIP files you downloaded. Here's
how to install them:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create the folder
  \texttt{\$WILDFLY\_HOME/modules/com/liferay/portal/main} if it doesn't
  exist and extract the Dependencies ZIP JARs to it.
\item
  Download your database driver \texttt{.jar} file and copy it into the
  same folder.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** The [Liferay DXP Compatibility Matrix](https://web.liferay.com/documents/14/21598941/Liferay+DXP+7.2+Compatibility+Matrix/b6e0f064-db31-49b4-8317-a29d1d76abf7?) specifies supported databases and environments.
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  Create the file \texttt{module.xml} in the
  \texttt{\$WILDFLY\_HOME/modules/com/liferay/portal/main} folder and
  insert this configuration:

\begin{verbatim}
<?xml version="1.0"?>

<module xmlns="urn:jboss:module:1.0" name="com.liferay.portal">
    <resources>
        <resource-root path="com.liferay.petra.concurrent.jar" />
        <resource-root path="com.liferay.petra.executor.jar" />
        <resource-root path="com.liferay.petra.function.jar" />
        <resource-root path="com.liferay.petra.io.jar" />
        <resource-root path="com.liferay.petra.lang.jar" />
        <resource-root path="com.liferay.petra.memory.jar" />
        <resource-root path="com.liferay.petra.nio.jar" />
        <resource-root path="com.liferay.petra.process.jar" />
        <resource-root path="com.liferay.petra.reflect.jar" />
        <resource-root path="com.liferay.petra.string.jar" />
        <resource-root path="com.liferay.registry.api.jar" />
        <resource-root path="hsql.jar" />
        <resource-root path="[place your database vendor's jar here]" />
        <resource-root path="portal-kernel.jar" />
        <resource-root path="portlet.jar" />
    </resources>
    <dependencies>
        <module name="javax.api" />
        <module name="javax.mail.api" />
        <module name="javax.servlet.api" />
        <module name="javax.servlet.jsp.api" />
        <module name="javax.transaction.api" />
    </dependencies>
</module>
\end{verbatim}

  Replace
  \texttt{{[}place\ your\ database\ vendor\textquotesingle{}s\ jar\ here{]}}
  with the driver JAR for your database.
\item
  Create an \texttt{osgi} folder in your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder. Extract the OSGi Dependencies ZIP file that you downloaded
  into the \texttt{{[}Liferay\ Home{]}/osgi} folder.

  The \texttt{osgi} folder provides the necessary modules for Liferay
  DXP's OSGi runtime.
\end{enumerate}

\section{Running Liferay DXP on Wildfly in Standalone Mode vs.~Domain
Mode}\label{running-liferay-dxp-on-wildfly-in-standalone-mode-vs.-domain-mode}

Wildfly can be launched in either \emph{standalone} mode or
\emph{domain} mode. Domain mode allows multiple application server
instances to be managed from a single control point. A collection of
such application servers is known as a \emph{domain}. For more
information on standalone mode vs.~domain mode, please refer to the
section on this topic in the
\href{https://docs.jboss.org/author/display/WFLY/Admin+Guide\#AdminGuide-Operatingmodes}{Wildfly
Admin Guide}. Liferay DXP fully supports Wildfly in standalone mode but
not in domain mode.

You can run Liferay DXP on Wildfly in domain mode, but this method is
not fully supported. In particular, Liferay DXP's hot-deploy does not
work with a managed deployment, since Wildfly manages the content of a
managed deployment by copying files (exploded or non-exploded). This
prevents JSP hooks and Ext plugins from working as intended. For
example, JSP hooks don't work on Wildfly running in managed domain mode,
since Liferay DXP's JSP override mechanism relies on the application
server. Since JSP hooks and Ext plugins are deprecated, however, you may
not be using them.

The command line interface is recommended for domain mode deployments.

\noindent\hrulefill

\textbf{Note:} This does not prevent Liferay DXP from running in a
clustered environment on multiple Wildfly servers. You can set up a
cluster of Liferay DXP instances running on Wildfly servers running in
standalone mode. Please refer to the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{Liferay
DXP clustering articles} for more information.

\noindent\hrulefill

\section{Configuring Wildfly}\label{configuring-wildfly}

Configuring Wildfly to run Liferay DXP includes these things:

\begin{itemize}
\tightlist
\item
  Setting environment variables
\item
  Setting properties and descriptors
\item
  Removing unnecessary configurations
\end{itemize}

Optionally, you can configure Wildfly to manage Liferay DXP's data
source and mail session.

Start with configuring Wildfly to run Liferay DXP.

Make the following modifications to
\texttt{\$WILDFLY\_HOME/standalone/configuration/standalone.xml}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Locate the closing \texttt{\textless{}/extensions\textgreater{}} tag.
  Directly beneath that tag, insert the following system properties:

\begin{verbatim}
<system-properties>
    <property name="org.apache.catalina.connector.URI_ENCODING" value="UTF-8" />
    <property name="org.apache.catalina.connector.USE_BODY_ENCODING_FOR_QUERY_STRING" value="true" />
</system-properties>
\end{verbatim}
\item
  Add the following \texttt{\textless{}filter-spec\textgreater{}} tag
  within the \texttt{\textless{}console-handler\textgreater{}} tag,
  directly below the
  \texttt{\textless{}level\ name="INFO"/\textgreater{}} tag:

\begin{verbatim}
<filter-spec value="not(any(match(&quot;WFLYSRV0059&quot;),match(&quot;WFLYEE0007&quot;)))" />
\end{verbatim}
\item
  Add a timeout for the deployment scanner by setting
  \texttt{deployment-timeout="600"} as seen in the excerpt below.

\begin{verbatim}
<subsystem xmlns="urn:jboss:domain:deployment-scanner:2.0">
    <deployment-scanner deployment-timeout="600" path="deployments" relative-to="jboss.server.base.dir" scan-interval="5000" runtime-failure-causes-rollback="${jboss.deployment.scanner.rollback.on.failure:false}"/>
</subsystem>
\end{verbatim}
\item
  Add the following JAAS security domain to the security subsystem
  \texttt{\textless{}security-domains\textgreater{}} defined in element
  \texttt{\textless{}subsystem\ xmlns="urn:jboss:domain:security:2.0"\textgreater{}}.

\begin{verbatim}
<security-domain name="PortalRealm">
    <authentication>
        <login-module code="com.liferay.portal.security.jaas.PortalLoginModule" flag="required" />
    </authentication>
</security-domain>
\end{verbatim}
\item
  Remove the welcome content code snippets:

\begin{verbatim}
<location name="/" handler="welcome-content"/>
\end{verbatim}

  and

\begin{verbatim}
<handlers>
    <file name="welcome-content" path="${jboss.home.dir}/welcome-content"/>
</handlers>
\end{verbatim}
\item
  Find the \texttt{\textless{}jsp-config/\textgreater{}} tag and set the
  \texttt{development}, \texttt{source-vm}, and \texttt{target-vm}
  attributes in the tag. Once finished, the tag should look like this:

\begin{verbatim}
<jsp-config development="true" source-vm="1.8" target-vm="1.8" />
\end{verbatim}
\end{enumerate}

\textbf{Checkpoint:}

Before continuing, verify the following properties have been set in the
\texttt{standalone.xml} file:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The new \texttt{\textless{}system-property\textgreater{}} is added.
\item
  The new \texttt{\textless{}filter-spec\textgreater{}} is added.
\item
  The \texttt{\textless{}deployment-timeout\textgreater{}} is set to
  \texttt{600}.
\item
  The new \texttt{\textless{}security-domain\textgreater{}} is created.
\item
  Welcome content is removed.
\item
  The \texttt{\textless{}jsp-config\textgreater{}} tag contains its new
  attributes.
\end{enumerate}

Now you must configure your JVM and startup scripts.

In the \texttt{\$WILDFLY\_HOME/bin/} folder, modify your standalone
domain's configuration script file \texttt{standalone.conf}
(\texttt{standalone.conf.bat} on Windows):

\begin{itemize}
\tightlist
\item
  Set the file encoding to \texttt{UTF-8}
\item
  Set the user time zone to \texttt{GMT}
\item
  Set the preferred protocol stack
\item
  Increase the default amount of memory available.
\end{itemize}

\noindent\hrulefill

\textbf{Important:} For Liferay DXP to work properly, the application
server JVM must use the \texttt{GMT} time zone and \texttt{UTF-8} file
encoding.

\noindent\hrulefill

Make the following edits as applicable for your operating system:

\textbf{Windows:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Comment out the initial \texttt{JAVA\_OPTS} assignment like this:

\begin{verbatim}
rem set "JAVA_OPTS=-Xms64M -Xmx512M -XX:MetaspaceSize=96M -XX:MaxMetaspaceSize=2560m"
\end{verbatim}
\item
  Add the following \texttt{JAVA\_OPTS} assignment one line above the
  \texttt{:JAVA\_OPTS\_SET} line found at end of the file:

\begin{verbatim}
set "JAVA_OPTS=%JAVA_OPTS% -Dfile.encoding=UTF-8 -Djava.net.preferIPv4Stack=true -Djboss.as.management.blocking.timeout=480 -Duser.timezone=GMT -Xms2560m -Xmx2560m -XX:MaxMetaspaceSize=512m -XX:MetaspaceSize=200m"
\end{verbatim}
\end{enumerate}

\textbf{Unix:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Below the \texttt{if\ {[}\ "x\$JAVA\_OPTS"\ =\ "x"\ {]};} statement,
  replace this \texttt{JAVA\_OPTS} statement:

\begin{verbatim}
JAVA_OPTS="-Xms64m -Xmx512m -XX:MetaspaceSize=96M -XX:MaxMetaspaceSize=256m -Djava.net.preferIPv4Stack=true"
\end{verbatim}

  with this:

\begin{verbatim}
JAVA_OPTS="-Djava.net.preferIPv4Stack=true"
\end{verbatim}
\item
  Add the following statement to the bottom of the file:

\begin{verbatim}
JAVA_OPTS="$JAVA_OPTS -Dfile.encoding=UTF-8 -Djava.net.preferIPv4Stack=true -Djboss.as.management.blocking.timeout=480 -Duser.timezone=GMT -Xms2560m -Xmx2560m -XX:MaxMetaspaceSize=512m -XX:MetaspaceSize=200m"
\end{verbatim}
\end{enumerate}

This sets the file encoding to UTF-8, prefers an IPv4 stack over IPv6,
sets the time zone to GMT, gives the JVM 2GB of RAM, and limits
Metaspace to 512MB.

On JDK 11, it's recommended to add this JVM argument to display
four-digit years.

\begin{verbatim}
-Djava.locale.providers=JRE,COMPAT,CLDR
\end{verbatim}

After installation, tune your system (including these JVM options) for
performance.

\noindent\hrulefill

\textbf{Important:} For Liferay DXP to work properly, the application
server JVM must use the \texttt{GMT} time zone and \texttt{UTF-8} file
encoding.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} If you plan on using the IBM JDK with your Wildfly
server, you must complete some additional steps. First, navigate to the
\texttt{\$WILDFLY\_HOME/modules/com/liferay/portal/main/module.xml} file
and insert the following dependency within the
\texttt{\textless{}dependencies\textgreater{}} element:

\begin{verbatim}
 <module name="ibm.jdk" />
\end{verbatim}

Then navigate to the
\texttt{\$WILDFLY\_HOME/modules/system/layers/base/sun/jdk/main/module.xml}
file and insert the following path names inside the
\texttt{\textless{}paths\textgreater{}...\textless{}/paths\textgreater{}}
element:

\begin{verbatim}
 <path name="com/sun/crypto" />
 <path name="com/sun/crypto/provider" />
 <path name="com/sun/org/apache/xml/internal/resolver" />
 <path name="com/sun/org/apache/xml/internal/resolver/tools" />
\end{verbatim}

The added paths resolve issues with deployment exceptions and image
uploading problems.

\noindent\hrulefill

\textbf{Checkpoint:}

You've configured the application server's JVM settings.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The file encoding, user time-zone, preferred protocol stack have been
  set in the \texttt{JAVA\_OPTS} in the \texttt{standalone.conf.bat}
  file.
\item
  The default amount of memory available has been increased.
\end{enumerate}

The prescribed script modifications are now complete for your Liferay
DXP installation on Wildfly. Next you'll configure your database.

\section{Database Configuration}\label{database-configuration-1}

The easiest way to handle database configuration is to let Liferay DXP
manage your data source. The
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#using-the-built-in-data-source}{Basic
Configuration} page lets you configure Liferay DXP's built-in data
source. If you want to use the built-in data source, skip this section.

If using WildFly to manage the data source, follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add the data source inside the
  \texttt{\$WILDFLY\_HOME/standalone/configuration/standalone.xml}
  file's \texttt{\textless{}datasources\textgreater{}} element:

\begin{verbatim}
<datasource jndi-name="java:jboss/datasources/ExampleDS" pool-name="ExampleDS" enabled="true" jta="true" use-java-context="true" use-ccm="true">
    <connection-url>[place the URL to your database here]</connection-url>
    <driver>[place your driver name here]</driver>
    <security>
        <user-name>[place your user name here]</user-name>
        <password>[place your password here]</password>
    </security>
</datasource>
\end{verbatim}

  Make sure to replace the database URL, user name, and password with
  the appropriate values. For example JDBC connection values, please see
  \href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
  Templates}
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** If the data source `jndi-name` must be changed, edit the `datasource` element in the `<default-bindings>` tag.
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add the driver to the \texttt{standalone.xml} file's
  \texttt{\textless{}drivers\textgreater{}} element also found within
  the \texttt{\textless{}datasources\textgreater{}} element.

\begin{verbatim}
<drivers>
    <driver name="[name of database driver]" module="com.liferay.portal">
        <driver-class>[JDBC driver class]</driver-class>
    </driver>
</drivers>
\end{verbatim}

  A final data sources subsystem that uses MySQL should look like this:

\begin{verbatim}
<subsystem xmlns="urn:jboss:domain:datasources:1.0">
    <datasources>
        <datasource jndi-name="java:jboss/datasources/ExampleDS" pool-name="ExampleDS" enabled="true" jta="true" use-java-context="true" use-ccm="true">
            <connection-url>jdbc:mysql://localhost/lportal</connection-url>
            <driver>mysql</driver>
            <security>
                <user-name>root</user-name>
                <password>root</password>
            </security>
        </datasource>
        <drivers>
            <driver name="mysql" module="com.liferay.portal">
                <driver-class>com.mysql.cj.jdbc.Driver</driver-class>
            </driver>
        </drivers>
    </datasources>
</subsystem>
\end{verbatim}
\item
  In a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
  file in your Liferay Home, specify your data source:

\begin{verbatim}
jdbc.default.jndi.name=java:jboss/datasources/ExampleDS
\end{verbatim}
\end{enumerate}

Now that you've configured your data source, the mail session is next.

\section{Mail Configuration}\label{mail-configuration-1}

As with database configuration, the easiest way to configure mail is to
let Liferay DXP handle your mail session. If you want to use @product@'s
built-in mail session, skip this section and
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-mail}{configure
the mail session} in the Control Panel.

If you want to manage your mail session with Wildfly, follow these
steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Specify your mail subsystem in the
  \texttt{\$WILDFLY\_HOME/standalone/configuration/standalone.xml} file
  like this:

\begin{verbatim}
<subsystem xmlns="urn:jboss:domain:mail:3.0">
    <mail-session jndi-name="java:jboss/mail/MailSession" name="mail-smtp">
        <smtp-server ssl="true" outbound-socket-binding-ref="mail-smtp" username="USERNAME" password="PASSWORD"/>
   </mail-session>
</subsystem>
...
<socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}">
...
<outbound-socket-binding name="mail-smtp">
        <remote-destination host="[place SMTP host here]" port="[place SMTP port here]"/>
    </outbound-socket-binding>
</socket-binding-group>
\end{verbatim}
\item
  In your
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
  file in Liferay Home, reference your mail session:

\begin{verbatim}
mail.session.jndi.name=java:jboss/mail/MailSession
\end{verbatim}
\end{enumerate}

Next, you'll deploy Liferay DXP to your Wildfly app server.

\section{Deploying Liferay DXP}\label{deploying-liferay-dxp-2}

Now you're ready to deploy Liferay DXP using the @product@ WAR file.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If the folder \texttt{\$WILDFLY\_HOME/standalone/deployments/ROOT.war}
  already exists in your Wildfly installation, delete all of its
  subfolders and files. Otherwise, create a new folder called
  \texttt{\$WILDFLY\_HOME/standalone/deployments/ROOT.war}.
\item
  Unzip the Liferay DXP \texttt{.war} file into the \texttt{ROOT.war}
  folder.
\item
  To trigger deployment of \texttt{ROOT.war}, create an empty file named
  \texttt{ROOT.war.dodeploy} in your
  \texttt{\$WILDFLY\_HOME/standalone/deployments/} folder. On startup,
  Wildfly detects this file and deploys it as a web application.
\item
  Start the Wildfly application server by navigating to
  \texttt{\$WILDFLY\_HOME/bin} and running \texttt{standalone.bat} or
  \texttt{standalone.sh}.
\end{enumerate}

Congratulations; you've deployed Liferay DXP on Wildfly!

\noindent\hrulefill

\textbf{Note:} After deploying Liferay DXP, you may see excessive
warnings and log messages, such as the ones below, involving
\texttt{PhaseOptimizer}. These are benign and can be ignored. Make sure
to adjust your app server's logging level or log filters to avoid
excessive benign log messages.

\begin{verbatim}
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass gatherExternProperties
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass checkControlFlow
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 INFO: pass supports: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, modules, exponent operator (**), async function, trailing comma in param list]
 current AST contains: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, exponent operator (**), async function, trailing comma in param list, object literals with spread, object pattern rest]
\end{verbatim}

\chapter{Installing Liferay DXP on JBoss
EAP}\label{installing-liferay-dxp-on-jboss-eap}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Installing Liferay DXP on JBoss EAP 7.1 takes three steps:

\begin{itemize}
\tightlist
\item
  Installing dependencies to your application server
\item
  Configuring your application server for Liferay DXP
\item
  Installing the Liferay DXP WAR file to your application server
\end{itemize}

\noindent\hrulefill

\textbf{Important:} Before installing Liferay DXP, familiarize yourself
with
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install}{preparing
for install}.

\noindent\hrulefill

Now,
\href{/docs/7-2/deploy/-/knowledge_base/d/obtaining-product\#downloading-the-liferay-war-and-dependency-jars}{download
the Liferay DXP WAR and Dependency JARs}:

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file
\item
  Dependencies ZIP file
\item
  OSGi Dependencies ZIP file
\end{itemize}

Not that
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
Home}} is the folder containing your JBoss server folder. After
installing and deploying Liferay DXP, the Liferay Home folder contains
the JBoss server folder as well as \texttt{data}, \texttt{deploy},
\texttt{logs}, and \texttt{osgi} folders. \texttt{\$JBOSS\_HOME} refers
to your JBoss server folder. This folder is usually named
\texttt{jboss-eap-{[}version{]}}.

\section{Installing Dependencies}\label{installing-dependencies-2}

Liferay DXP depends on several Liferay-specific and third-party JARs.
Download and install the required JARs as described below.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create the folder
  \texttt{\$JBOSS\_HOME/modules/com/liferay/portal/main} if it doesn't
  exist and extract the JARs from the dependencies ZIP to it.
\item
  Download your database driver \texttt{.jar} file and copy it into the
  same folder.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** The [Liferay DXP Compatibility Matrix](https://web.liferay.com/documents/14/21598941/Liferay+DXP+7.2+Compatibility+Matrix/b6e0f064-db31-49b4-8317-a29d1d76abf7?) specifies supported databases and environments.
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  Create the file \texttt{module.xml} in the
  \texttt{\$JBOSS\_HOME/modules/com/liferay/portal/main} folder and
  insert this configuration:

\begin{verbatim}
<?xml version="1.0"?>

<module xmlns="urn:jboss:module:1.0" name="com.liferay.portal">
    <resources>
        <resource-root path="com.liferay.petra.concurrent.jar" />
        <resource-root path="com.liferay.petra.executor.jar" />
        <resource-root path="com.liferay.petra.function.jar" />
        <resource-root path="com.liferay.petra.io.jar" />
        <resource-root path="com.liferay.petra.lang.jar" />
        <resource-root path="com.liferay.petra.memory.jar" />
        <resource-root path="com.liferay.petra.nio.jar" />
        <resource-root path="com.liferay.petra.process.jar" />
        <resource-root path="com.liferay.petra.reflect.jar" />
        <resource-root path="com.liferay.petra.string.jar" />
        <resource-root path="com.liferay.registry.api.jar" />
        <resource-root path="hsql.jar" />
        <resource-root path="[place your database vendor's jar here]" />
        <resource-root path="portal-kernel.jar" />
        <resource-root path="portlet.jar" />
    </resources>
    <dependencies>
        <module name="javax.api" />
        <module name="javax.mail.api" />
        <module name="javax.servlet.api" />
        <module name="javax.servlet.jsp.api" />
        <module name="javax.transaction.api" />
    </dependencies>
</module>
\end{verbatim}

  Replace
  \texttt{{[}place\ your\ database\ vendor\textquotesingle{}s\ jar\ here{]}}
  with the driver JAR for your database.
\item
  Create an \texttt{osgi} folder in your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder. Extract the OSGi Dependencies ZIP file that you downloaded
  into the \texttt{{[}Liferay\ Home{]}/osgi} folder.

  The \texttt{osgi} folder provides the necessary modules for Liferay
  DXP's OSGi runtime.
\end{enumerate}

\textbf{Checkpoint:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The dependencies files have been unzipped into the
  \texttt{\$JBOSS\_HOME/modules/com/liferay/portal/main} folder and a
  database jar.
\item
  The \texttt{module.xml} contains all JARs in the
  \texttt{\textless{}resource-root-path\textgreater{}} elements.
\item
  The \texttt{osgi} dependencies have been unzipped into the
  \texttt{osgi} folder.
\end{enumerate}

\section{Running Liferay DXP on JBoss EAP in Standalone Mode vs.~Domain
Mode}\label{running-liferay-dxp-on-jboss-eap-in-standalone-mode-vs.-domain-mode}

JBoss EAP can be launched in either \emph{standalone} mode or
\emph{domain} mode. Domain mode allows multiple application server
instances to be managed from a single control point. A collection of
such application servers is known as a \emph{domain}. For more
information on standalone mode vs.~domain mode, please refer to the
section on this topic in the
\href{https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.1/html/introduction_to_jboss_eap/overview_of_jboss_eap\#operating_modes}{JBoss
EAP Product Documentation}.

Liferay DXP supports JBoss EAP when it runs in standalone mode but not
when it runs in domain mode. Liferay DXP's hot-deploy does not work with
a managed deployment, since JBoss manages the content of a managed
deployment by copying files (exploded or non-exploded). This prevents
JSP hooks and Ext plugins from working as intended. For example, JSP
hooks don't work on JBoss EAP running in managed domain mode, since
Liferay DXP's JSP override mechanism relies on the application server.
Since JSP hooks and Ext plugins are deprecated, however, you may not be
using them.

The command line interface is recommended for domain mode deployments.

\noindent\hrulefill

\textbf{Note:} This does not prevent Liferay DXP from running in a
clustered environment on multiple JBoss servers. You can set up a
cluster of Liferay DXP instances running on JBoss EAP servers running in
standalone mode. Please refer to the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{Liferay
DXP clustering articles} for more information.

\noindent\hrulefill

\section{Configuring JBoss}\label{configuring-jboss}

Configuring JBoss to run Liferay DXP includes these things:

\begin{itemize}
\tightlist
\item
  Setting environment variables
\item
  Setting properties and descriptors
\item
  Removing unnecessary configurations
\end{itemize}

Optionally, you can configure JBoss to manage Liferay DXP's data source
and mail session.

Start with configuring JBoss to run Liferay DXP.

Make the following modifications to
\texttt{\$JBOSS\_HOME/standalone/configuration/standalone.xml}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Locate the closing \texttt{\textless{}/extensions\textgreater{}} tag.
  Directly beneath that tag, insert these system properties:

\begin{verbatim}
<system-properties>
    <property name="org.apache.catalina.connector.URI_ENCODING" value="UTF-8" />
    <property name="org.apache.catalina.connector.USE_BODY_ENCODING_FOR_QUERY_STRING" value="true" />
</system-properties>
\end{verbatim}
\item
  Add the following \texttt{\textless{}filter-spec\textgreater{}} tag
  within the \texttt{\textless{}console-handler\textgreater{}} tag,
  directly below the
  \texttt{\textless{}level\ name="INFO"/\textgreater{}} tag:

\begin{verbatim}
<filter-spec value="not(any(match(&quot;WFLYSRV0059&quot;),match(&quot;WFLYEE0007&quot;)))" />
\end{verbatim}
\item
  Add a timeout for the deployment scanner by setting
  \texttt{deployment-timeout="600"} as seen in the excerpt below.

\begin{verbatim}
<subsystem xmlns="urn:jboss:domain:deployment-scanner:2.0">
    <deployment-scanner deployment-timeout="600" path="deployments" relative-to="jboss.server.base.dir" scan-interval="5000"/>
</subsystem>
\end{verbatim}
\item
  Add the following JAAS security domain to the security subsystem
  \texttt{\textless{}security-domains\textgreater{}} defined in element
  \texttt{\textless{}subsystem\ xmlns="urn:jboss:domain:security:2.0"\textgreater{}}.

\begin{verbatim}
<security-domain name="PortalRealm">
    <authentication>
        <login-module code="com.liferay.portal.security.jaas.PortalLoginModule" flag="required" />
    </authentication>
</security-domain>
\end{verbatim}
\item
  Remove the welcome content code snippets:

\begin{verbatim}
<location name="/" handler="welcome-content"/>
\end{verbatim}

  and

\begin{verbatim}
<handlers>
    <file name="welcome-content" path="${jboss.home.dir}/welcome-content"/>
</handlers>
\end{verbatim}
\item
  Find the \texttt{\textless{}jsp-config/\textgreater{}} tag and set the
  \texttt{development}, \texttt{source-vm}, and \texttt{target-vm}
  attributes in the tag. Once finished, the tag should look like this:

\begin{verbatim}
<jsp-config development="true" source-vm="1.8" target-vm="1.8"/>
\end{verbatim}
\end{enumerate}

\textbf{Checkpoint:}

Before continuing, verify the following properties have been set in the
\texttt{standalone.xml} file:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The new \texttt{\textless{}system-property\textgreater{}} is added.
\item
  The new \texttt{\textless{}filter-spec\textgreater{}} is added.
\item
  The \texttt{\textless{}deployment-timeout\textgreater{}} is set to
  \texttt{360}.
\item
  The new \texttt{\textless{}security-domain\textgreater{}} is created.
\item
  Welcome content is removed.
\item
  The \texttt{\textless{}jsp-config\textgreater{}} tag contains its new
  attributes.
\end{enumerate}

Now you should configure your JVM and startup scripts.

In the \texttt{\$WILDFLY\_HOME/bin/} folder, modify your standalone
domain's configuration script file \texttt{standalone.conf}
(\texttt{standalone.conf.bat} on Windows):

\begin{itemize}
\tightlist
\item
  Set the file encoding to \texttt{UTF-8}
\item
  Set the user time zone to \texttt{GMT}
\item
  Set the preferred protocol stack
\item
  Increase the default amount of memory available.
\end{itemize}

\noindent\hrulefill

\textbf{Important:} For Liferay DXP to work properly, the application
server JVM must use the \texttt{GMT} time zone and \texttt{UTF-8} file
encoding.

\noindent\hrulefill

Make the following edits as applicable to your operating system:

\textbf{Windows}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Comment out the initial \texttt{JAVA\_OPTS} assignment as demonstrated
  in the following line:

\begin{verbatim}
rem set "JAVA_OPTS=-Xms1G -Xmx1G -XX:MetaspaceSize=96M -XX:MaxMetaspaceSize=2560m"
\end{verbatim}
\item
  Add the following \texttt{JAVA\_OPTS} assignment one line above the
  \texttt{:JAVA\_OPTS\_SET} line found at end of the file:

\begin{verbatim}
set "JAVA_OPTS=%JAVA_OPTS% -Dfile.encoding=UTF-8 -Djava.net.preferIPv4Stack=true -Djboss.as.management.blocking.timeout=480 -Duser.timezone=GMT -Xms2560m -Xmx2560m -XX:MaxMetaspaceSize=768m"
\end{verbatim}
\end{enumerate}

\textbf{Unix}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Below the \texttt{if\ {[}\ "x\$JAVA\_OPTS"\ =\ "x"\ {]};} statement,
  replace this \texttt{JAVA\_OPTS} statement:

\begin{verbatim}
JAVA_OPTS="-Xms1303m -Xmx1303m -XX:MetaspaceSize=96M -XX:MaxMetaspaceSize=2560m -Djava.net.preferIPv4Stack=true"
\end{verbatim}

  with this:

\begin{verbatim}
JAVA_OPTS="-Djava.net.preferIPv4Stack=true"
\end{verbatim}
\item
  Add the following statement to the bottom of the file:

\begin{verbatim}
JAVA_OPTS="$JAVA_OPTS -Dfile.encoding=UTF-8 -Djava.net.preferIPv4Stack=true -Djboss.as.management.blocking.timeout=480 -Duser.timezone=GMT -Xms2560m -Xmx2560m -XX:MaxMetaspaceSize=512m"
\end{verbatim}
\end{enumerate}

On JDK 11, it's recommended to add this JVM argument to display
four-digit years.

\begin{verbatim}
-Djava.locale.providers=JRE,COMPAT,CLDR
\end{verbatim}

\noindent\hrulefill

\textbf{Note:} If you plan on using the IBM JDK with your JBoss server,
you must complete some additional steps. First, navigate to the
\texttt{\$JBOSS\_HOME/modules/com/liferay/portal/main/module.xml} file
and insert the following dependency within the
\texttt{\textless{}dependencies\textgreater{}} element:

\begin{verbatim}
 <module name="ibm.jdk" />
\end{verbatim}

Then navigate to the
\texttt{\$JBOSS\_HOME/modules/system/layers/base/sun/jdk/main/module.xml}
file and insert the following path names inside the
\texttt{\textless{}paths\textgreater{}...\textless{}/paths\textgreater{}}
element:

\begin{verbatim}
 <path name="com/sun/crypto" />
 <path name="com/sun/crypto/provider" />
 <path name="com/sun/image/codec/jpeg" />
 <path name="com/sun/org/apache/xml/internal/resolver" />
 <path name="com/sun/org/apache/xml/internal/resolver/tools" />
\end{verbatim}

The added paths resolve issues with portal deployment exceptions and
image uploading problems.

\noindent\hrulefill

\textbf{Checkpoint:}

At this point, you've finished configuring the application server's JVM
settings.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The file encoding, user time-zone, preferred protocol stack have been
  set in the \texttt{JAVA\_OPTS} in the \texttt{standalone.conf.bat}
  file.
\item
  The default amount of memory available has been increased.
\end{enumerate}

The prescribed script modifications are now complete for your Liferay
DXP installation on JBoss. Next you'll configure the database and mail.

\section{Database Configuration}\label{database-configuration-2}

The easiest way to handle your database configuration is to let Liferay
DXP manage your data source. The
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#using-the-built-in-data-source}{Basic
Configuration} page lets you configure Liferay DXP's built-in data
source. If you want to use the built-in data source, skip this section.

This section demonstrates configuring a MySQL database. If you're using
a different database, modify the data source and driver snippets as
necessary.

If using JBoss to manage the data source, follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add the data source inside the
  \texttt{\$JBOSS\_HOME/standalone/configuration/standalone.xml} file's
  the \texttt{\textless{}datasources\textgreater{}} element.

\begin{verbatim}
<datasource jndi-name="java:jboss/datasources/ExampleDS" pool-name="ExampleDS" enabled="true" jta="true" use-java-context="true" use-ccm="true">
    <connection-url>[place the URL to your database here]</connection-url>
    <driver>[place the driver name here]</driver>
    <security>
        <user-name>[place your user name here]</user-name>
        <password>[place your password here]</password>
    </security>
</datasource>
\end{verbatim}

  Make sure to replace the database URL, user name, and password with
  the appropriate values.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** If the data source `jndi-name` must be changed, edit the `datasource` element in the `<default-bindings>` tag.
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Add your driver to the \texttt{standalone.xml} file's
  \texttt{\textless{}drivers\textgreater{}} element also found within
  the \texttt{\textless{}datasources\textgreater{}} element.

\begin{verbatim}
<drivers>
    <driver name="[name of driver must match name above]" module="com.liferay.portal">
        <driver-class>[place your JDBC driver class here]</driver-class>
    </driver>
</drivers>
\end{verbatim}

  A final data sources subsystem that uses MySQL should look like this:

\begin{verbatim}
<subsystem xmlns="urn:jboss:domain:datasources:5.0">
    <datasources>
        <datasource jndi-name="java:jboss/datasources/ExampleDS" pool-name="ExampleDS" enabled="true" jta="true" use-java-context="true" use-ccm="true">
            <connection-url>jdbc:mysql://localhost/lportal</connection-url>
            <driver>mysql</driver>
            <security>
                <user-name>root</user-name>
                <password>root</password>
            </security>
        </datasource>
        <drivers>
            <driver name="mysql" module="com.liferay.portal"/>
        </drivers>
    </datasources>
</subsystem>
\end{verbatim}
\item
  In a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
  file in your Liferay Home, specify your data source:

\begin{verbatim}
jdbc.default.jndi.name=java:jboss/datasources/ExampleDS
\end{verbatim}
\end{enumerate}

Now that you've configured your data source, the mail session is next.

\section{Mail Configuration}\label{mail-configuration-2}

As with database configuration, the easiest way to configure mail is to
let Liferay DXP handle your mail session. If you want to use @product@'s
built-in mail session, skip this section and
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-mail}{configure
the mail session} in the Control Panel.

If you want to manage your mail session with JBoss, follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Specify your mail subsystem in the
  \texttt{\$JBOSS\_HOME/standalone/configuration/standalone.xml} file
  like this:

\begin{verbatim}
<subsystem xmlns="urn:jboss:domain:mail:3.0">
    <mail-session jndi-name="java:jboss/mail/MailSession" >
        <smtp-server ssl="true" outbound-socket-binding-ref="mail-smtp">
            <login username="[place user name here]" password="[place password here]"/>
        </smtp-server>
   </mail-session>
</subsystem>
...
<socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}">
...
<outbound-socket-binding name="mail-smtp">
        <remote-destination host="[place SMTP mail host here]" port="[place mail port here]"/>
    </outbound-socket-binding>
</socket-binding-group>
\end{verbatim}
\item
  In your \texttt{portal-ext.properties} file in Liferay Home, reference
  your mail session:

\begin{verbatim}
mail.session.jndi.name=java:jboss/mail/MailSession
\end{verbatim}
\end{enumerate}

You've got mail! Next, you'll deploy Liferay DXP to your JBoss app
server.

\section{Deploy Liferay}\label{deploy-liferay}

Now you're ready to deploy Liferay DXP using the @product@ WAR file.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If the folder \texttt{\$JBOSS\_HOME/standalone/deployments/ROOT.war}
  already exists in your JBoss installation, delete all of its
  subfolders and files. Otherwise, create a new folder called
  \texttt{\$JBOSS\_HOME/standalone/deployments/ROOT.war}.
\item
  Unzip the Liferay DXP \texttt{.war} file into the \texttt{ROOT.war}
  folder.
\item
  To trigger deployment of \texttt{ROOT.war}, create an empty file named
  \texttt{ROOT.war.dodeploy} in your
  \texttt{\$JBOSS\_HOME/standalone/deployments/} folder. On startup,
  JBoss detects this file and deploys it as a web application.
\item
  Start the JBoss application server by navigating to
  \texttt{\$JBOSS\_HOME/bin} and running \texttt{standalone.bat} or
  \texttt{standalone.sh}.
\end{enumerate}

Congratulations; you've now deployed Liferay DXP on JBoss!

\noindent\hrulefill

After deploying Liferay DXP, you may see excessive warnings and log
messages, such as the ones below, involving \texttt{PhaseOptimizer}.
These are benign and can be ignored. Make sure to adjust your app
server's logging level or log filters to avoid excessive benign log
messages.

\begin{verbatim}
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass gatherExternProperties
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass checkControlFlow
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 INFO: pass supports: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, modules, exponent operator (**), async function, trailing comma in param list]
 current AST contains: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, exponent operator (**), async function, trailing comma in param list, object literals with spread, object pattern rest]
\end{verbatim}

\chapter{Installing Liferay DXP on WebLogic 12c
R2}\label{installing-liferay-dxp-on-weblogic-12c-r2}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Although you can install Liferay DXP in a WebLogic Admin Server, this
isn't recommended. It's a best practice to install web apps, including
Liferay DXP, in a WebLogic Managed server. Deploying to a Managed Server
lets you start or shut down Liferay DXP more quickly and facilitates
transitioning into a cluster configuration. This article therefore
focuses on installing Liferay DXP in a Managed Server.

Before getting started, create your Admin and Managed Servers. See
\href{http://www.oracle.com/technetwork/middleware/weblogic/documentation/index.html}{WebLogic's
documentation} for instructions on setting up and configuring Admin and
Managed Servers.

Also familiarize yourself with
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install}{preparing
for install}.

Now,
\href{/docs/7-2/deploy/-/knowledge_base/d/obtaining-product\#downloading-the-liferay-war-and-dependency-jars}{download
the Liferay DXP WAR and Dependency JARs}:

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file
\item
  Dependencies ZIP file
\item
  OSGi Dependencies ZIP file
\end{itemize}

\section{Configuring WebLogic's Node
Manager}\label{configuring-weblogics-node-manager}

WebLogic's Node Manager starts and stops managed servers.

If you're running WebLogic on a UNIX system other than Solaris or Linux,
use the Java Node Manager, instead of the native version of the Node
Manager, by configuring these Node Manager properties in the
\texttt{domains/your\_domain\_name/nodemanager/nodemanager.properties}
file:

\begin{verbatim}
NativeVersionEnabled=false

StartScriptEnabled=true
\end{verbatim}

\noindent\hrulefill

\textbf{Note:} By default, SSL is used with Node Manager. If you want to
disable SSL during development, for example, set
\texttt{SecureListener=false} in your \texttt{nodemanager.properties}
file.

\noindent\hrulefill

See Oracle's
\href{https://docs.oracle.com/middleware/1212/wls/NODEM/java_nodemgr.htm\#NODEM173}{Configuring
Java Node Manager} documentation for details.

\section{Configuring WebLogic}\label{configuring-weblogic}

Next, you must set some variables in two WebLogic startup scripts. These
variables and scripts are as follows. Be sure to use \texttt{set}
instead of \texttt{export} if you're on Windows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{your-domain/startWebLogic.{[}cmd\textbar{}sh{]}}: This is the
  Admin Server's startup script.
\item
  \texttt{your-domain/bin/startWebLogic.{[}cmd\textbar{}sh{]}}: This is
  the startup script for Managed Servers.

  Add the following variables to both
  \texttt{startWebLogic.{[}cmd\textbar{}sh{]}} scripts:

\begin{verbatim}
export DERBY_FLAG="false"
export JAVA_OPTIONS="${JAVA_OPTIONS} -Dfile.encoding=UTF-8 -Duser.timezone=GMT -da:org.apache.lucene... -da:org.aspectj..."
export MW_HOME="/your/weblogic/directory"
export USER_MEM_ARGS="-Xmx2560m -Xms2560m"
\end{verbatim}
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Important:** For Liferay DXP to work properly, the application server JVM
 must use the `GMT` time zone and `UTF-8` file encoding.
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
The `DERBY_FLAG` setting disables the Derby server built in to WebLogic, as
Liferay DXP doesn't require this server. The remaining settings support
Liferay DXP's  memory requirements, UTF-8 requirement, Lucene usage, and
Aspect Oriented  Programming via AspectJ. Also make sure to set `MW_HOME` to
the directory  containing your WebLogic server on your machine. For example:

```bash
export MW_HOME="/Users/ray/Oracle/wls12210"
```
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  Some of the settings are also found in the
  \texttt{your-domain/bin/SetDomainEnv.{[}cmd\textbar{}sh{]}} . Add the
  following variables (Windows):

\begin{verbatim}
set WLS_MEM_ARGS_64BIT=-Xms2560m -Xmx2560m
set WLS_MEM_ARGS_32BIT=-Xms2560m -Xmx2560m
\end{verbatim}

  or on Mac or Linux:

\begin{verbatim}
WLS_MEM_ARGS_64BIT="-Xms2560m -Xmx2560m"
export WLS_MEM_ARGS_64BIT

WLS_MEM_ARGS_32BIT="-Xms2560m -Xmx2560m"
export WLS_MEM_ARGS_32BIT
\end{verbatim}
\item
  Set the Java file encoding to UTF-8 in
  \texttt{your-domain/bin/SetDomainEnv.{[}cmd\textbar{}sh{]}} by
  appending \texttt{-Dfile.encoding=UTF-8} ahead of your other Java
  properties:

\begin{verbatim}
JAVA_PROPERTIES="-Dfile.encoding=UTF-8 ${JAVA_PROPERTIES} ${CLUSTER_PROPERTIES}"
\end{verbatim}
\item
  You must also ensure that the Node Manager sets Liferay DXP's memory
  requirements when starting the Managed Server. In the Admin Server's
  console UI, navigate to the Managed Server you want to deploy Liferay
  DXP to and select the \emph{Server Start} tab. Enter the following
  parameters into the \emph{Arguments} field:

\begin{verbatim}
-Xmx2560m -Xms2560m -XX:MaxMetaspaceSize=512m
\end{verbatim}

  Click \emph{Save} when you're finished.
\end{enumerate}

Next, you'll set some Liferay DXP-specific properties for your @product@
installation.

\section{Setting Liferay DXP
Properties}\label{setting-liferay-dxp-properties}

Before installing Liferay DXP, you must set the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
Home}} folder's location via the \texttt{liferay.home} property in a
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
file. You can also use this file to override
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html}{other
Liferay DXP properties} that you may need.

First, decide which folder you want to serve as Liferay Home. In
WebLogic, your domain's folder is generally Liferay Home, but you can
choose any folder on your machine. Then create your
\texttt{portal-ext.properties} file and add the \texttt{liferay.home}
property:

\begin{verbatim}
liferay.home=/full/path/to/your/liferay/home/folder
\end{verbatim}

Remember to change this file path to the location on your machine that
you want to serve as Liferay Home.

Now that you've created your \texttt{portal-ext.properties} file, you
must put it inside the Liferay DXP WAR file. Expand the @product@ WAR
file and place \texttt{portal-ext.properties} in the
\texttt{WEB-INF/classes} folder. Later, you can deploy the expanded
archive to WebLogic. Alternatively, you can re-WAR the expanded archive
for later deployment. In either case, Liferay DXP reads your property
settings once it starts up.

If you need to make any changes to \texttt{portal-ext.properties} after
Liferay DXP deploys, you can find it in your domain's
\texttt{autodeploy/ROOT/WEB-INF/classes} folder. Note that the
\texttt{autodeploy/ROOT} folder contains the Liferay DXP deployment.

Next, you'll install Liferay DXP's dependencies.

\section{Installing Liferay DXP
Dependencies}\label{installing-liferay-dxp-dependencies}

You must now install Liferay DXP's dependencies. Recall that earlier you
downloaded two ZIP files containing these dependencies. Install their
contents now:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Unzip the Dependencies ZIP file and place its contents in your
  WebLogic domain's \texttt{lib} folder.
\item
  Unzip the OSGi Dependencies ZIP file and place its contents in the
  \texttt{Liferay\_Home/osgi} folder (create this folder if it doesn't
  exist).
\end{enumerate}

You must also add your database's driver JAR file to your domain's
\texttt{lib} folder.

\noindent\hrulefill

\textbf{Note:} Although Hypersonic is fine for testing purposes,
\textbf{do not} use it for production Liferay DXP instances.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} The
\href{https://web.liferay.com/documents/14/21598941/Liferay+DXP+7.2+Compatibility+Matrix/b6e0f064-db31-49b4-8317-a29d1d76abf7?}{Liferay
DXP Compatibility Matrix} specifies supported databases and
environments.

\noindent\hrulefill

Next, you'll configure your database.

\section{Database Configuration}\label{database-configuration-3}

Use the following procedure if you want WebLogic to manage your
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#using-the-built-in-data-source}{database}
for Liferay DXP. You can skip this section if you want to use
@product@'s built-in Hypersonic database.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Log in to your AdminServer console.
\item
  In the \emph{Domain Structure} tree, find your domain and navigate to
  \emph{Services} → \emph{JDBC} → \emph{Data Sources}.
\item
  To create a new data source, click \emph{New}. Fill in the \emph{Name}
  field with \texttt{Liferay\ Data\ Source} and the \emph{JNDI Name}
  field with \texttt{jdbc/LiferayPool}. Select your database type and
  driver. For example, MySQL is \emph{MySQL's Driver (Type 4)
  Versions:using com.mysql.cj.jdbc.Driver}. Click \emph{Next} to
  continue.
\item
  Accept the default settings on this page and click \emph{Next} to move
  on.
\item
  Fill in your database information for your MySQL database.
\item
  If using MySQL, add the text
  \texttt{?useUnicode=true\&characterEncoding=UTF-8\&\textbackslash{}useFastDateParsing=false}
  to the URL line and test the connection.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Tip:** For more example URLs, see the `jdbc.default.url` values in [Database Templates](/docs/7-2/deploy/-/knowledge_base/d/database-templates).
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
If the connection works, click *Next*.
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\item
  Select the target for the data source and click \emph{Finish}.
\item
  You must now tell Liferay DXP about the JDBC data source. Create a
  \texttt{portal-ext.propreties} file in your Liferay Home directory,
  and add the line:

\begin{verbatim}
jdbc.default.jndi.name=jdbc/LiferayPool
\end{verbatim}
\end{enumerate}

Alternatively, you can make the above configuration strictly via
properties in the \texttt{portal-ext.properties} file. Please see the
\href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
Templates} for example properties.

Next, you'll configure your mail session.

\section{Mail Configuration}\label{mail-configuration-3}

If you want WebLogic to manage your
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-mail}{mail
session}, use the following procedure. If you want to use Liferay's
built-in mail session (recommended), skip this section.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start WebLogic and log in to your Admin Server's console.
\item
  Select \emph{Services} → \emph{Mail Sessions} from the \emph{Domain
  Structure} box on the left hand side of your Admin Server's console
  UI.
\item
  Click \emph{New} to begin creating a new mail session.
\item
  Name the session \emph{LiferayMail} and give it the JNDI name
  \texttt{mail/MailSession}. Then fill out the \emph{Session Username},
  \emph{Session Password}, \emph{Confirm Session Password}, and
  \emph{JavaMail Properties} fields as necessary for your mail server.
  See the
  \href{http://docs.oracle.com/middleware/1221/wls/FMWCH/pagehelp/Mailcreatemailsessiontitle.html}{WebLogic
  documentation} for more information on these fields. Click \emph{Next}
  when you're done.
\item
  Choose the Managed Server that you'll install Liferay DXP on, and
  click \emph{Finish}. Then shut down your Managed and Admin Servers.
\item
  With your Managed and Admin servers shut down, add the following
  property to your \texttt{portal-ext.properties} file in Liferay Home:

\begin{verbatim}
mail.session.jndi.name=mail/MailSession
\end{verbatim}
\end{enumerate}

Liferay DXP references your WebLogic mail session via this property
setting. If you've already deployed Liferay DXP, you can find your
\texttt{portal-ext.properties} file in your domain's
\texttt{autodeploy/ROOT/WEB-INF/classes} folder.

Your changes take effect upon restarting your Managed and Admin servers.

\section{Deploying Liferay DXP}\label{deploying-liferay-dxp-3}

As mentioned earlier, although you can deploy Liferay DXP to a WebLogic
Admin Server, you should instead deploy it to a WebLogic Managed Server.
Dedicating the Admin Server to managing other servers that run your apps
is a best practice.

Follow these steps to deploy Liferay DXP to a Managed Server:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Make sure the Managed Server you want to deploy Liferay DXP to is shut
  down.
\item
  In your Admin Server's console UI, select \emph{Deployments} from the
  \emph{Domain Structure} box on the left hand side. Then click
  \emph{Install} to start a new deployment.
\item
  Select the Liferay DXP WAR file or its expanded contents on your file
  system. Alternatively, you can upload the WAR file by clicking the
  \emph{Upload your file(s)} link. Click \emph{Next}.
\item
  Select \emph{Install this deployment as an application} and click
  \emph{Next}.
\item
  Select the Managed Server you want to deploy Liferay DXP to and click
  \emph{Next}.
\item
  If the default name is appropriate for your installation, keep it.
  Otherwise, give it a name of your choosing and click \emph{Next}.
\item
  Click \emph{Finish}. After the deployment finishes, click \emph{Save}
  if you want to save the configuration.
\item
  Start the Managed Server where you deployed Liferay DXP. @product@
  precompiles all the JSPs and then launches.
\end{enumerate}

Nice work! Now you're running Liferay DXP on WebLogic.

\noindent\hrulefill

After deploying Liferay DXP, you may see excessive warnings and log
messages, such as the ones below, involving \texttt{PhaseOptimizer}.
These are benign and can be ignored. Make sure to adjust your app
server's logging level or log filters to avoid excessive benign log
messages.

\begin{verbatim}
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass gatherExternProperties
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass checkControlFlow
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 INFO: pass supports: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, modules, exponent operator (**), async function, trailing comma in param list]
 current AST contains: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, exponent operator (**), async function, trailing comma in param list, object literals with spread, object pattern rest]
\end{verbatim}

\chapter{Installing Liferay DXP on
WebSphere}\label{installing-liferay-dxp-on-websphere}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

IBM ® WebSphere ® is a trademark of International Business Machines
Corporation, registered in many jurisdictions worldwide.

\noindent\hrulefill

\textbf{Tip:} Throughout this installation and configuration process,
WebSphere prompts you to click \emph{Save} to apply changes to the
Master Configuration. Do \textbar{} so intermittently to save your
changes.

\noindent\hrulefill

For Liferay DXP to work correctly, WebSphere 9 (Fix Pack 11 is the
latest) must be installed. You can find more information about this fix
pack
\href{http://www-01.ibm.com/support/docview.wss?uid=swg24043005}{here}.

Please also note that Liferay DXP doesn't support the WebSphere
Application Liberty Profile.

\noindent\hrulefill

\textbf{Important:} Before installing Liferay DXP, familiarize yourself
with
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install}{preparing
for install}.

\noindent\hrulefill

Now,
\href{/docs/7-2/deploy/-/knowledge_base/d/obtaining-product\#downloading-the-liferay-war-and-dependency-jars}{download
the Liferay DXP WAR and Dependency JARs}:

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file
\item
  Dependencies ZIP file
\item
  OSGi Dependencies ZIP file
\end{itemize}

Note that the
\href{docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
Home} folder} is important to the operation of Liferay DXP. In Liferay
Home, @product@ creates certain files and folders that it needs to run.
On WebSphere, Liferay Home is typically
\texttt{{[}Install\ Location{]}/WebSphere/AppServer/profiles/your-profile/liferay}.

Without any further ado, get ready to install Liferay DXP in WebSphere!

\section{Preparing WebSphere for Liferay
DXP}\label{preparing-websphere-for-liferay-dxp}

When the application server binaries have been installed, start the
\emph{Profile Management Tool} to create a profile appropriate for
Liferay DXP.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click \emph{Create\ldots{}}, choose \emph{Application Server}, and
  then click \emph{Next}.
\item
  Click the \emph{Advanced} profile creation option and then click
  \emph{Next}. You need the advanced profile to specify your own values
  for settings such as the location of the profile and names of the
  profile, node and host, to assign your own ports, or to optionally
  choose whether to deploy the administrative console and sample
  application and also add web-server definitions for IBM HTTP Server.
  See the WebSphere documentation for more information about these
  options.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/websphere-01-profile.png}}
  \caption{Choose the Advanced profile option to specify your own
  settings.}
  \end{figure}
\item
  Check the box \emph{Deploy the administrative console}. This gives you
  a web-based UI for working with your application server. Skip the
  default applications. You'd only install these on a development
  machine. Click \emph{Next}.
\item
  Set the profile name and location. Ensure you specify a performance
  tuning setting other than \emph{Development}, since you're installing
  a production server. See the WebSphere documentation for more
  information about performance tuning settings. Click \emph{Next}.
\item
  Choose node, server, and host names for your server. These are
  specific to your environment. Click \emph{Next}.
\item
  Administrative security in WebSphere is a way to restrict who has
  access to the administrative tools. You may want to have it enabled in
  your environment so that a user name and password are required to
  administer the WebSphere server. See WebSphere's documentation for
  more information. Click \emph{Next}.
\item
  Each profile needs a security certificate, which comes next in the
  wizard. If you don't have certificates already, choose the option to
  generate a personal certificate and a signing certificate and click
  \emph{Next}.
\item
  Once the certificates are generated, set a password for your keystore.
  Click \emph{Next}.
\item
  Now you can customize the ports this server profile uses. Be sure to
  choose ports that are open on your machine. When choosing ports, the
  wizard detects existing WebSphere installations and if it finds
  activity, it increments ports by one.
\item
  Choose whether to start this profile when the machine starts. Click
  \emph{Next}.
\item
  WebSphere ships with IBM HTTP Server, which is a re-branded version of
  Apache. Choose whether you want a web server definition, so that this
  JVM receives requests forwarded from the HTTP server. See WebSphere's
  documentation for details on this. When finished, click \emph{Next}.
\item
  The wizard then shows you a summary of what you selected, enabling you
  to keep your choices or go back and change something. When you're
  satisfied, click \emph{Next}.
\end{enumerate}

WebSphere then creates your profile and finishes with a message telling
you the profile was created successfully. Awesome! Your profile is
complete. Now there are a few things you need to configure in your
application server.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/websphere-02-profile.png}}
\caption{Example of the settings before creating the profile.}
\end{figure}

\section{Configuring the WebSphere Application
Server}\label{configuring-the-websphere-application-server}

In this version of WebSphere, servlet filters are not initialized on web
application startup, but rather, on first access. This can cause
problems when deploying certain apps to Liferay DXP. To configure
servlet filters to initialize on application startup (i.e., deployment),
set the following \texttt{webcontainer} properties in your WebSphere
application server:

\begin{verbatim}
com.ibm.ws.webcontainer.initFilterBeforeInitServlet = true
com.ibm.ws.webcontainer.invokeFilterInitAtStartup = true
\end{verbatim}

To set \texttt{webcontainer} properties in the WebSphere application
server, follow the instructions
\href{http://www-01.ibm.com/support/docview.wss?rss=180&uid=swg21284395}{here
in WebSphere's documentation}.

\section{Setting up JVM Parameters for Liferay
DXP}\label{setting-up-jvm-parameters-for-liferay-dxp}

Next, in the WebSphere profile you created for Liferay DXP, you must set
an argument that supports Liferay DXP's Java memory requirements. You'll
modify this file:

\begin{verbatim}
[Install Location]/WebSphere/AppServer/profiles/your-profile/config/cells/your-cell/nodes/your-node/servers/your-server/server.xml
\end{verbatim}

Add \texttt{maximumHeapSize="2560"} inside the \texttt{jvmEntries} tag.
For example:

\begin{verbatim}
<jvmEntries xmi:id="JavaVirtualMachine_1183122130078" ... maximumHeapSize="2560">
\end{verbatim}

\noindent\hrulefill

\textbf{Note:} The JVM parameters used here are defaults intended for
initial deployment of production systems. Administrators should change
the settings to values that best address their specific environments.
These must be tuned depending on need.

\noindent\hrulefill

Administrators can set the UTF-8 properties in the
\texttt{\textless{}jvmEntries\ genericJvmArguments=.../\textgreater{}}
attribute in \texttt{server.xml}. This is required or else special
characters will not be parsed correctly. Set the maximum and minimum
heap sizes to \texttt{2560m} there too. Add the following inside the
\texttt{jvmEntries} tag:

\begin{verbatim}
<jvmEntries xmi:id="JavaVirtualMachine_1183122130078" ...genericJvmArguments="-Dfile.encoding=UTF-8 -Duser.timezone=GMT -Xms2560m -Xmx2560m">
\end{verbatim}

\noindent\hrulefill

\textbf{Important:} For Liferay DXP to work properly, the application
server JVM must use the \texttt{GMT} time zone and \texttt{UTF-8} file
encoding.

\noindent\hrulefill

Alternately, you can set the UTF-8 properties from the WebSphere Admin
Console. (See below.)

\section{Removing the secureSessionCookie
Tag}\label{removing-the-securesessioncookie-tag}

In the same profile, you should delete a problematic
\texttt{secureSessionCookie} tag that can cause Liferay DXP startup
errors. Note that this is just a default setting; once Liferay DXP is
installed, you should tune it appropriately based on your usage.

In
\texttt{{[}Install\ Location{]}/WebSphere/AppServer/profiles/your-profile/config/cells/your-cell/cell.xml},
Delete the \texttt{secureSessionCookie} tag containing
\texttt{xmi:id="SecureSessionCookie\_1"}.

If this tag is not removed, an error similar to this may occur:

\begin{verbatim}
WSVR0501E: Error creating component com.ibm.ws.runtime.component.CompositionUnitMgrImpl@d74fa901
com.ibm.ws.exception.RuntimeWarning: com.ibm.ws.webcontainer.exception.WebAppNotLoadedException: Failed to load webapp: Failed to load webapp: SRVE8111E: The application, LiferayEAR, is trying to modify a cookie which matches a pattern in the restricted programmatic session cookies list [domain=*, name=JSESSIONID, path=/].
\end{verbatim}

\section{Installing Liferay DXP's
Dependencies}\label{installing-liferay-dxps-dependencies}

You must now install Liferay DXP's dependencies. Recall that earlier you
downloaded two ZIP files containing these dependencies. Install their
contents now:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Unzip the Dependencies ZIP file and place its contents in your
  WebSphere application server's
  \texttt{{[}Install\ Location{]}/WebSphere/AppServer/lib/ext} folder.
  If you have a JDBC database driver \texttt{JAR}, copy it to this
  location as well.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** The [Liferay DXP Compatibility Matrix](https://web.liferay.com/documents/14/21598941/Liferay+DXP+7.2+Compatibility+Matrix/b6e0f064-db31-49b4-8317-a29d1d76abf7?) specifies supported databases and environments.
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  From the same archive, copy \texttt{portlet.jar}into
  \texttt{{[}Install\ Location{]}/WebSphere/AppServer/javaext} for
  WebSphere 9.0.0.x. WebSphere already contains an older version of
  \texttt{portlet.jar} which must be overridden at the highest class
  loader level. The new \texttt{portlet.jar} (version 3) is
  backwards-compatible.
\item
  Unzip the OSGi Dependencies ZIP file and place its contents in the
  \texttt{{[}Liferay\ Home{]}/osgi} folder (create this folder if it
  doesn't exist). This is typically
  \texttt{{[}Install\ Location{]}/WebSphere/AppServer/profiles/your-profile/liferay/osgi}.
\end{enumerate}

\section{Ensuring that Liferay DXP's portlet.jar is loaded
first}\label{ensuring-that-liferay-dxps-portlet.jar-is-loaded-first}

In addition to placing the \texttt{portlet.jar} in the correct folder,
you must configure the \texttt{config.ini} file so that it is loaded
first. Navigate to
\texttt{/IBM/WebSphere/AppServer/configuration/config.ini}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find the property \texttt{com.ibm.CORBA,com.ibm}
\item
  Insert the property
  \texttt{javax.portlet,javax.portlet.filter,javax.portlet.annotations}
  after \texttt{com.ibm.CORBA} and before \texttt{com.ibm}.
\item
  Save the file.
\end{enumerate}

Once you've installed these dependencies and configured the
\texttt{config.ini} file, start the server profile you created for
Liferay DXP. Once it starts, you're ready to configure your database.

\section{Database Configuration}\label{database-configuration-4}

If you want WebSphere to manage the database connections, follow the
instructions below. Note this is not necessary if you plan to use
Liferay DXP's standard database configuration; in that case, skip this
section. See the
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#using-the-built-in-data-source}{Using
the Built-in Data Sources} section for more article.

You'll set your database information in Liferay DXP's setup wizard after
the install.

\noindent\hrulefill

\textbf{Note:} Although Liferay DXP's embedded database is fine for
testing purposes, you \textbf{should not} use it for production Liferay
DXP instances.

\noindent\hrulefill

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/websphere-jdbc-providers.png}}
\caption{WebSphere JDBC providers}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start WebSphere.
\item
  Open the Administrative Console and log in.
\item
  Click \emph{Resources → JDBC Providers}.
\item
  Select a scope and then click \emph{New}.
\item
  Select your database type, provider type, and implementation type. If
  you select a predefined database, the wizard fills in the name and
  description fields for you. If the database you want to use isn't
  listed, select \emph{User-defined} from the \emph{Database type} field
  and then fill in the \emph{Implementation Class Name}. For example, if
  you use MySQL, select \emph{Database type} → \emph{User-defined}, and
  then enter
  \texttt{com.mysql.jdbc.jdbc2.optional.MysqlConnectionPoolDataSource}
  in \emph{Implementation Class Name}. Click \emph{Next} when you are
  finished.
\item
  Clear any text in the class path settings. You already copied the
  necessary JARs to a location on the server's class path. Click
  \emph{Next}.
\item
  Review your settings and click \emph{Finish}. The final configuration
  should look like this:

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/websphere-03.png}}
  \caption{Completed JDBC provider configurations.}
  \end{figure}
\item
  Click your new provider configuration when it appears in the table,
  and then click \emph{Data Sources} under \emph{Additional Properties}.
  Click \emph{New}.
\item
  Enter \emph{liferaydatabasesource} in the \emph{Data source name}
  field and \texttt{jdbc/LiferayPool} in the \emph{JNDI name} field.
  Click \emph{Next}.
\item
  Click \emph{Next} in the remaining screens of the wizard to accept the
  default values. Then review your changes and click \emph{Finish}.
\item
  Click the data source when it appears in the table and then click
  \emph{Custom Properties}. Now click the \emph{Show Filter Function}
  button. This is the second from last of the small icons under the
  \emph{New} and \emph{Delete} buttons.
\item
  Type \emph{user} into the search terms and click \emph{Go}.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/websphere-database-properties.png}}
  \caption{Modifying data source properties in WebSphere}
  \end{figure}
\item
  Select the \emph{user} property and give it the value of the user name
  to your database. Click \emph{OK} and save to master configuration.
\item
  Do another filter search for the \emph{url} property. Give this
  property a value that points to your database. For example, a MySQL
  URL would look like this:

\begin{verbatim}
jdbc:mysql://localhost/lportal?useUnicode=true&characterEncoding=UTF-8&serverTimezone=GMT&useFastDateParsing=false
\end{verbatim}
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Tip:** For more example URLs, see the `jdbc.default.url` values in
 [Database Templates](/docs/7-2/deploy/-/knowledge_base/d/database-templates).
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
Click *OK* and save to master configuration.
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{14}
\item
  Do another filter search for the \emph{password} property. Enter the
  password for the user ID you added earlier as the value for this
  property. Click \emph{OK} and save to master configuration.
\item
  Go back to the data source page by clicking it in the breadcrumb
  trail. Click the \emph{Test Connection} button. It should connect
  successfully.
\end{enumerate}

Once you've set up your database, you can set up your mail session.

\section{Mail Configuration}\label{mail-configuration-4}

If you want WebSphere to manage your mail sessions, use the following
procedure. If you want to use Liferay DXP's built-in mail sessions, you
can skip this section. See the
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-mail}{Configuring
Mail} article on how to use Liferay DXP's built-in mail sessions.

\section{Creating a WebSphere-Managed Mail Session
(Optional)}\label{creating-a-websphere-managed-mail-session-optional}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click \emph{Resources → Mail → Mail Providers}.
\item
  Click the Built-In Mail Provider for your node and server.
\item
  Click \emph{Mail Sessions} and then click the \emph{New} button.
\item
  Give your mail session a name of \emph{liferaymail} and a JNDI name of
  \texttt{mail/MailSession}. Fill in the correct information for your
  mail server in the sections \emph{Outgoing Mail Properties} and
  \emph{Incoming Mail Properties}. Click \emph{OK} and then save to the
  master configuration.
\item
  Click your mail session when it appears in the table and select
  \emph{Custom Properties} under the \emph{Additional Properties}
  section. Set any other JavaMail properties required by your mail
  server, such as the protocol, ports, whether to use SSL, and so on.
\item
  Click \emph{Security → Global Security} and de-select \emph{Use Java 2
  security to restrict application access to local resources} if it is
  selected. Click \emph{Apply}.
\end{enumerate}

Note that you may also need to retrieve a SSL certificate from your mail
server and add it to WebSphere's trust store. See WebSphere's
documentation for instructions on this.

\section{Verifying WebSphere Mail
Provider}\label{verifying-websphere-mail-provider}

To validate that the mail session has been configured correctly, there
are a number of ways to test this once the WAR has been deployed, the
server has started, and the user has signed in as the system
administrator. One quick way to validate is to create a new user with a
valid email account. The newly created user should receive an email
notification. The logs should display that the SMTP server has been
pinged with the correct port number listed.

\section{Enable Cookies for HTTP
Sessions}\label{enable-cookies-for-http-sessions}

WebSphere restricts cookies to HTTPS sessions by default. If you're
using HTTP instead, this prevents users from signing in to Liferay DXP
and displays the following error in the console:

\begin{verbatim}
20:07:14,021 WARN  [WebContainer : 1][SecurityPortletContainerWrapper:341]
User 0 is not allowed to access URL http://localhost:9081/web/guest/home and
portlet com_liferay_login_web_portlet_LoginPortlet
\end{verbatim}

This occurs because Liferay DXP can't use the HTTPS cookie when you use
HTTP. The end result is that new sessions are created on each page
refresh. Follow these steps to resolve this issue in WebSphere:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click \emph{Application Servers} → \emph{server1} → \emph{Session
  Management} → Enable Cookies
\item
  De-select \emph{Restrict cookies to HTTPS sessions}
\item
  Click \emph{Apply}
\item
  Click \emph{Save}
\end{enumerate}

\section{Enable UTF-8}\label{enable-utf-8}

If you did not add the \texttt{-Dfile.encoding=UTF-8} property in the
\texttt{server.xml}, you can do so in the Administrative Console.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click \emph{Application Servers} → \emph{server1} → \emph{Process
  definition}.
\item
  Click \emph{Java Virtual Machine} under \emph{Additional Properties}.
\item
  Enter \texttt{-Dfile.encoding=UTF-8} in the \emph{Generic JVM
  arguments} field.
\item
  Click \emph{Apply} and then \emph{Save} to master configuration.
\end{enumerate}

Once the changes have been saved, Liferay DXP can parse special
characters if there is localized content.

\section{Deploy Liferay DXP}\label{deploy-liferay-dxp}

Now you're ready to deploy Liferay DXP!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In WebSphere's administrative console, click \emph{Applications} →
  \emph{New Application} → \emph{New Enterprise Application}.
\item
  Browse to the Liferay DXP \texttt{.war} file, select it, and click
  \emph{Next}.
\item
  Leave \emph{Fast Path} selected and click \emph{Next}. Ensure that
  \emph{Distribute Application} has been checked and click \emph{Next}
  again.
\item
  Choose the WebSphere runtimes and/or clusters where you want Liferay
  DXP deployed. Click \emph{Next}.
\item
  Select the virtual host to deploy Liferay DXP on and click
  \emph{Next}.
\item
  Map Liferay DXP to the root context (\texttt{/}) and click
  \emph{Next}.
\item
  Select the \emph{metadata-complete attribute} setting that you want to
  use and click \emph{Next}.
\item
  Ensure that you have made all the correct choices and click
  \emph{Finish}. When Liferay DXP has installed, click \emph{Save to
  Master Configuration}.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/websphere-deploy-dxp.png}}
\caption{Review your deployment options before deploying.}
\end{figure}

You've now installed Liferay DXP!

\section{Setting the JDK Version for Compiling
JSPs}\label{setting-the-jdk-version-for-compiling-jsps}

Liferay DXP requires that its JSPs are compiled to the Java 8 bytecode
format. To ensure that WebSphere does this, shut down WebSphere after
you've deployed the Liferay DXP \texttt{.war} file. Navigate to the
\texttt{WEB\_INF} folder and add the following setting to the
\texttt{ibm-web-ext.xml} or in most cases the \texttt{ibm-web-ext.xmi}
file:

\begin{verbatim}
<jsp-attribute name="jdkSourceLevel" value="18" />
\end{verbatim}

The exact path to the \texttt{ibm-web-ext.xmi} file depends on your
WebSphere installation location and Liferay DXP version, but here's an
example:

\begin{verbatim}
/opt/IBM/WebSphere/AppServer/profiles/AppSrv01/config/cells/localhostNode01Cell/applications/liferayXX.ear/deployments/liferayXX/liferayXX.war/WEB-INF/ibm-web-ext.xmi
\end{verbatim}

Note that the Liferay DXP \texttt{.war} comes pre-packaged with the
\texttt{ibm-web-ext.xmi} file; this format is functionally the same as
\texttt{.xml} and WebSphere recognizes both formats. For more general
information on how WebSphere compiles JSPs see IBM's official
documentation for
\href{https://www.ibm.com/support/knowledgecenter/en/SSEQTP_9.0.0/com.ibm.websphere.base.doc/ae/rweb_jspengine.html}{WebSphere
Application Server 9.0.0.x}.

\section{Start Liferay DXP}\label{start-liferay-dxp}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If you plan to use Liferay DXP's {[}setup

  wizard{]}(/docs/7-2/deploy/-/knowledge\_base/d/installing-product\#using-the-setup-wizard),
  skip to the next step. If you wish to use WebSphere's data source and
  mail session, create a file called \texttt{portal-ext.properties} in
  your Liferay Home folder. Place the following configuration in the
  file:

\begin{verbatim}
jdbc.default.jndi.name=jdbc/LiferayPool
mail.session.jndi.name=mail/MailSession
setup.wizard.enabled=false
\end{verbatim}
\item
  In the WebSphere administrative console, navigate to \emph{Enterprise
  Applications}, select the Liferay DXP application, and click
  \emph{Start}. While Liferay DXP is starting, WebSphere displays a
  spinning graphic.
\item
  In Liferay DXP's setup wizard, select and configure your database
  type. Click \emph{Finish} when you're done. Liferay DXP then creates
  the tables it needs in the database.
\end{enumerate}

Congratulations! You've installed Liferay DXP on WebSphere!

\noindent\hrulefill

After deploying Liferay DXP, you may see excessive warnings and log
messages, such as the ones below, involving \texttt{PhaseOptimizer}.
These are benign and can be ignored. Make sure to adjust your app
server's logging level or log filters to avoid excessive benign log
messages.

\begin{verbatim}
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass gatherExternProperties
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 WARNING: Skipping pass checkControlFlow
 May 02, 2018 9:12:27 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process
 INFO: pass supports: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, modules, exponent operator (**), async function, trailing comma in param list]
 current AST contains: [ES3 keywords as identifiers, getters, reserved words as properties, setters, string continuation, trailing comma, array pattern rest, arrow function, binary literal, block-scoped function declaration, class, computed property, const declaration, default parameter, destructuring, extended object literal, for-of loop, generator, let declaration, member declaration, new.target, octal literal, RegExp flag 'u', RegExp flag 'y', rest parameter, spread expression, super, template literal, exponent operator (**), async function, trailing comma in param list, object literals with spread, object pattern rest]
\end{verbatim}

\chapter{Activating Liferay DXP}\label{activating-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

There are two ways to activate your Liferay DXP instance:

\begin{itemize}
\item
  With an XML activation key that you request and receive from Liferay
  Support.
\item
  Online activation through Liferay Connected Services (LCS). Liferay
  DXP 7.0 introduced LCS as a way to activate Liferay DXP instances. LCS
  can also install fix packs, monitor each instance's performance, and
  help administrators automatically manage Liferay DXP subscriptions.
  See the
  \href{/docs/7-1/deploy/-/knowledge_base/d/managing-liferay-dxp-with-liferay-connected-services}{LCS
  documentation} for instructions on activating your instances with LCS.
\end{itemize}

\noindent\hrulefill

\textbf{Note:} You must use LCS for activation of Elastic subscriptions.
Otherwise, you don't have to use LCS for activation. You can instead
request an XML activation key from Liferay Support.

\noindent\hrulefill

\chapter{Setting Up Marketplace}\label{setting-up-marketplace}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

\href{https://www.liferay.com/marketplace}{Liferay Marketplace} is more
than just a store for Liferay applications. Under the hood, it provides
both the store and Liferay DXP's application deployment features. For
this reason, you must ensure that Marketplace can run and configure
itself.

Here are some scenarios to work around to ensure Marketplace works
successfully:

\begin{itemize}
\tightlist
\item
  Server is Firewalled without Access to the Internet
\item
  Limited Database Access
\end{itemize}

The firewall scenario is discussed first.

\section{Server is Firewalled without Access to the
Internet}\label{server-is-firewalled-without-access-to-the-internet}

Your server might be behind a firewall that prevents access to the
Internet. Or your security policy might not allow direct download and
installation from the Internet. In these cases, you have two options:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From an Internet-enabled computer, download the
  \href{https://www.liferay.com/marketplace/download}{Marketplace
  plugin}. Then deploy the plugin (\texttt{.lpkg} file) by copying it
  into the \texttt{deploy} folder in
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}.
\item
  Alternately, once you have the downloaded \texttt{.lpkg} file, deploy
  it using the
  \href{/docs/7-2/user/-/knowledge_base/u/managing-and-configuring-apps}{App
  Manager}.
\end{enumerate}

Next you'll learn how to work around database access restrictions.

\section{Limited Database Access}\label{limited-database-access}

Some production environments do not have the necessary database
permissions for Liferay DXP, apps, modules, and plugins to maintain
their tables. In these cases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Grant the Liferay DXP database user temporary full rights to the
  database.
\item
  Install Liferay DXP and start it so that it populates its database.
\item
  Once the database is created, remove the permissions for creating
  tables and dropping tables from the Liferay DXP database user.
\end{enumerate}

See the
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-for-install\#limiting-database-access}{database
preparation instructions} for more information. Note that many
sophisticated Liferay DXP apps---not just the Marketplace app---require
new tables when deployed. If your environment restricts database access,
you may need to repeat the above steps whenever you deploy a new app.

You've prepared Liferay DXP for installing Marketplace and additional
apps.

\chapter{Trial Plugin Installation}\label{trial-plugin-installation}

{This document has been updated and ported to \textless a
href=``https://learn.liferay.com/dxp/latest/en/system-administration/installing-and-managing-apps/installing-apps/accessing-ee-plugins-during-a-trial-period.html)
and is no longer maintained here.}

For Liferay customers who are evaluating Liferay DXP on a trial basis,
\textbf{the plugins can be accessed from within the \emph{Apps} →
\emph{Store} (i.e., Marketplace) section of the Control Panel in your
product installation}.

\section{Installation Process}\label{installation-process}

Follow the steps below to install a trial plugin:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Register a \texttt{liferay.com} account (LRDC) account by visiting
  Liferay's home page (if necessary). Do this by clicking \emph{Sign
  In/Create Account} button from the top right Profile button.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/liferay-com-sign-in.png}}
  \caption{Hover over the Profile button and click \emph{Sign In/Create
  Account}.}
  \end{figure}
\item
  Start your Liferay DXP instance (trial license is OK).
\item
  After signing in as an Admin in your Liferay DXP trial server, go to
  the Control Panel → \emph{Apps} → \emph{Store} and sign in to the
  Marketplace using your \texttt{liferay.com} (LRDC) account
  credentials. Authorize Marketplace to access your local account.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/dxp-store-link.png}}
  \caption{Click the \emph{Store} link and authorize Marketplace to
  access your local account.}
  \end{figure}
\item
  Once signed into the Store, click on the \emph{Purchased} link, and
  then click on the \emph{EE} tab.

  Here you can see a list of Liferay DXP plugins that are installed, as
  well as options to update or install certain plugins. See
  \href{/docs/7-2/user/-/knowledge_base/u/using-the-liferay-marketplace}{Using
  the Liferay Marketplace} for details.
\end{enumerate}

Next are answers to some common questions.

\section{FAQ}\label{faq}

\textbf{Q:} Where are the \emph{Liferay DXP Trial Plugins}?

\textbf{A:} There is no such thing. The Liferay DXP plugins in Liferay
Marketplace are the same ones that you get to try out with your Liferay
DXP trial license for your portal. The Liferay DXP license (trial or
official @product@ subscriber) gives you access to the Liferay DXP
plugins. Also, there is no difference code-wise or release-wise between
a Liferay DXP trial installation and a regular @product@ non-trial
installation. The only difference is the license.

\textbf{Q:} Why can't I go to liferay.com/marketplace? Why can't I
\emph{purchase} from the Marketplace site?

\textbf{A:} DXP trial users must use the Marketplace from within the
product's Control Panel (instructions above). You do not need to
\emph{purchase} any DXP plugins because if you access Marketplace from
within the Control Panel, Marketplace sees that you have a DXP license
installed and gives access to DXP plugins. Official DXP subscription
customers (i.e., non trial) can log into \texttt{liferay.com} with their
designated DXP subscriber login and access all DXP plugins through the
Marketplace website.

\textbf{Q:} Why are the plugins under the Purchased tab? If I click on
the \emph{DXP Marketplace} link, it does not let me get the DXP plugins.

\textbf{A:} Once you're signed into the Store, click on the
\emph{Purchased} tab, then click on the \emph{EE} tab.

\textbf{Q:} What happens when DXP trial customers become official
Liferay Digital Experience subscribers?

\textbf{A:} They can still complete the above process, or they can also
visit the \href{https://www.liferay.com/marketplace}{Liferay Marketplace
website}.

\textbf{Q:} Do DXP trial customers get the DXP source code?

\textbf{A:} No, they can only install the plugin. The DXP source code
becomes available once they are official Liferay DXP Enterprise
subscribers.

\textbf{Q:} Can this process of installing DXP plugins be used from
Liferay Portal CE (Community Edition)?

\textbf{A:} No, the Marketplace must detect that you are running Liferay
DXP.

\chapter{Document Repository
Configuration}\label{document-repository-configuration}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

You can configure file storage in several ways. Each option is a
\emph{store} which can be configured through the
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
file by setting the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Document\%20Library\%20Service}{\texttt{dl.store.impl=}
property}.

The default store is called Simple File Store. It stores
\href{/docs/7-2/user/-/knowledge_base/u/managing-documents-and-media}{documents
and media} files on a file system (local or mounted). The store's
default root folder is
\texttt{{[}Liferay\ Home{]}/data/document\_library}. You can specify a
different root directory from within
\href{/docs/7-2/user/-/knowledge_base/u/system-settings}{System
Settings}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Access System Settings by opening the \emph{Menu}
  (\pandocbounded{\includegraphics[keepaspectratio]{./images/icon-menu.png}})
  and navigating to \emph{Control Panel → Configuration → System
  Settings}.
\item
  In the \emph{Platform} section, click \emph{File Storage}. The File
  Storage page appears.
\item
  Click \emph{Simple File System Store}.
\item
  For the store's \emph{Root directory} value, specify its absolute path
  or its path relative to
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}.
\item
  Click the \emph{Save} button.
\end{enumerate}

The document library store switches immediately to the new folder.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/file-storage.png}}
\caption{The File Storage page in System Settings lets you configure
document repository storage.}
\end{figure}

You can also use an entirely different method for storing documents and
media files:

\textbf{Simple File System Store}: uses the file system (local or a
mounted share) to store files.

\textbf{Advanced File System Store}: in addition to using the file
system (local or a mounted share) to store files, Advanced File System
Store nests the files into folders by version, for faster performance
and to store more files.

\textbf{S3 Store (Amazon Simple Storage)}: uses Amazon's cloud-based
storage solution.

\textbf{DBStore (Database Storage)}: stores the files in the database.
DBStore's file (stored as a blob) size is 1 gigabyte. To store files
larger than 1 gigabyte, use Simple File System Store or Advanced File
System Store.

These articles explain details for each one.

\chapter{Using the Simple File System
Store}\label{using-the-simple-file-system-store}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The simple file storage implementation is the default store. It uses a
local folder to store files. You can use the file system for your
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{clustered}
configuration, but the folder you're pointing to must be shared by all
nodes and handle concurrent requests and file locking. For this reason,
you need to use a Storage Area Network or a clustered file system.

The file system store was the first store used in Liferay DXP and is
heavily bound to the Liferay DXP database. By default, documents are
stored in a \texttt{document\_library} subfolder of the \texttt{data}
folder. Of course, you can change this path to anything you want in
\href{/docs/7-2/user/-/knowledge_base/u/system-settings}{System
Settings}.

The Simple File System store uses this folder path format for storing
documents:

\begin{verbatim}
/companyId/folderId/numericFileEntryName/versionNumber
\end{verbatim}

The first folder name is the site's company ID. The second folder name
is the Documents and Media folder's ID where the document resides. The
third folder name is the document's numeric file entry name. Finally,
the fourth name is a version number used for storing multiple versions
of the document.

\noindent\hrulefill

\textbf{Note:} A document's numeric file entry name is distinct from the
document ID; don't confuse the two! Each has an independent counter. The
numeric file entry name is used in the folder path for storing the
document but the document ID is not. The numeric file entry name is in
the \texttt{name} column of the \texttt{DLFileEntry} table in Liferay
DXP's database; the document ID is in the \texttt{fileEntryId} column of
the same table.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Warning:} If a database transaction rollback occurs in the
Document Library, file system changes that have occurred since the start
of the transaction aren't reversed. Inconsistencies between Document
Library files and those in the file system store can occur and may
require manual synchronization.

\noindent\hrulefill

The Simple File System Store binds documents very closely to Liferay
DXP, and may not be exactly what you want. If you've been using the
default settings for a while and must migrate your documents, there's a
migration utility in the Control Panel in \emph{Server Administration} →
\emph{Data Migration}. The utility facilitates moving documents from one
store implementation to another.

\chapter{Using the Advanced File System
Store}\label{using-the-advanced-file-system-store}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The advanced file system store is similar to the simple file system
store (the default store). Like that store, it saves files to the local
file system---which, of course, could be a remote file system mount. It
uses a slightly different folder structure to store files, which is
pictured below.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/enterprise-adv-file-system-store.png}}
\caption{The advanced file system store creates a more nested folder
structure than the file system store.}
\end{figure}

So what makes the advanced file system store \emph{advanced}? Several
operating systems have limitations on the number of files that can be
stored in a particular folder. The advanced file system store overcomes
this limitation by programmatically creating a structure that can expand
to millions of files, by alphabetically nesting the files in folders.
This not only allows for more files to be stored, but also improves
performance as there are fewer files stored per folder.

The same rules apply to the advanced file system store as apply to the
simple file system store. To
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{cluster}
this, you must point the store to a network mounted file system that all
the nodes can access, and that networked file system must support
concurrent requests and file locking. Otherwise, you may experience data
corruption issues if two users attempt to write to the same file at the
same time from two different nodes.

To use the advanced file system store, follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Configure \texttt{portal-ext.properties} with this property:

\begin{verbatim}
dl.store.impl=com.liferay.portal.store.file.system.AdvancedFileSystemStore
\end{verbatim}
\item
  Restart Liferay DXP.
\item
  In the Control Panel, navigate to \emph{Configuration} → \emph{System
  Settings} → \emph{File Storage}.
\item
  In the \emph{Advanced File System Store} screen, configure the store
  your way.
\item
  Click \emph{Save}.
\end{enumerate}

Liferay DXP is using the advanced file system store.

\noindent\hrulefill

\textbf{Warning:} If a database transaction rollback occurs in the
Document Library, file system changes that have occurred since the start
of the transaction aren't reversed. Inconsistencies between Document
Library files and those in the file system store can occur and may
require manual synchronization.

\noindent\hrulefill

You may decide the advanced file system store for whatever reason
doesn't serve your needs. If this is the case, you can of course mount
other file systems into the documents and media library. In addition to
this, you can also redefine the Liferay DXP store to use one of the
other supported protocols. S3 store is next.

\chapter{Using Amazon Simple Storage
Service}\label{using-amazon-simple-storage-service}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Amazon's simple storage service (S3) is a cloud-based storage solution
that you can use with Documents and Media. All you need is an account,
and you can store your documents to the cloud from all nodes,
seamlessly.

When you sign up for the service, Amazon assigns you unique keys that
link you to your account. In Amazon's interface, you can create
``buckets'' of data optimized by region.

Here are the steps for configuring Liferay DXP to use your S3 account
for file storage:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Amazon S3 requires a \texttt{SAXParser} from the application server to
  operate. If you are using an app server like Apache Tomcat that have
  one, you must include this property in a
  \href{/docs/7-2/deploy/-/knowledge_base/d/system-properties}{\texttt{system-ext.properties}}
  file:

\begin{verbatim}
org.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser
\end{verbatim}
\item
  Place your \texttt{system-ext.properties} file in a folder that
  resides in your Liferay DXP installation's class path (e.g.,
  \texttt{/WEB-INF/classes/}).
\item
  Set the following property in a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
  file in your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder:

\begin{verbatim}
dl.store.impl=com.liferay.portal.store.s3.S3Store
\end{verbatim}
\item
  Restart Liferay DXP.
\item
  In the Control Panel, navigate to \emph{Configuration} → \emph{System
  Settings} → \emph{File Storage}.
\item
  In the \emph{S3 Store Configuration} screen, configure the store your
  way.
\item
  Click \emph{Save}.
\end{enumerate}

Your Liferay DXP instance is using the Amazon S3 store.

\noindent\hrulefill

\textbf{Warning:} If a database transaction rollback occurs in a
Document Library that uses a file system based store, file system
changes that have occurred since the start of the transaction aren't
reversed. Inconsistencies between Document Library files and those in
the file system store can occur and may require manual synchronization.
All stores except DBStore are vulnerable to this limitation.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} No action is required to support AWS Signature Version 4
request authorization.

\noindent\hrulefill

Consult the Amazon Simple Storage documentation for additional details
on using Amazon's service.

\chapter{Using the DBStore}\label{using-the-dbstore}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

You can store Documents and Media files in your Liferay DXP database
using DBStore. DBStore's maximum file (stored as a blob) size is 1
gigabyte. To store files larger than that, use Simple File System Store
or Advanced File System Store.

Here are the DBStore configuration steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Set the following property in a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
  file in your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder:

\begin{verbatim}
dl.store.impl=com.liferay.portal.store.db.DBStore
\end{verbatim}
\item
  Restart Liferay DXP.
\end{enumerate}

Documents and Media now uses Liferay DXP's database via DBStore.

\chapter{Configuring Liferay DXP}\label{configuring-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Once you have Liferay DXP installed, it's time to configure it to the
specifics of your environment. This means doing things like setting the
time zone and language, configuring mail, configuring a cluster,
configuring a Content Delivery Network, tuning, and more. These topics
and more are discussed here.

\chapter{Configuring Mail}\label{configuring-mail}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay DXP uses a mail server and SMTP to email notifications.
@product@'s built-in mail session is the easiest way to configure mail
and it's recommended. You can configure the built-in mail session before
or after deploying Liferay DXP. Alternatively, you can configure Liferay
DXP to use a mail session on the application server.

Creating a mail session in Liferay DXP or on the application server
requires this information:

\begin{itemize}
\tightlist
\item
  Incoming POP Server and port
\item
  POP User Name
\item
  POP Password
\item
  Outgoing SMTP Server and port
\item
  SMTP User Name
\item
  SMTP Password
\item
  All JavaMail properties you want to use
\end{itemize}

Built-in mail session setup is recommended and easiest.

\section{Configuring Liferay DXP's Built-in Mail
Session}\label{configuring-liferay-dxps-built-in-mail-session}

The built-in mail session setup can be done using either of these
methods:

\begin{itemize}
\item
  Control Panel
\item
  Portal properties
\end{itemize}

\section{Built-in Mail Session in the Control
Panel}\label{built-in-mail-session-in-the-control-panel}

After deploying Liferay DXP, you can configure the mail session from the
Control Panel.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Sign in as the administrative user (the user you specified on the
  \href{/docs/7-2/deploy/-/knowledge_base/d/installing-product\#using-the-setup-wizard}{Basic
  Configuration page}).
\item
  Navigate to \emph{Control Panel → Configuration → Server
  Administration → Mail}.
\item
  Fill out the form. You're asked for the following information:

  \textbf{Incoming POP Server:} The hostname for a server running the
  Post Office Protocol. Liferay DXP checks this mailbox for incoming
  messages, such as message board replies.

  \textbf{Incoming Port:} The port on which the POP server is listening.

  \textbf{Use a Secure Network Connection:} Use an encrypted connection
  when connecting to the POP server.

  \textbf{User Name:} The user ID Liferay DXP should use to log into the
  POP server.

  \textbf{Password:} The password Liferay DXP should use to log into the
  POP server.

  \textbf{Outgoing SMTP Server:} The hostname for a server running the
  Simple Mail Transfer Protocol. Liferay DXP uses this server to send
  emails, such as password change emails and other notifications.

  \textbf{Outgoing Port:} The port on which the SMTP server is
  listening.

  \textbf{Use a Secure Network Connection:} Use an encrypted connection
  when connecting to the SMTP server.

  \textbf{User Name:} The user ID Liferay DXP should use to log into the
  SMTP server.

  \textbf{Password:} The password Liferay DXP should use to log into the
  SMTP server.

  \textbf{Manually specify additional JavaMail properties to override
  the above configuration:} If there are additional properties you need
  to specify, supply them here.
\item
  Click \emph{Save}.
\end{enumerate}

Liferay DXP connects to the mail session immediately.

\section{Built-in Mail Session Portal
Properties}\label{built-in-mail-session-portal-properties}

If you prefer specifying your mail session offline or before deploying
Liferay DXP, use portal properties.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}
  file}, if you haven't already created one.
\item
  Copy these default property settings into your
  \texttt{portal-ext.properties} file:

\begin{verbatim}
mail.session.mail=false
mail.session.mail.pop3.host=localhost
mail.session.mail.pop3.password=
mail.session.mail.pop3.port=110
mail.session.mail.pop3.user=
mail.session.mail.smtp.auth=false
mail.session.mail.smtp.host=localhost
mail.session.mail.smtp.password=
mail.session.mail.smtp.port=25
mail.session.mail.smtp.user=
mail.session.mail.store.protocol=pop3
mail.session.mail.transport.protocol=smtp
\end{verbatim}
\item
  Replace the default mail session values with your own.
\item
  Put the \texttt{portal-ext.properties} file into your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{LIFERAY\_HOME},
  once you've established it based on your installation.
\end{enumerate}

Liferay DXP connects to the mail session on the next startup.

\section{Configuring a Mail Session on the Application
Server}\label{configuring-a-mail-session-on-the-application-server}

You can manage a mail session for Liferay DXP on your application
server. Here's how:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a mail session on your application server, following your
  application server documentation.
\item
  Point Liferay DXP to that mail session using the Control Panel or
  portal properties. Here are instructions for both:

  \begin{itemize}
  \item
    Configure the JNDI name in the \emph{Mail} page at \emph{Control
    Panel → Configuration → Server Administration → Mail}.
  \item
    Set a \texttt{mail.session.jndi.name} portal property in a
    \texttt{{[}LIFERAY\_HOME{]}/portal-ext.properties} file. Here's an
    example property:

\begin{verbatim}
    mail.session.jndi.name=mail/MailSession
\end{verbatim}
  \end{itemize}
\end{enumerate}

Lastly, configure your instance's email senders.

\section{Configuring default email
senders}\label{configuring-default-email-senders}

Email senders are the default name and email address Liferay DXP uses to
send administrative emails and announcement emails.

Default email senders are configured in the
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}
file}.

\begin{itemize}
\item
  Admin email configuration:

\begin{verbatim}
admin.email.from.name=Joe Bloggs
admin.email.from.address=test@domain.invalid
\end{verbatim}
\item
  Announcements email configuration:

\begin{verbatim}
announcements.email.to.name=
announcements.email.to.address=noreply@domain.invalid
\end{verbatim}
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace the names and email addresses above with your values.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} Following emails are blacklisted by default and cannot be
used in any Liferay DXP installation:

\begin{itemize}
\tightlist
\item
  \texttt{noreply@liferay.com}
\item
  \texttt{test@liferay.com}
\item
  \texttt{noreply@domain.invalid}
\item
  \texttt{test@domain.invalid}
\end{itemize}

If you use them, Liferay DXP logs a \texttt{WARN} trace:

\texttt{Email\ xxx\ will\ be\ ignored\ because\ it\ is\ included\ in\ mail.send.blacklist}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Restart your server.
\end{enumerate}

Congratulations on configuring mail for Liferay DXP.

\chapter{Locales and Encoding
Configuration}\label{locales-and-encoding-configuration}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

You can display content based on language, time zone, ``right to left''
(that is, languages such as Hebrew, Arabic, and Persian), and you can
localize user names and titles. Administrators can localize specific
core UI messages so that the messages display in certain languages.

\section{Time Zones}\label{time-zones}

You can set time zones in the Control Panel and theoretically in the JVM
(but this must be set to GMT: see below).

Time zone configuration and default language customization are done in
the Control Panel, at the Instance level.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Navigate to the \emph{Control Panel} → \emph{Configuration}.
\item
  Click \emph{Instance Settings}.
\item
  Click on the \emph{Miscellaneous} tab.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/instance-locales.png}}
\caption{You can change the default and available languages and the time
zone in Instance Settings.}
\end{figure}

The central left and right arrows let you add or remove available
languages and locales. You can also set these as properties in your
\texttt{portal-ext.properties} file in your
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
folder. The \texttt{portal.properties} reference document's
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Company}{Company}
section defines the default locale. The
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Languages\%20and\%20Time\%20Zones}{Languages
and Time Zones} section defines the available and current locales.

\begin{verbatim}
company.default.locale=en_GB 
\end{verbatim}

\noindent\hrulefill

\textbf{Note:} The \texttt{company.default.locale} portal property is
only intended for use on initial startup. To change the language
settings on an existing instance, open the Control Panel and navigate to
\emph{Configuration} → \emph{Instance Settings} and select the
Localization category under the PLATFORM heading. Under the Language
entry you can change the default language, as well as define the current
locales.

\noindent\hrulefill

As an example, the above property changes the locale to English, Great
Britain.

\section{Set the JVM Time Zone to
GMT}\label{set-the-jvm-time-zone-to-gmt}

If you set the time zone in the JVM, it causes issues such as Calendar
Events and Web Content articles displaying the wrong dates. This happens
because the system assumes each date stored in the database is stored in
GMT time. When the system needs to display one stored date to the end
users, the display date is calculated by the application server's
current date. This date is affected by the configured JVM level time
zone and the stored GMT format date. To make sure the display date is
calculated correctly, the time zone must be configured to GMT at the JVM
level. Otherwise, an incorrect time zone offset at the JVM level causes
the display date to be wrongly calculated and displayed.

\section{Friendly URLs and Locales}\label{friendly-urls-and-locales}

In addition to configuring instance settings, you can also define unique
URLs for specific languages using the \texttt{I18nServlet} by editing
Portal's \texttt{web.xml} file:

\begin{verbatim}
<servlet-mapping>
    <servlet-name>I18n Servlet</servlet-name>
    <url-pattern>/ar/*</url-pattern>
</servlet-mapping>
  .
  .
.
<servlet-mapping>
    <servlet-name>I18n Servlet</servlet-name>
    <url-pattern>/de/*</url-pattern>
</servlet-mapping>
\end{verbatim}

The defaults should be sufficient for nearly all circumstances. Because
\texttt{web.xml} changes require stopping and possibly redeploying
Liferay DXP (depending on your app server), test the defaults and make
sure you really need to modify these settings. If you're clustered, you
must make these changes on all nodes.

\section{Modifying Language Keys}\label{modifying-language-keys}

Developers can add or modify certain core UI messages (e.g.~\emph{Your
request completed successfully.}) by
\href{/docs/7-2/customization/-/knowledge_base/c/overriding-language-keys}{modifying
the language keys} that ship by default.

\section{Right to Left}\label{right-to-left}

For languages that are displayed right to left, use the following
language properties settings:

\begin{verbatim}
lang.dir=rtl
lang.line.begin=right
lang.line.end=left
\end{verbatim}

To display right to left by default,
\href{/docs/7-2/customization/-/knowledge_base/c/overriding-global-language-keys}{override
these properties globally}.

\section{Localizing User Names}\label{localizing-user-names}

Users can change the prefix and suffix values for a locale. For example,
for Spanish, the \texttt{language\_es.properties} file contains these
values:

\begin{verbatim}
lang.user.name.field.names=prefix,first-name,last-name
lang.user.name.prefix.values=Sr,Sra,Sta,Dr,Dra
lang.user.name.required.field.names=last-name
\end{verbatim}

For more information, see
\href{/docs/7-2/frameworks/-/knowledge_base/f/using-liferays-localization-settings}{Using
Liferay Language Settings}.

\section{Related Topics}\label{related-topics}

\href{/docs/7-2/frameworks/-/knowledge_base/f/using-liferays-localization-settings}{Using
Liferay Language Settings}

\href{/docs/7-2/customization/-/knowledge_base/c/overriding-global-language-keys}{Overriding
Global Language Keys}

\href{/docs/7-2/customization/-/knowledge_base/c/overriding-a-modules-language-keys}{Overriding
a Module's Language Keys}

\chapter{Liferay DXP Clustering}\label{liferay-dxp-clustering}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay DXP can serve everything from the smallest to the largest web
sites. Out of the box, it's configured optimally for a single server
environment. If one server isn't sufficient to serve your site's high
traffic needs, Liferay DXP scales to the size you need.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/clustering-enterprise-configuration.png}}
\caption{Liferay DXP is designed to scale to as large an installation as
you need.}
\end{figure}

Liferay DXP works well in clusters of multiple machines (horizontal
cluster) or in clusters of multiple VMs on a single machine (vertical
cluster), or any mixture of the two. Once you have Liferay DXP installed
on more than one application server node, there are several
optimizations that must be made. At a minimum, Liferay DXP should be
configured in the following way for a clustered environment:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/point-all-nodes-to-the-same-database}{All
  nodes should point to the same database or database cluster.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/configure-documents-and-media-the-same-for-all-nodes}{Documents
  and Media repositories must have the same configuration and be
  accessible to all nodes of the cluster.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/clustering-search}{Search
  should be on a separate search server that is optionally clustered.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/enabling-cluster-link}{Cluster
  Link must be enabled so the cache replicates across all nodes of the
  cluster.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/auto-deploy-to-all-nodes}{Applications
  must be auto-deployed to each node individually.}
\end{enumerate}

Many of these configuration changes can be made by adding or modifying
properties in your \texttt{portal-ext.properties} file. Remember that
this file overrides the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html}{defaults}
in the \texttt{portal.properties} file. It's a best practice to copy the
relevant section you want to modify from \texttt{portal.properties} into
your \texttt{portal-ext.properties} file, and then modify the values
there.

\noindent\hrulefill

\textbf{Note:} This documentation describes a Liferay DXP-specific
cluster configuration without getting into specific implementations of
third party software, such as Java EE application servers, HTTP servers,
and load balancers. Please consult your documentation for those
components of your cluster to configure those components. Before
creating a Liferay DXP cluster, make sure your OS is not defining the
hostname of your box to the local network at 127.0.0.1.

\noindent\hrulefill

Each step defined above is covered below to give you a step by step
process for creating your cluster. Start with making all Nodes point to
the same database.

\chapter{Point all Nodes to the Same Liferay DXP
Database}\label{point-all-nodes-to-the-same-liferay-dxp-database}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Each node should have a data source that points to one Liferay DXP
database (or a database cluster) that all the nodes share. This means,
of course, Liferay DXP cannot (and should not) use the embedded HSQL
database that is shipped with the bundles (but you already knew that,
right?). And, of course, the database server should be on a separate
system from the Liferay DXP server.

\section{Read-Writer Database
Configuration}\label{read-writer-database-configuration}

To improve database performance, you can use a read-writer database
configuration. Instead of using the same data source for read and
read-write operations, this strategy uses a separate data source for
each operation type. DXP's Aspect Oriented Programming (AOP) transaction
infrastructure directs read transactions to the read data source and
read-write transactions to the write data source.

Connections to separate read and read-write
\href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#JDBC}{data
sources} are configured using JDBC or JNDI
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{Portal
Properties} (e.g., in a
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}
file}), as explained in the following sections. The data sources should
use separate instances of the DXP database, where the read-write
database instance is replicated to the read database instance.

\section{JDBC}\label{jdbc}

Edit your \texttt{portal-ext.properties} file following these steps to
connect directly to your separate read and write data sources using
\href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{JDBC}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Set the default connection pool provider. For provider information,
  see the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#JDBC}{JDBC
  properties reference}. The default setting specifies
  \href{https://github.com/brettwooldridge/HikariCP}{HikariCP} as the
  pool provider:

\begin{verbatim}
jdbc.default.liferay.pool.provider=hikaricp
\end{verbatim}
\item
  Configure JDBC connections to your separate read and write data
  sources. Here's an example:

\begin{verbatim}
jdbc.read.driverClassName=[place your driver name here]
jdbc.read.url=[place the URL to your "read" database here]
jdbc.read.username=[place your user name here]
jdbc.read.password=[place your password here]

jdbc.write.driverClassName=[place your driver name here]
jdbc.write.url=[place the URL to your "read-write" database here]
jdbc.write.username=[place your user name here]
jdbc.write.password=[place your password here]
\end{verbatim}

  For example JDBC connection values, please see
  \href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
  Templates}.
\item
  Configure DXP to use the write data source (the data source whose
  prefix is \texttt{jdbc.write.}) to create the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Counter}{Counter}
  data source. A separate data source is always dedicated to the
  counter.

\begin{verbatim}
counter.jdbc.prefix=jdbc.write.
\end{verbatim}
\item
  Optionally validate the data connections to make sure bad connections
  are handled gracefully.

  Some connection pools used with JDBC4 (check your driver's JDBC
  version) validate connections automatically. Other connection pools
  may require additional, vendor-specific connection validation
  properties---specify them in a Portal Properties file. Refer to your
  connection pool provider documentation for connection validation
  details.
\item
  Enable the read-writer database configuration by copying the default
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Spring}{\texttt{spring.configs}
  and \texttt{spring.infrastructure.configs} Portal Properties} to your
  \texttt{portal-ext.properties} file and adding the following Spring
  configuration file paths to them.

  Add to \texttt{spring.configs}:

\begin{verbatim}
META-INF/dynamic-data-source-spring.xml
\end{verbatim}

  Add to \texttt{spring.infrastructure.configs}:

\begin{verbatim}
META-INF/dynamic-data-source-infrastructure-spring.xml
\end{verbatim}

  For more information, see the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Spring}{Spring
  configuration Portal Properties}.
\end{enumerate}

\section{JNDI}\label{jndi}

Edit your \texttt{portal-ext.properties} file following these steps to
connect to your read and write data sources on your app server using
JNDI:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Set your read and write JNDI data source user names and passwords.

\begin{verbatim}
jdbc.read.jndi.name=[place your "read" data source JNDI name here]

jdbc.read.username=*[place your user name here]
jdbc.read.password=[place your password here]

jdbc.write.jndi.name=[place your "read-write" data source JNDI name here]

jdbc.write.username=[place your user name here]
jdbc.write.password=[place your password here]
\end{verbatim}
\item
  Configure DXP to use the write data source (the data source whose
  prefix is \texttt{jdbc.write.}) to create the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Counter}{Counter}
  data source. A separate data source is always dedicated to the
  counter.

\begin{verbatim}
counter.jdbc.prefix=jdbc.write.
\end{verbatim}
\item
  Optionally validate the data connections to make sure bad connections
  are handled gracefully.

  Some connection pools used with JDBC4 (check your driver's JDBC
  version) validate connections automatically. Other connection pools
  may require additional, vendor-specific connection validation
  properties---specify them in a Portal Properties file. Refer to your
  connection pool provider documentation for connection validation
  details.
\item
  Enable the read-writer database configuration by copying the default
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Spring}{\texttt{spring.configs}
  and \texttt{spring.infrastructure.configs} Portal Properties} to your
  \texttt{portal-ext.properties} file and add the following Spring
  configuration file paths to them.

  Add to \texttt{spring.configs}:

\begin{verbatim}
META-INF/dynamic-data-source-spring.xml
\end{verbatim}

  Add to \texttt{spring.infrastructure.configs}:

\begin{verbatim}
META-INF/dynamic-data-source-infrastructure-spring.xml
\end{verbatim}

  For more information, see the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Spring}{Spring
  configuration Portal Properties}.
\end{enumerate}

DXP uses a read data source, a write data source, and a counter data
source the next time it starts.

\chapter{Configure Documents and Media the Same for all
Nodes}\label{configure-documents-and-media-the-same-for-all-nodes}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

In a cluster, Documents and Media must use the same
\href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{document
repository configuration} on all nodes.

Note if you are using the \texttt{File\ System} or
\texttt{Advanced\ File\ System} stores, the file system must be
accessible from all nodes (i.e., a network share), support concurrent
requests, and file locking.

\textbf{Checkpoint}: Verify sharing works by executing these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  On Node 1 upload a document to the Documents and Media.
\item
  On Node 2 download the document. The download should be successful.
\item
  Repeat the test with reversed roles.
\end{enumerate}

\chapter{Clustering Search}\label{clustering-search}

Search should always run on a separate environment from your Liferay DXP
server. Liferay DXP supports
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{Elasticsearch},
and \href{/docs/7-2/deploy/-/knowledge_base/d/installing-solr}{Solr}.
Both can also be clustered.

For more information on how to cluster Elasticsearch, see
\href{https://www.elastic.co/guide/en/elasticsearch/guide/current/distributed-cluster.html}{Elasticsearch's
distributed cluster setup}.

Once Liferay DXP servers have been properly configured as a cluster and
the same for Elasticsearch, change Liferay DXP from \emph{embedded} mode
to \emph{remote} mode. On the first connection, the two sets of
clustered servers communicate with each other the list of all IP
addresses; in case of a node going down, the proper failover protocols
enable. Queries and indexes can continue to be sent for all nodes.

For more information on how to cluster Solr, see
\href{https://cwiki.apache.org/confluence/display/solr/SolrCloud}{Apache
Solr Cloud} documentation.

Once Liferay DXP servers have been properly configured as a cluster,
deploy the Liferay Connector to Solr on all nodes. (This app is
available for download from Liferay Marketplace) Create a Solr Cloud
(cluster) managed by \emph{Apache Solr Zookeeper}. Connect the Liferay
DXP cluster to Zookeeper and finish the final configurations to connect
the two clusters.

\chapter{Enabling Cluster Link}\label{enabling-cluster-link}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Enabling Cluster Link automatically activates distributed caching. The
cache is distributed across multiple Liferay DXP nodes running
concurrently. Cluster Link does \href{http://www.ehcache.org}{Ehcache}
replication. The Ehcache global settings are in the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Ehcache}{\texttt{portal.properties}
file}.

By default Liferay does not copy cached entities between nodes. If an
entity is deleted or changed, for example, Cluster Link sends a
\emph{remove} message to the other nodes to invalidate this entity in
their local caches. Requesting that entity on another node results in a
cache \emph{miss}; the entity is then retrieved from the database and
put into the local cache. Entities added to one node's local cache are
not copied to local caches of the other nodes. An attempt to retrieve a
new entity on a node which doesn't have that entity cached results in a
cache \emph{miss}. The miss triggers the node to retrieve the entity
from the database and store it in its local cache.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/clustering-cache-efficient-algorithm.png}}
\caption{Liferay DXP's cache algorithm is extremely efficient.}
\end{figure}

Here are the Cluster Link topics:

\begin{itemize}
\tightlist
\item
  \hyperref[enabling-cluster-link]{Enabling Cluster Link}
\item
  \hyperref[multicast-over-udp]{Multicast Over UDP}
\item
  \hyperref[unicast-over-tcp]{Unicast Over TCP}
\item
  \hyperref[using-different-control-and-transport-channel-ports]{Using
  Different Control and Transport Channel Ports}
\item
  \hyperref[modifying-the-cache-configuration-with-a-module]{Modifying
  the Cache Configuration with a Module}
\item
  \hyperref[conclusion]{Conclusion}
\end{itemize}

\section{Enabling Cluster Link}\label{enabling-cluster-link-1}

To enable Cluster Link, add this
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{portal
property} to a \texttt{portal-ext.properties} file:

\begin{verbatim}
cluster.link.enabled=true
\end{verbatim}

The
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Cluster\%20Link}{Cluster
Link portal properties} provide a default configuration that you can
override to fit your needs.

Many of the defaults use \texttt{localhost}, instead of a real address.
In some configurations, however, \texttt{localhost} is bound to the
internal loopback network (\texttt{127.0.0.1} or \texttt{::1}), rather
than the host's real address. If for some reason you need this
configuration, you can make DXP auto detect the real address with this
property:

\begin{verbatim}
cluster.link.autodetect.address=www.google.com:80
\end{verbatim}

Set it to connect to some other host that's contactable by your server.
By default, it points to Google, but this may not work if your server is
behind a firewall. If you use each host's real address, you don't need
to set the auto-detect address.

Cluster Link depends on \href{http://www.jgroups.org}{JGroups} and
provides an API for nodes to communicate. It can

\begin{itemize}
\tightlist
\item
  Send messages to all nodes in a cluster
\item
  Send messages to a specific node
\item
  Invoke methods and retrieve values from all, some, or specific nodes
\item
  Detect membership and notify when nodes join or leave
\end{itemize}

Cluster Link contains an enhanced algorithm that provides one-to-many
type communication between the nodes. This is implemented by default
with JGroups's UDP multicast, but unicast and TCP are also available.

\section{Multicast Over UDP}\label{multicast-over-udp}

When you enable Cluster Link, Liferay DXP's default clustering
configuration is enabled. This configuration defines IP multicast over
UDP. Liferay DXP uses two groups of
\href{http://www.jgroups.org/manual4/index.html\#_channel}{channels from
JGroups} to implement this: a control group and a transport group. If
you want to customize the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Cluster\%20Link}{channel
properties}, you can do so in \texttt{portal-ext.properties}:

\begin{verbatim}
cluster.link.channel.name.control=[your control channel name]
cluster.link.channel.properties.control=[your control channel properties]
\end{verbatim}

Please see
\href{http://www.jgroups.org/manual4/index.html\#protlist}{JGroups's
documentation} for channel properties. The default configuration sets
many properties whose settings are discussed there.

Multicast broadcasts to all devices on the network. Clustered
environments on the same network communicate with each other by default.
Messages and information (e.g., scheduled tasks) sent between them can
lead to unintended consequences. Isolate such cluster environments by
either separating them logically or physically on the network, or by
configuring each cluster's \texttt{portal-ext.properties} to use
different sets of
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Multicast}{multicast
group address and port values}.

JGroups sets a bind address automatically. If you want to set a manual
address, you can do this. By default, these are set to
\texttt{localhost}:

\begin{verbatim}
cluster.link.bind.addr["cluster-link-control"]=localhost
cluster.link.bind.addr["cluster-link-udp"]=localhost
\end{verbatim}

In some configurations, however, \texttt{localhost} is bound to the
internal loopback network (\texttt{127.0.0.1} or \texttt{::1}), rather
than the host's real address. If for some reason you need this
configuration, you can make Liferay DXP auto detect its real address
with this property:

\begin{verbatim}
cluster.link.autodetect.address=www.google.com:80
\end{verbatim}

Set it to connect to some other host that's contactable by your server.
By default, it points to Google, but this may not work if your server is
behind a firewall. If you set the address manually using the properties
above, you don't need to set the auto-detect address.

Your network configuration may preclude the use of multicast over TCP,
so below are some other ways you can get your cluster communicating.
Note that these methods are all provided by JGroups.

\section{Checkpoint:}\label{checkpoint}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If you are binding the IP address instead of using \texttt{localhost},
  make sure the right IP addresses are declared using these properties:

\begin{verbatim}
cluster.link.bind.addr["cluster-link-control"]=localhost
cluster.link.bind.addr["cluster-link-udp"]=localhost
\end{verbatim}
\item
  Test your load and then optimize your settings if necessary.
\end{enumerate}

\section{Unicast over TCP}\label{unicast-over-tcp}

If your network configuration or the geographical distance between nodes
prevents you from using UDP Multicast clustering, you can configure TCP
Unicast. You must use this if you have a firewall separating any of your
nodes or if your nodes are in different geographical locations.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add a parameter to your app server's JVM on each node:

\begin{verbatim}
-Djgroups.bind_addr=[node_ip_address]
\end{verbatim}

  Use the node's IP address.
\item
  Select a discovery protocol for the nodes to use to find each other.
  Here are the protocol choices:

  \begin{itemize}
  \tightlist
  \item
    TCPPing
  \item
    JDBCPing
  \item
    S3\_Ping
  \item
    Rackspace\_Ping
  \end{itemize}

  If you aren't sure which one to choose, use TCPPing. The rest of these
  steps use TCPPing
\item
  Extract the \texttt{tcp.xml} file from
  \texttt{\$LIFERAY.HOME/osgi/marketplace/Liferay\ Foundation\ -\ Liferay\ Portal\ -\ Impl.lpkg/com\hspace{0pt}.\hspace{0pt}liferay\hspace{0pt}.\hspace{0pt}portal\hspace{0pt}.\hspace{0pt}cluster\hspace{0pt}.\hspace{0pt}multiple\hspace{0pt}-\hspace{0pt}{[}version{]}.\hspace{0pt}jar/lib\hspace{0pt}/\hspace{0pt}jgroups\hspace{0pt}-\hspace{0pt}{[}version{]}.\hspace{0pt}Final\hspace{0pt}.\hspace{0pt}jar/tcp.xml}
  to a location accessible to DXP, such as a folder called
  \texttt{jgroups} in the DXP web application's \texttt{WEB-INF/classes}
  folder.

\begin{verbatim}
WEB-INF/classes/jgroups/tcp.xml
\end{verbatim}
\item
  In the \texttt{tcp.xml} file, set the TCP bind port to an unused port
  on your node. Here's an example:

\begin{verbatim}
<TCP bind_port="7800"/>
\end{verbatim}
\item
  In the \texttt{tcp.xml} file, make each node discoverable to TCPPing
  by specifying its IP address and an unused port on that node. Building
  off of the previous step, here's an example
  \texttt{\textless{}TCPPing\textgreater{}} element:

\begin{verbatim}
<TCP bind_port="7800"/>
<TCPPING async_discovery="true"
    initial_hosts="192.168.224.154[7800],192.168.224.155[7800]"
    port_range="0"/>
\end{verbatim}

  \textbf{Regarding Initial Hosts:}

  \begin{itemize}
  \tightlist
  \item
    An alternative to specifying initial hosts in a TCP XML file is to
    specify them to your app server using a JVM argument like this:
    \texttt{-Djgroups.tcpping.initial\_hosts=192.168.224.154{[}7800{]},192.168.224.155{[}7800{]}}.
  \item
    Make sure the initial hosts value accounts for all your nodes. If
    \texttt{initial\_hosts} is not specified in a TCP XML file or in a
    JVM argument, \texttt{localhost} is the initial host.
  \end{itemize}
\item
  Copy your \texttt{tcp.xml} file to each node, making sure to set the
  TCP bind port to the node's bind port. On the node with IP address
  \texttt{192.168.224.155}, for example, configure TCPPing like this:

\begin{verbatim}
<TCP bind_port="7800"/>
<TCPPING async_discovery="true"
    initial_hosts="192.168.224.154[7800],192.168.224.155[7800]"
    port_range="0"/>
\end{verbatim}
\item
  Modify the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Cluster\%20Link}{Cluster
  Link properties} in the node's \texttt{portal-ext.properties} file to
  enable Cluster Link and point to the TCP XML file for each Cluster
  Link channel:
\end{enumerate}

\begin{verbatim}
cluster.link.enabled=true
cluster.link.channel.properties.control=/jgroups/tcp.xml
cluster.link.channel.properties.transport.0=/jgroups/tcp.xml
\end{verbatim}

The JGroups configuration demonstrated above is typically all that
Unicast over TCP requires. However, in a very specific case, if
\emph{(and only if)} cluster nodes are deployed across multiple
networks, then the parameter \texttt{external\_addr} must be set on each
host to the external (public IP) address of the firewall. This kind of
configuration is usually only necessary when nodes are geographically
separated. By setting this, clustered nodes deployed to separate
networks (e.g.~separated by different firewalls) can communicate
together. This configuration may be flagged in security audits of your
system. See
\href{http://www.jgroups.org/manual4/index.html\#_transport_protocols}{JGroups
documentation} for more information.

\begin{quote}
\textbf{Note:} The \texttt{singleton\_name} TCP attribute was deprecated
in JGroups v4.0.0 and has therefore been removed since Liferay DXP 7.2
SP1 and Liferay Portal CE GA2 which use JGroups v 4.1.1-Final.
\end{quote}

You're now set up for Unicast over TCP clustering! Repeat either TCPPING
process for each node you want to add to the cluster.

\section{JDBC Ping}\label{jdbc-ping}

Rather than use TCP Ping to discover cluster members, you can use a
central database accessible by all the nodes to help them find each
other. Cluster members write their own and read the other members'
addresses from this database. To enable this configuration, replace the
\texttt{TCPPING} tag with the corresponding \texttt{JDBC\_PING} tag:

\begin{verbatim}
<JDBC_PING
    connection_url="[place the URL to your database here]"
    connection_username="[place your user name here]"
    connection_password="[place your password here]"
    connection_driver="[place your driver name here]"/>
\end{verbatim}

For example JDBC connection values, please see
\href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
Templates}. For further information about JDBC Ping, please see the
\href{http://www.jgroups.org/manual4/index.html\#DiscoveryProtocols}{JGroups
Documentation}.

\section{S3 Ping}\label{s3-ping}

Amazon S3 Ping can be used for servers running on Amazon's EC2 cloud
service. Each node uploads a small file to an S3 bucket, and all the
other nodes read the files from this bucket to discover the other nodes.
When a node leaves, its file is deleted.

To configure S3 Ping, replace the \texttt{TCPPING} tag with the
corresponding \texttt{S3\_PING} tag:

\begin{verbatim}
<S3_PING
    secret_access_key="[SECRETKEY]"
    access_key="[ACCESSKEY]"
    location="ControlBucket"/>
\end{verbatim}

Supply your Amazon keys as values for the parameters above. For further
information about S3 Ping, please see the
\href{http://www.jgroups.org/manual4/index.html\#_s3_ping}{JGroups
Documentation}.

\section{Other Pings}\label{other-pings}

JGroups supplies other means for cluster members to discover each other,
including Rackspace Ping, BPing, File Ping, and others. Please see the
\href{http://www.jgroups.org/manual4/index.html\#DiscoveryProtocols}{JGroups
Documentation} for information about these discovery methods.

The control and transport channels can be configured to use different
ports.

\section{Using Different Control and Transport Channel
Ports}\label{using-different-control-and-transport-channel-ports}

Using separate control and transport channel ports lets you monitor
control and transport traffic and helps you isolate information to
diagnose problems. These steps use Unicast over TCPPing to demonstrate
the approach.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add a parameter to your app server's JVM on each node:

\begin{verbatim}
-Djgroups.bind_addr=[node_ip_address]
\end{verbatim}
\item
  Extract the \texttt{tcp.xml} file from
  \texttt{\$LIFERAY.HOME/osgi/marketplace/Liferay\ Foundation\ -\ Liferay\ Portal\ -\ Impl.lpkg/com\hspace{0pt}.\hspace{0pt}liferay\hspace{0pt}.\hspace{0pt}portal\hspace{0pt}.\hspace{0pt}cluster\hspace{0pt}.\hspace{0pt}multiple\hspace{0pt}-\hspace{0pt}{[}version{]}.\hspace{0pt}jar/lib\hspace{0pt}/\hspace{0pt}jgroups\hspace{0pt}-\hspace{0pt}{[}version{]}.\hspace{0pt}Final\hspace{0pt}.\hspace{0pt}jar/tcp.xml}
  to a location accessible to DXP, such as a folder called
  \texttt{jgroups} in the DXP web application's \texttt{WEB-INF/classes}
  folder.
\item
  Make a copy of the \texttt{tcp.xml} in the same location and rename
  both files, designating one for the control channel and the other for
  the transport channel. For example, you could use these file names:

  \begin{itemize}
  \item
    \texttt{tcp-control.xml}
  \item
    \texttt{tcp-transport.xml}
  \end{itemize}
\item
  Modify the
  \href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#Cluster\%20Link}{Cluster
  Link properties} in the node's \texttt{portal-ext.properties} file to
  enable Cluster Link and point to the TCP XML file for each Cluster
  Link channel:

\begin{verbatim}
cluster.link.enabled=true
cluster.link.channel.properties.control=/jgroups/tcp-control.xml
cluster.link.channel.properties.transport.0=/jgroups/tcp-transport.xml
\end{verbatim}
\item
  Modify each \texttt{tcp-*.xml} file's the TCP and TCPPing elements to
  account for each node's IP address and bind port.

  If you're vertically clustering (i.e., you have multiple servers
  running on the same physical or virtual system), every channel must
  use a unique unused bind port for discovery communication. In each
  \texttt{tcp-*.xml} file, assign the TCP tag's \texttt{bind\_port}
  attribute to a unique, unused port.

  For example, your first two nodes might assign these bind ports:
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 Node   | Properties File     | Port   |
 :----- | :------------------ | :----- |
 Node 1 | `tcp-control.xml`   | `7800` |
 Node 1 | `tcp-transport.xml` | `7801` |
 Node 2 | `tcp-control.xml`   | `7802` |
 Node 2 | `tcp-transport.xml` | `7803` |
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
Here are example TCP and TCPPing elements using the bind ports on nodes running on the same system (i.e., same IP address):

**Node 1 `tcp-control.xml`**

```xml
<TCP bind_port="7800"/>
<TCPPING async_discovery="true"
    initial_hosts="192.168.224.154[7800],192.168.224.154[7802]"
    port_range="0"/>
```

**Node 1 `tcp-transport.xml`**

```xml
<TCP bind_port="7801"/>
<TCPPING async_discovery="true"
    initial_hosts="192.168.224.154[7801],192.168.224.154[7803]"
    port_range="0"/>
```

**Node 2 `tcp-control.xml`**

```xml
<TCP bind_port="7802"/>
<TCPPING async_discovery="true"
    initial_hosts="192.168.224.154[7800],192.168.224.154[7802]"
    port_range="0"/>
```

**Node 2 `tcp-transport.xml`**

```xml
<TCP bind_port="7803"/>
<TCPPING async_discovery="true"
    initial_hosts="192.168.224.154[7801],192.168.224.154[7803]"
    port_range="0"/>
```
\end{verbatim}

If you have added entities that can be cached or you want to tune the
cache configuration for your system, you can do so using a module.

\section{Modifying the Cache Configuration with a
Module}\label{modifying-the-cache-configuration-with-a-module}

It's recommended to test your system under a load that best simulates
the kind of traffic your system must handle. If you serve a lot of
message board messages, your script should reflect that. If web content
is the core of your site, your script should reflect that too.

As a result of a load test, you may find that the default distributed
cache settings aren't optimized for your site. In this case, tweak the
settings using a module. Follow instructions for
\href{/docs/7-2/frameworks/-/knowledge_base/f/overriding-cache}{Overriding
Cache}.

You can install the module on each node and change the settings without
taking down the cluster. This is a great benefit, but beware: since
Ehcache doesn't allow for changes to cache settings while the cache is
alive, reconfiguring a cache while the server is running flushes the
cache.

\section{Conclusion}\label{conclusion}

Once you've configured your cluster, you can start it. A log file
message shows your cluster's name (e.g.,
\texttt{cluster=liferay-channel-control}):

\begin{verbatim}
GMS: address=oz-52865, cluster=liferay-channel-control, physical address=192.168.1.10:50643
\end{verbatim}

Congratulations! Your cluster is using Cluster Link.

\chapter{Auto Deploy to All Nodes}\label{auto-deploy-to-all-nodes}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

All modules and WAR files you deploy onto the cluster must be deployed
to all cluster nodes. Because Liferay DXP
\href{/docs/7-2/customization/-/knowledge_base/c/deploying-wars-wab-generator}{installs
applications as OSGi bundles}, you cannot rely on your application
server's means of installing WAR files (even if you only intend to
install WAR files) to deploy an application to the entire cluster.
Instead, place the application in each node's auto deploy folder (e.g.,
\texttt{{[}Liferay\ Home{]}/deploy}).

This, as you might imagine, can be done with a script. Write a shell
script that uploads applications to each node using sftp or some other
service. This way, when you deploy an application, it uploads to each
node's auto deploy folder and installs to Liferay DXP on each node.

\chapter{Updating a Cluster}\label{updating-a-cluster}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Maintaining a
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{cluster}
is a big responsibility. It includes deploying new and updated plugins
and modules, applying
\href{/docs/7-2/deploy/-/knowledge_base/d/maintaining-liferay}{fix
packs}, making configuration changes, and more. Maximizing server uptime
and minimizing risks take priority when applying changes. Liferay DXP
supports using standard cluster maintenance techniques.

\begin{itemize}
\tightlist
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/using-rolling-restarts}{Rolling
  restarts}: Nodes are shut down and updated one at a time.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/other-cluster-update-techniques}{Blue-green
  deployment}: Blue-green involves duplicating the current environment
  (\emph{blue} environment), updating the duplicate (\emph{green}
  environment), and cutting over users to the updated environment
  (green).
\end{itemize}

The techniques are compared below.

\textbf{Cluster Update Techniques}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4762}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3810}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
~Rolling Restart
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
~Blue-green
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Plugin/module installation & Supported & Supported \\
Plugin/module update (backward-compatible data/schema changes) &
Supported & Supported \\
Plugin/module update (non-backward-compatible data/schema changes)
\hyperref[one]{1} & Not supported & Supported \\
Fix pack installation and removal (revertable fix pack) & Supported &
Supported \\
Fix pack installation (non-revertible fix pack) & Not supported &
Supported \\
Cluster code changes \hyperref[two]{2} & Not supported & Supported \\
Portal property changes & Supported & Supported \\
System Setting changes via configuration admin files & Supported &
Supported \\
Application server updates & Supported & Supported \\
JVM setting changes & Supported & Supported \\
New Java version (minor) & Supported & Supported \\
New Java version (major) & Not supported & Supported \\
\end{longtable}

\noindent\hrulefill

{[}1{]} Data and data schema changes that are not backward-compatible
include, but are not limited to these:

\begin{itemize}
\tightlist
\item
  Modifying data in existing columns
\item
  Dropping columns
\item
  Changing column types
\item
  Changing data formats used in columns (such as changing from XML to
  JSON)
\item
  Updating a Service Builder service module's data schema to a version
  outside of the module's required data schema range. A module's
  \texttt{Liferay-Require-SchemaVersion} (specified in its
  \texttt{bnd.bnd}) must match the module's schema version value in the
  \texttt{Release\_} table. Installing a module with a new schema
  version updates the \texttt{Release\_} table with that schema version
  and triggers a data upgrade process. If you install such a module on
  one node, the schema version in the \texttt{Release\_} table no longer
  matches the \texttt{Liferay-Require-SchemaVersion} of the modules on
  the other nodes, and the module's Service Builder services become
  unavailable until the module is installed on the other nodes. Such
  changes cannot be reverted: the database must be restored from a
  backup. These schema version changes must be applied while all nodes
  are shut down.
\end{itemize}

{[}2{]} Cluster communication must stay intact. For this reason, cluster
code must not be updated in rolling restarts. The Customer Portal
identifies DXP fix packs that contain such changes as non-revertible.
Here are packages you must not change in rolling restarts:

\begin{itemize}
\tightlist
\item
  \texttt{com.liferay.portal.kernel.cluster}
\item
  \texttt{com.liferay.portal.kernel.cluster.*}
\item
  \texttt{com.liferay.portal.kernel.exception.NoSuchClusterGroupException}
\item
  \texttt{com.liferay.portal.kernel.scheduler.multiple}
\item
  \texttt{com.liferay.portal.kernel.scheduler.multiple.*}
\item
  \texttt{com.liferay.portal.cache.multiple}
\item
  \texttt{com.liferay.portal.cache.multiple.*}
\item
  \texttt{com.liferay.portal.scheduler.multiple}
\item
  \texttt{com.liferay.portal.scheduler.multiple.*}
\end{itemize}

Since eligible changes should be done with rolling restarts, it's
explained first.

\chapter{Rolling Restarts}\label{rolling-restarts}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The rolling restart cluster maintenance process involves shutting down
and updating nodes one at a time (while the other nodes are running)
until they're all updated. It maximizes uptime while you update your
cluster. Rolling restarts can be used in container and image based
environments.

\noindent\hrulefill

\textbf{Note:} Rolling restart does not include concepts for blue-green
(separate, but identical environments) architectures, as these concepts
specifically address multi-cluster style developments.

\noindent\hrulefill

Here are the rolling restart steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Shut down one cluster node (JVM instance).
\item
  Update/modify the deployment for that node (see the maintenance
  scenarios that follow).
\item
  Start the node.
\item
  Repeat these steps for all other cluster nodes.
\end{enumerate}

Maintenance scenarios vary in how they behave in rolling restarts. For
example, UI changes in a plugin update are only visible on the updated
nodes. Users on nodes that haven't been updated don't see the UI
changes. Maintenance scenarios might have specific cases that cannot be
performed in rolling restarts---the scenario descriptions mention these
cases.

The maintenance scenarios eligible for rolling restart are described
below.

\section{New Modules and Plugins}\label{new-modules-and-plugins}

For a new plugin or module (one that does not already exist in the
cluster) to be eligible for rolling restart it must not modify data, or
delete or rename database columns in a way that breaks compatibility
with existing plugins or modules.

\section{Updating Existing Modules and
Plugins}\label{updating-existing-modules-and-plugins}

For a new version of an existing plugin or module to be eligible for
rolling restart, it must not modify data or delete or rename database
columns in a way that breaks compatibility with the existing version of
the plugin or module.

\section{Applying Fix Packs (DXP
only)}\label{applying-fix-packs-dxp-only}

The Customer Portal identifies
\href{/docs/7-2/deploy/-/knowledge_base/d/maintaining-liferay}{fix
packs} that are not revertible, and therefore ineligible for rolling
restart. All other fix packs are eligible.

\section{Reverting Fix Packs (DXP
only)}\label{reverting-fix-packs-dxp-only}

Revertible fix packs can be removed in rolling restarts.

\section{\texorpdfstring{Portal Properties controlled by
\texttt{portal-ext.properties}}{Portal Properties controlled by portal-ext.properties}}\label{portal-properties-controlled-by-portal-ext.properties}

\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html}{Portal
Properties} file changes can be applied in rolling restarts.

\section{System Settings controlled by Configuration Admin
Files}\label{system-settings-controlled-by-configuration-admin-files}

\href{/docs/7-2/user/-/knowledge_base/u/understanding-system-configuration-files}{System
configuration} files can be applied in rolling restarts.

\section{Application Server or JVM setting
modifications}\label{application-server-or-jvm-setting-modifications}

Modifications to application server and JVM settings can be done in
rolling restarts.

\section{Java Version Updates}\label{java-version-updates}

Minor version updates of Java can be applied in rolling restarts. Major
version updates are not supported in rolling restarts, and should
instead be done when all cluster nodes are shut down.

All rolling restart eligible updates can be applied using the rolling
restart steps listed earlier. Other updates must be done differently as
described next.

\section{Related Topics}\label{related-topics-1}

\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{Liferay
DXP Clustering}

\href{/docs/7-2/deploy/-/knowledge_base/d/maintaining-liferay}{Maintaining
Liferay DXP}

\chapter{Blue-Green Deployment}\label{blue-green-deployment}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Blue-green is a deployment technique in which you duplicate your
production environment (the \emph{blue} environment) and modify the
duplicate (the \emph{green} environment) with software and data changes.
When you've successfully tested the green environment, you cut users
over from the blue environment to the green environment. Blue-green
eliminates system down time.

Data schema and data changes require special attention. Custom
plugin/module data schema changes that break compatibility with existing
code must be introduced over several releases in which the data is
transitioned and maintained in old and new columns until the old columns
are unnecessary.

Data and schema changes require these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a new column.
\item
  Copy the data to the new column.
\item
  Maintain both columns until the old column is no longer used by any
  cluster nodes.
\item
  Delete the column in the next release.
\end{enumerate}

For more information, refer to these blue-green deployment articles:

\begin{itemize}
\item
  \href{http://martinfowler.com/bliki/BlueGreenDeployment.html}{BlueGreenDeployment}
\item
  \href{https://www.thoughtworks.com/insights/blog/implementing-blue-green-deployments-aws}{Implementing
  Blue-Green Deployments with AWS}
\end{itemize}

\section{Related Topics}\label{related-topics-2}

\href{/docs/7-2/deploy/-/knowledge_base/d/using-rolling-restarts}{Rolling
Restarts}

\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{Liferay
DXP Clustering}

\href{/docs/7-2/deploy/-/knowledge_base/d/maintaining-liferay}{Maintaining
Liferay DXP}

\chapter{Configuring Remote Staging in a Clustered
Environment}\label{configuring-remote-staging-in-a-clustered-environment}

If you're running Liferay DXP as a
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{clustered
environment} and you want to use remote staging, you must configure it
properly for a seamless experience. In this tutorial, you'll learn how
to set up remote staging in an example clustered environment scenario.
The example environment assumes you have

\begin{itemize}
\tightlist
\item
  a Staging instance with database configurations and a file repository
  different from the cluster nodes.
\item
  a balancer responsible for managing the traffic flow between the
  cluster's nodes.
\item
  two nodes that call two Liferay app servers (e.g., \emph{App Server 1}
  and \emph{App Server 2}), both of which are connected to the same
  database.
\end{itemize}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/remote-staging-clustering.png}}
\caption{This is the assumed setup for your clustered environment.}
\end{figure}

The steps below also assume your web tier, application tier, and cluster
environment are already configured. You may need to adjust the
configurations in this tutorial to work with your specific
configuration.

Let's begin!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  You must secure the communication made between your nodes and Staging
  server. Add the following property to both app servers' and Staging
  server's \texttt{portal-ext.properties} file:

\begin{verbatim}
tunneling.servlet.shared.secret=[secret]
\end{verbatim}

  This secret key denies other portals access to your configured portal
  servers. If you'd like to set your secret key using hexadecimal
  encoding, also set the following property in your
  \texttt{portal-ext.properties} files:

\begin{verbatim}
tunneling.servlet.shared.secret.hex=true
\end{verbatim}
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** The following key lengths are supported by the available
 encryption algorithms:
 
 - *AES:* 128, 192, and 256-bit keys
 - *Blowfish:* 32-448 bit keys
 - *DESede (Triple DES):* 56, 112, or 168 bit keys (Liferay places an
   artificial limit on the minimum key length and does not support the 56-bit
   key length)
 
 For example, you can use [OpenSSL](https://www.openssl.org/) to generate a
 128-bit AES key:
 
     openssl enc -aes-128-cbc -k abc123 -P -md sha1
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  You must allow the connection between the configured IPs of your app
  servers and the Staging server. Open your remote Liferay server's
  \texttt{portal-ext.properties} file and add the following properties:

\begin{verbatim}
tunnel.servlet.hosts.allowed=127.0.0.1,SERVER_IP,[STAGING_IP]
tunnel.servlet.https.required=false
\end{verbatim}

  The \texttt{{[}STAGING\_IP{]}} variable must be replaced by the
  staging server's IP addresses. The \texttt{SERVER\_IP} constant can
  remain set for this property; it's automatically replaced by the
  Liferay server's IP addresses.
\item
  If you're validating IPv6 addresses, you must configure the app
  server's JVM to not force the usage of IPv4 addresses. For example, if
  you're using Tomcat, add the following attribute in the
  \texttt{\$TOMCAT\_HOME\textbackslash{}bin\textbackslash{}setenv.{[}bat\textbar{}sh{]}}
  file.

\begin{verbatim}
     `-Djava.net.preferIPv4Stack=false`
\end{verbatim}
\item
  Restart both app servers for the new properties to take effect.
\item
  Configure the \emph{TunnelAuthVerifier} property for your nodes' app
  servers. There are two ways to do this:

  \begin{itemize}
  \item
    \textbf{Use a \texttt{.config} file (recommended):} In the
    \texttt{\$LIFERAY\_HOME/osgi/configs} folder of one of your node
    Liferay DXP instances, create (if necessary) a
    \texttt{com.liferay.portal.security.auth.verifier.tunnel.module.configuration.TunnelAuthVerifierConfiguration-default.config}
    file and insert the properties listed below. Creating one
    \texttt{.config} file configures all cluster nodes the same way. For
    more information on \texttt{.config} files, see the
    \href{/docs/7-2/user/-/knowledge_base/u/understanding-system-configuration-files}{Understanding
    System Configuration Files} article.

\begin{verbatim}
  enabled=true
  hostsAllowed=127.0.0.1,SERVER_IP,STAGING_IP
  serviceAccessPolicyName=SYSTEM_USER_PASSWORD
  urlsIncludes=/api/liferay/do
\end{verbatim}
  \item
    \textbf{Via System Settings:} Navigate to the \emph{Control Panel} →
    \emph{Configuration} → \emph{System Settings} → \emph{Foundation} →
    \emph{Tunnel Auth Verifiers}. Click on the \emph{/api/liferay/do}
    configuration entry and add the Staging IP address to the
    \emph{Hosts allowed} field. If you choose to configure the
    \emph{TunnelAuthVerifier} this way, you \textbf{must} do this for
    all nodes (e.g., App Server 1 and App Server 2).
  \end{itemize}
\item
  On your Staging instance, navigate to the Site Administration portion
  of the Product Menu and select \emph{Publishing} → \emph{Staging}.
  Then select \emph{Remote Live}.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/remote-staging-menu.png}}
  \caption{When selecting the Remote Staging radio button, you're given
  a list of options to configure.}
  \end{figure}
\item
  For the Remote Host/IP field, insert the balancer's IP of your web
  tier. Configuring the Staging instance with the balancer's IP ensures
  the availability of the environment at the time of publication from
  staging to live.
\item
  Enter the port on which the balancer is running into the Remote Port
  field.
\item
  Insert the remote site ID of your app servers into the Remote Site ID
  field. The site ID of all your app servers are the same since they are
  configured for the same database and are shared between nodes.

  Navigate to the Site Administration portion of the Product Menu and
  select \emph{Configuration} → \emph{Site Settings} to find the site
  ID.
\item
  Save the Remote Live settings.
\end{enumerate}

That's it! You've configured remote staging in your clustered
environment.

\chapter{Content Delivery Network}\label{content-delivery-network}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

A Content Delivery Network (CDN) is an network of servers deployed in
multiple data centers that contain your static content. When users hit
your site, that static content is loaded from a server with geographical
proximity to the user, speeding up requests.

Here, you'll first discover the perks of using a CDN and learn about
general guidelines for using a CDN with Liferay DXP. Then, you'll
configure a CDN. It's time to distribute your content around the world!

\section{Using CDN for Performance
Enhancements}\label{using-cdn-for-performance-enhancements}

A CDN serves static web resources to users. These resources (images, CSS
files, JavaScript files, etc.) are stored on multiple servers around the
world. When requested, the resources are retrieved from the server
nearest to the user.

The CDN functions as a caching proxy. This means that once static
content is copied to a local server, it is stored in a cache for quick
and easy retrieval. This drastically improves latency time, because
browsers can download static resources from a local server down the
street instead of halfway around the world. A user's request to the CDN
for content is directed to specific server machine based on an algorithm
that finds the server closest to the user. The figure below shows a
visual representation of using geographical proximity to improve
latency.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/cdn-map.png}}
\caption{The red lines on the map represent the required distances
traveled by requests from a server to the user. Using CDN allows a user
to request static resources from a much closer local server, improving
download times.}
\end{figure}

Because of the reduced wait time for requests and reduced load on your
application server, a CDN is a great option to improve performance.
Using a CDN with Liferay DXP, however, has some restrictions.

\section{Liferay CDN Requirements}\label{liferay-cdn-requirements}

Liferay DXP only works with CDNs that can dynamically retrieve requested
resources. Dynamic resources change over time or via interaction with
end users and thus cannot be cached. For this reason, check with your
CDN provider to make sure you don't have to upload anything manually in
order for the CDN to work. The CDN must automatically fetch the content.

The CDN must work like a transparent proxy. A request first goes to the
CDN. If the CDN doesn't have the requested resource, the CDN makes an
identical request back to the origin (Liferay DXP), caches the resource,
then serves the resource.

Once you're using a CDN (see below), it serves both portal resources and
plugin resources (e.g., theme resources or JavaScript files referenced
from a plugin's \texttt{liferay-portlet.xml} file). The CDN only serves
resources that are included in a plugin. It does not serve resources
that are dynamically loaded from external sources.

To get the CDN URL for a resource, developers should replace the portal
host in the resource path with
\texttt{themeDisplay.getCDNDynamicResourcesHost()}. Prefix resources
with the CDN host name. Don't manually upload any resources to the CDN
or put anything on the CDN which requires permission checking or complex
policy access.

There are several portal properties for configuring your CDN to suit
your needs. You'll learn how to do this next.

\section{Configuring Liferay DXP to Use a
CDN}\label{configuring-liferay-dxp-to-use-a-cdn}

Now that you understand what a CDN accomplishes and how it's used, it's
time to set one up for yourself. You can set your CDN and its properties
using two different methods:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  By editing your portal properties file
\item
  By using the Control Panel
\end{enumerate}

To configure your CDN via a properties file, create a
\texttt{portal-ext.properties} file in your
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
folder and set the appropriate
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Content\%20Delivery\%20Network}{Content
Delivery Network properties}.

Once you configure your CDN host, Liferay DXP generates URLs to the
static assets that replace the old host with your new CDN host so they
are automatically cached and served afterwards by the CDN.

To configure your CDN in the Control Panel, navigate to \emph{Control
Panel} → \emph{Configuration} → \emph{Instance Settings}. In the main
configuration, there are three fields related to CDNs:

\begin{itemize}
\tightlist
\item
  \emph{CDN Host HTTP}
\item
  \emph{CDN Host HTTPS}
\item
  \emph{Enable CDN Dynamic Resources}
\end{itemize}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/cdn-control-panel.png}}
\caption{The Control Panel lets you configure your portal's CDN.}
\end{figure}

These properties are exactly the same as the ones you can specify in
your \texttt{portal-ext.properties}. Make sure to visit the Content
Delivery Network section of the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Content\%20Delivery\%20Network}{portal.properties}
reference document if you don't know how to fill in the CDN fields. Once
you're finished, click \emph{Save} and your old host is replaced with
your new CDN host for static content.

As you can see, configuring a CDN is easy and can drastically reduce
latency time and improve performance.

\chapter{Tuning Guidelines}\label{tuning-guidelines}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Although setting names may differ, these concepts apply to most
application servers. To keep things simple, Tomcat is used as the
example. For other application servers, consult the provider's
documentation for specific settings.

Here are the tuning topics:

\begin{itemize}
\tightlist
\item
  Database Connection Pool
\item
  Deactivating Development Settings in the JSP Engine
\item
  Thread Pool
\end{itemize}

\section{Database Connection Pool}\label{database-connection-pool}

The database connection pool should be roughly 30-40\% of the thread
pool size. It provides a connection whenever Liferay DXP needs to
retrieve data from the database (e.g., user login). If the pool size is
too small, requests queue in the server waiting for database
connections. If the size is too large, however, idle database
connections waste resources. As with thread pools, monitor these
settings and adjust them based on your performance tests.

In Tomcat, the connection pools are configured in the Resource elements
in \texttt{\$CATALINA\_HOME/conf/Catalina/localhost/ROOT.xml}. Liferay
Engineering tests with this configuration:

\begin{verbatim}
<Resource auth="Container"         
    description="Digital Enterprise DB Connection"   
    driverClass="[place the driver class name here]"   
    maxPoolSize="75"   
    minPoolSize="10"           
    acquireIncrement="5"   
    name="jdbc/LiferayPool"  
    user="[place your user name here]"   
    password="[place your password here]"           
    factory="org.apache.naming.factory.BeanFactory"
    type="com.mchange.v2.c3p0.ComboPooledDataSource"
    jdbcUrl="[place the URL to your database here]"/>
\end{verbatim}

This configuration starts with 10 threads and increments by 5 as needed
to a maximum of 75 connections in the pool.

There are a variety of database connection pool providers, including
DBCP, C3P0, HikariCP, and Tomcat. You may also configure the Liferay
JDBC settings in your
\href{https://docs.liferay.com/ce/portal/7.2-latest/propertiesdoc/portal.properties.html}{\texttt{portal-ext.properties}}
file. For example JDBC connection values, please see
\href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
Templates}

\section{Deactivating Development Settings in the JSP
Engine}\label{deactivating-development-settings-in-the-jsp-engine}

Many application servers' JSP Engines are in development mode by
default. Deactivate these settings prior to entering production:

\textbf{Development mode:} This makes the JSP container poll the file
system for changes to JSP files. Since you won't change JSPs on the fly
like this in production, turn off this mode.

\textbf{Mapped File:} Generates static content with one print statement
versus one statement per line of JSP text.

To disable these in Tomcat, for example, update the
\texttt{\$CATALINA\_HOME/conf/web.xml} file's JSP servlet configuration
to this:

\begin{verbatim}
<servlet>   
    <servlet-name>jsp</servlet-name>
    <servlet-class>org.apache.jasper.servlet.JspServlet</servlet-class>   
    <init-param>    
        <param-name>development</param-name>    
        <param-value>false</param-value>   
    </init-param>   
    <init-param>    
        <param-name>mappedFile</param-name>    
        <param-value>false</param-value>   
    </init-param>   
    <load-on-startup>3</load-on-startup>
</servlet>
\end{verbatim}

Development mode and mapped files are disabled.

\section{Thread Pool}\label{thread-pool}

Each request to the application server consumes a worker thread for the
duration of the request. When no threads are available to process
requests, the request is queued to wait for the next available worker
thread. In a finely tuned system, the number of threads in the thread
pool are balanced with the total number of concurrent requests. There
should not be a significant amount of threads left idle to service
requests.

Use an initial thread pool setting of 50 threads and then monitor it
within your application server's monitoring consoles. You may wish to
use a higher number (e.g., 250) if your average page times are in the
2-3 second range. Too few threads in the thread pool might queue
excessive requests; too many threads can cause excessive context
switching.

In Tomcat, the thread pools are configured in the
\texttt{\$CATALINA\_HOME/conf/server.xml} file's \texttt{Connector}
element. The
\href{https://tomcat.apache.org/tomcat-9.0-doc/config/http.html}{Apache
Tomcat documentation} provides more details. Liferay Engineering tests
with this configuration:

\begin{verbatim}
<Connector maxThreads="75" minSpareThreads="50"
    maxConnections="16384" port="8080"     
    connectionTimeout="600000" redirectPort="8443"
    URIEncoding="UTF-8"  socketBuffer="-1"     
    maxKeepAliveRequests="-1" address="xxx.xxx.xxx.xxx"/>
\end{verbatim}

Additional tuning parameters around Connectors are available, including
the connector types, the connection timeouts, and TCP queue. Consult
your application server's documentation for further details.

\chapter{Java Virtual Machine Tuning}\label{java-virtual-machine-tuning}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Java Virtual Machine (JVM) tuning primarily focuses on adjusting the
garbage collector and the Java memory heap. We used Oracle's 1.8 JVM for
the reference architecture. You may choose other supported JVM versions
and implementations. Please consult the
\href{https://web.liferay.com/group/customer/dxp/support/compatibility-matrix}{Liferay
DXP Compatibility Matrix} for additional compatible JVMs.

Here are the JVM tuning topics:

\begin{itemize}
\tightlist
\item
  \hyperref[garbage-collector]{Garbage Collector}
\item
  \hyperref[code-cache]{Code Cache}
\item
  \hyperref[java-heap]{Java Heap}
\item
  \hyperref[jvm-advanced-options]{JVM Advanced Options}
\end{itemize}

Garbage collection is first.

\section{Garbage Collector}\label{garbage-collector}

Choosing the appropriate garbage collector (GC) helps improve the
responsiveness of your Liferay DXP deployment. Use the concurrent low
pause collectors:

\begin{verbatim}
-XX:+UseParNewGC -XX:ParallelGCThreads=16 -XX:+UseConcMarkSweepGC
-XX:+CMSParallelRemarkEnabled -XX:+CMSCompactWhenClearAllSoftRefs
-XX:CMSInitiatingOccupancyFraction=85 -XX:+CMSScavengeBeforeRemark
\end{verbatim}

You may choose from other available GC algorithms, including parallel
throughput collectors and G1 collectors. Start tuning using parallel
collectors in the new generation and concurrent mark sweep (CMS) in the
old generation.

\textbf{Note:} the \texttt{ParallelGCThreads} value (e.g.,
\texttt{ParallelGCThreads=16}) varies based on the type of CPUs
available. Set the value according to CPU specification. On Linux
machines, report the number of available CPUs by running
\texttt{cat\ /proc/cpuinfo}.

\textbf{Note:} There are additional ``new'' algorithms like G1, but
Liferay Engineering's tests for G1 indicated that it does not improve
performance. Since your application performance may vary, you should add
G1 to your testing and tuning plans.

\section{Code Cache}\label{code-cache}

Java's just-in-time (JIT) compiler generates native code to improve
performance. The default size is \texttt{48m}. This may not be
sufficient for larger applications. Too small a code cache reduces
performance, as the JIT isn't able to optimize high frequency methods.
For Liferay DXP, start with \texttt{64m} for the initial code cache
size.

\begin{verbatim}
-XX:InitialCodeCacheSize=64m -XX:ReservedCodeCacheSize=96m
\end{verbatim}

Examine the efficacy of the parameter changes by adding the following
logging parameters:

\begin{verbatim}
-XX:+PrintCodeCache -XX:+PrintCodeCacheOnCompilation
\end{verbatim}

\section{Java Heap}\label{java-heap}

When most people think about tuning the Java memory heap, they think of
setting the maximum and minimum memory of the heap. Unfortunately, most
deployments require far more sophisticated heap tuning to obtain optimal
performance, including tuning the young generation size, tenuring
durations, survivor spaces, and many other JVM internals.

For most systems, it's best to start with at least the following memory
settings:

\begin{verbatim}
-server -XX:NewSize=700m -XX:MaxNewSize=700m -Xms2048m -Xmx2048m -XX:MetaspaceSize=512m
-XX:MaxMetaspaceSize=512m -XX:SurvivorRatio=6 -XX:TargetSurvivorRatio=9 -XX:MaxTenuringThreshold=15
\end{verbatim}

On systems that require large heap sizes (e.g., above 4GB), it may be
beneficial to use large page sizes. You can activate large page sizes
like this:

\begin{verbatim}
-XX:+UseLargePages -XX:LargePageSizeInBytes=256m
\end{verbatim}

You may choose to specify different page sizes based on your application
profile.

\textbf{Note:} To use large pages in the JVM, you must configure your
underlying operating system to activate them. In Linux, run
\texttt{cat\ /proc/meminfo} and look at ``huge page'' items.

\noindent\hrulefill

\textbf{Caution:} Avoid allocating more than 32GB to your JVM heap. Your
heap size should be commensurate with the speed and quantity of
available CPU resources.

\noindent\hrulefill

\section{JVM Advanced Options}\label{jvm-advanced-options}

The following advanced JVM options were also applied in the Liferay
benchmark environment:

\begin{verbatim}
-XX:+UseLargePages -XX:LargePageSizeInBytes=256m 
-XX:+UseCompressedOops -XX:+DisableExplicitGC -XX:-UseBiasedLocking 
-XX:+BindGCTaskThreadsToCPUs -XX:UseFastAccessorMethods
\end{verbatim}

Please consult your JVM documentation for additional details on advanced
JVM options.

Combining the above recommendations together, makes this configuration:

\begin{verbatim}
-server -XX:NewSize=1024m -XX:MaxNewSize=1024m -Xms4096m
-Xmx4096m -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m
-XX:SurvivorRatio=12 -XX:TargetSurvivorRatio=90
-XX:MaxTenuringThreshold=15 -XX:+UseLargePages 
-XX:LargePageSizeInBytes=256m -XX:+UseParNewGC 
-XX:ParallelGCThreads=16 -XX:+UseConcMarkSweepGC 
-XX:+CMSParallelRemarkEnabled -XX:+CMSCompactWhenClearAllSoftRefs
-XX:CMSInitiatingOccupancyFraction=85 -XX:+CMSScavengeBeforeRemark 
-XX:+UseLargePages -XX:LargePageSizeInBytes=256m
-XX:+UseCompressedOops -XX:+DisableExplicitGC -XX:-UseBiasedLocking
-XX:+BindGCTaskThreadsToCPUs -XX:+UseFastAccessorMethods
-XX:InitialCodeCacheSize=32m -XX:ReservedCodeCacheSize=96m
\end{verbatim}

\noindent\hrulefill

\textbf{Caution:} The above JVM settings should formulate a starting
point for your performance tuning. Every system's final parameters vary
due to many factors, including number of current users and transaction
speed.

\noindent\hrulefill

Monitor the garbage collector statistics to ensure your environment has
sufficient allocations for metaspace and also for the survivor spaces.
Using the configuration above in the wrong environment could result in
dangerous runtime scenarios like out of memory failures. Improperly
tuned survivor spaces also lead to wasted heap space.

\chapter{Installing a Search Engine}\label{installing-a-search-engine}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

A search engine is a critical component of your Liferay DXP
installation. If you're here, you probably know the basics already and
want to configure a search engine for your Liferay DXP deployment.

Elasticsearch, a highly scalable, full-text search engine, is installed
by default, as an embedded server. Elasticsearch is well-supported and
almost certainly meets any search and indexing need you have, but you
must not use the
\href{/docs/7-2/deploy/-/knowledge_base/d/elasticsearch\#embedded-vs-remote-operation-mode}{embedded
version in your production deployment}.

Learn to configure a remote Elasticsearch server or cluster
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{here}.

\href{http://lucene.apache.org/solr}{Solr} is another capable and
popular search engine supported in Liferay DXP.

Learn to configure a remote Solr server or cluster
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-solr}{here}. But
first, make sure you understand the disparity in functionality between
the supported search engines.

\section{Choosing a Search Engine}\label{choosing-a-search-engine}

Elasticsearch and Solr are both supported, but there are limitations to
Liferay's Solr integration. To make use of some features, you must
choose Elasticsearch.

\section{End User Feature Limitations of Liferay's Solr
Integration}\label{end-user-feature-limitations-of-liferays-solr-integration}

\begin{itemize}
\tightlist
\item
  \href{https://learn.liferay.com/commerce-2.x/index.html}{Liferay
  Commerce}
\item
  \href{https://help.liferay.com/hc/en-us/articles/360029042071-Workflow-Metrics-The-Service-Level-Agreement-SLA-}{Workflow
  Metrics}
\item
  \href{/docs/7-2/user/-/knowledge_base/u/filtering-search-results-with-the-custom-filter-widget}{Custom
  Filter search widget}
\item
  \href{/docs/7-2/user/-/knowledge_base/u/low-level-search-options-searching-additional-or-alternate-indexes}{The
  Low Level Search Options widget}
\item
  \href{https://help.liferay.com/hc/en-us/articles/360034473872-Search-Tuning-Customizing-Search-Results}{Search
  Tuning: Customizing Search Results}
\item
  \href{https://help.liferay.com/hc/en-us/articles/360034473852-Search-Tuning-Synonym-Sets}{Search
  Tuning: Synonyms}
\end{itemize}

\section{Developer Feature Limitations of Liferay's Solr
Integration}\label{developer-feature-limitations-of-liferays-solr-integration}

Implementation for the following APIs may be added in the future, but
they are not currently supported by Liferay's Solr connector.

\begin{itemize}
\tightlist
\item
  From Portal Core (Module: \texttt{portal-kernel}, Artifact:
  \texttt{com.liferay.portal.kernel}):

  \begin{itemize}
  \tightlist
  \item
    \texttt{com.liferay.portal.kernel.search.generic.NestedQuery}
  \item
    \texttt{com.liferay.portal.kernel.search.filter}:

    \begin{itemize}
    \tightlist
    \item
      \texttt{ComplexQueryPart}
    \item
      \texttt{GeoBoundingBoxFilter}
    \item
      \texttt{GeoDistanceFilter}
    \item
      \texttt{GeoDistanceRangeFilter}
    \item
      \texttt{GeoPolygonFilter}
    \end{itemize}
  \end{itemize}
\item
  From the Portal Search API (Module: \texttt{portal-search-api},
  Artifact: \texttt{com.liferay.portal.search.api}):

  \begin{itemize}
  \tightlist
  \item
    \texttt{com.liferay.portal.search.filter}:

    \begin{itemize}
    \tightlist
    \item
      \texttt{ComplexQueryPart}
    \item
      \texttt{TermsSetFilter}
    \end{itemize}
  \item
    \texttt{com.liferay.portal.search.geolocation.*}
  \item
    \texttt{com.liferay.portal.search.highlight.*}
  \item
    \texttt{com.liferay.portal.search.query.function.*}
  \item
    \texttt{com.liferay.portal.search.query.*}:
  \item
    \texttt{com.liferay.portal.search.script.*}
  \item
    \texttt{com.liferay.portal.search.significance.*}
  \item
    \texttt{com.liferay.portal.search.sort.*}: only
    \texttt{Sort},\texttt{FieldSort}, and \texttt{ScoreSort} are
    supported
  \end{itemize}
\item
  Portal Search Engine Adapter API (Module:
  \texttt{portal-search-engine-adapter-api}, Artifact:
  \texttt{com.liferay.portal.search.engine.adapter.api})

  \begin{itemize}
  \tightlist
  \item
    \texttt{com.liferay.portal.search.engine.adapter.cluster.*}
  \item
    \texttt{com.liferay.portal.search.engine.adapter.document.UpdateByQueryDocumentRequest}
  \item
    \texttt{com.liferay.portal.search.engine.adapter.index.*}: only
    \texttt{RefreshIndexRequest} is supported
  \item
    \texttt{com.liferay.portal.search.engine.adapter.search.*}:

    \begin{itemize}
    \tightlist
    \item
      \texttt{MultisearchSearchRequest}
    \item
      \texttt{SuggestSearchRequest}
    \end{itemize}
  \item
    \texttt{com.liferay.portal.search.engine.adapter.snapshot.*}
  \end{itemize}
\end{itemize}

Liferay Commerce requires the \texttt{TermsSetFilter} implementation,
only available in the Elasticsearch connector.

\section{Elasticsearch Java Distribution
Compatibility}\label{elasticsearch-java-distribution-compatibility}

Another factor to consider in your search engine selection is JDK
version. The search engine and Liferay DXP must use the same Java
version and distribution (e.g., Oracle Open JRE 1.8.0\_201). Consult the
\href{https://www.elastic.co/support/matrix\#matrix_jvm}{Elasticsearch
compatibility matrix} and the
\href{https://help.liferay.com/hc/en-us/sections/360002103292-Compatibility-Matrix}{Liferay
DXP compatibility matrix} to learn more about supported JDK
distributions and versions. This consideration is not necessary for
Solr, because no JVM level serialization happens between the servers.
All communication occurs at the HTTP level.

\chapter{Elasticsearch}\label{elasticsearch}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Elasticsearch is an open source, highly scalable, full-text search and
analytics engine.

By default, Elasticsearch runs as an embedded search engine, which is
useful for development and testing but is not supported in production.
In production environments you must run Elasticsearch in remote mode, as
a separate server or cluster. This guide walks you through the process
of configuring Elasticsearch in remote mode.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/search-admin-engineinfo.png}}
\caption{To see information about the currently connected search engine,
go to \emph{Control Panel} → \emph{Configuration} → \emph{Search}.}
\end{figure}

\noindent\hrulefill

\textbf{Note:} Although Elasticsearch 6.5 is shipped as the embedded
Elasticsearch server version, Elasticsearch 7 is the most recent
supported Elasticsearch version for 7.0. Installing Elasticsearch 7
requires that you are running Service Pack 1/Fix Pack 2 or later (GA2 or
later for CE users). Elasticsearch 6.8.x is also supported. See the
\href{https://help.liferay.com/hc/en-us/articles/360016511651}{compatibility
matrix for exact versions}.

\noindent\hrulefill

If you'd rather use Solr, it's also supported. See the documentation on
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-solr}{Installing
Solr} if you're interested.

To get up and running quickly with Elasticsearch as a remote server,
refer to the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{Installing
Elasticsearch article}. Included there are basic instructions for
installing and configuring Elasticsearch in a single server environment.
Additional articles include more details and information on configuring
and tuning Elasticsearch.

These terms are useful to understand as you read this guide:

\begin{itemize}
\item
  \emph{Elasticsearch Home} refers to the root folder of your unzipped
  Elasticsearch installation (for example,
  \texttt{elasticsearch-7.4.1}).
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{\emph{Liferay
  Home}} refers to the root folder of your Liferay DXP installation. It
  contains the \texttt{osgi}, \texttt{deploy}, \texttt{data}, and
  \texttt{license} folders, among others.
\end{itemize}

\section{Embedded vs.~Remote Operation
Mode}\label{embedded-vs.-remote-operation-mode}

When you start Liferay DXP, this message is displayed in the log:

\begin{verbatim}
2019-04-29 09:59:02.276 WARN  [Elasticsearch initialization thread][EmbeddedElasticsearchConnection:288] Liferay is configured to use embedded Elasticsearch as its search engine. Do NOT use embedded Elasticsearch in production. Embedded Elasticsearch is useful for development and demonstration purposes. Refer to the documentation for details on the limitations of embedded Elasticsearch. Remote Elasticsearch connections can be configured in the Control Panel.
\end{verbatim}

When you start Liferay DXP, Elasticsearch is already running in embedded
mode. Liferay DXP runs an Elasticsearch node in the same JVM so it's
easy to test-drive with minimal configuration. Running both servers in
the same process has drawbacks:

\begin{itemize}
\tightlist
\item
  Elasticsearch must use the same JVM options as Liferay DXP.
\item
  Liferay DXP and Elasticsearch compete for the same system resources.
\end{itemize}

\noindent\hrulefill

\textbf{Note:} While it's not a supported production configuration,
installing Kibana to monitor the embedded Elasticsearch server is useful
during development and testing. Just be aware that you must install the
\href{https://www.elastic.co/downloads/kibana-oss}{OSS only Kibana
build}.

\noindent\hrulefill

You wouldn't run an embedded database like HSQL in production, and you
shouldn't run Elasticsearch in embedded mode in production either.
Instead, run Elasticsearch in \emph{remote operation mode}, as a
standalone server or cluster of server nodes.

\section{Troubleshooting Elasticsearch
Integration}\label{troubleshooting-elasticsearch-integration}

Sometimes things don't go as planned. If you've set up Liferay DXP with
Elasticsearch in remote mode, but Liferay DXP can't connect to
Elasticsearch, check these things:

\begin{description}
\tightlist
\item[\textbf{Cluster name:}]
The value of the \texttt{cluster.name} property in
\texttt{elasticsearch.yml} must match the \texttt{clusterName} property
configured in the Liferay DXP Elasticsearch connector.
\item[\textbf{Transport address:}]
The value of the \texttt{transportAddresses} property in the
Elasticsearch connector configuration must contain at least one valid
host and port where an Elasticsearch node is running. If Liferay DXP is
running in embedded mode, and you start a standalone Elasticsearch node
or cluster, it detects that port \texttt{9300} is taken and switches to
port \texttt{9301}. If you then set Liferay's Elasticsearch connector to
remote mode, it continues to look for Elasticsearch at the default port
(\texttt{9300}).
\end{description}

The following articles cover the Liferay Connector to Elasticsearch's
configuration options in more detail.

\begin{description}
\tightlist
\item[\textbf{Cluster Sniffing (Additional Configurations):}]
Elasticsearch clusters can have multiple node
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-node.html\#modules-node}{types}.
\href{https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.x/transport-client.html}{Cluster
sniffing}, enabled by default in the Liferay DXP connector, looks for
\texttt{data} nodes configured in the \texttt{transportAddresses}
property. If none are available, the connector may throw a
\texttt{NoNodeAvailableException} in the console log. If cluster
sniffing is to remain enabled, be sure that your configuration allows
for at least one \texttt{data} node's transport address to be
``sniffable'' at all times to avoid this error.
\end{description}

To disable cluster sniffing, add \texttt{clientTransportSniff=false} to
the \texttt{.config} file or un-check the Client Transport Sniff
property in System Settings.

\chapter{Preparing to Install
Elasticsearch}\label{preparing-to-install-elasticsearch}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

By default, 7.0 and its
\href{/docs/7-2/deploy/-/knowledge_base/d/elasticsearch\#embedded-vs-remote-operation-mode}{embedded
Elasticsearch engine} run in the same JVM. Although this enables
out-of-the-box search, it's only supported for development. For
production use, Elasticsearch must run in a separate JVM. See the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{installation
guide} for information on installing a remote Elasticsearch cluster.

Because search engines benefit heavily from caching, their JVM memory
profiles differ substantially from those of a JVM running Liferay DXP.
Therefore, the two applications should always be kept separate in
production environments.

The following sections provide a synopsis of Elasticsearch
configurations for 7.0. Prior to deployment, we strongly recommend
reading
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index.html}{Elastic's
documentation on production deployment}.

\section{Sizing Your Deployment}\label{sizing-your-deployment}

When sizing your Elasticsearch deployment, carefully consider CPU,
memory, disk, and network capacity. To scale effectively and avoid using
lots of machines, deploy Elasticsearch on medium to large machines (for
example, machines with two to eight CPUs). Avoid running multiple
Elasticsearch JVMs on the same operating system.

\section{CPU}\label{cpu}

We recommend allocating at least eight total CPU cores to the
Elasticsearch engine, assuming only one Elasticsearch JVM is running on
the machine.

\section{Memory}\label{memory}

At least 16 GB of memory is recommended, with 64 GB preferred. The
precise memory allocation required depends on how much data is indexed.
For index sizes 500 GB to 1 TB, 64 GB of memory suffices.

\section{Disk}\label{disk}

Search engines store their indexes on disk, so disk I/O capacity can
impact search performance. Deploy Elasticsearch on SSD whenever
possible. Otherwise use high-performance traditional hard disks (for
example, 15k RPM). In either case, consider using RAID 0.

Avoid using Network Attached Storage (NAS) whenever possible as the
network overhead can be large. If you're using public cloud
infrastructure like Amazon Web Services, use instance local storage
instead of network storage, such as Elastic Block Store (EBS).

Maintain 25 percent more disk capacity than the total size of your
indexes. If your index is 60 GB, make sure you have at least 75 GB of
disk space available. To estimate the disk space you need, you can index
a representative sample of your production content and multiply that
size by the fraction of your production content that it represents. For
example, index 25 percent of your production content and then multiply
the resulting index size by four. Keep in mind that indexing a 1 MB file
doesn't result in 1 MB of disk space in the search index.

\section{Cluster Size}\label{cluster-size}

While Liferay DXP can work with an Elasticsearch cluster comprised of
one or two nodes, the minimum cluster size recommended by Elastic for
fault tolerance is three nodes.

\section{Networking}\label{networking}

Elasticsearch relies on clustering and sharding to deliver fast,
accurate search results, and thus requires a fast and reliable network.
Most modern data centers provide 1 GbE or 10 GbE between machines.

\chapter{Installing Elasticsearch}\label{installing-elasticsearch}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay DXP uses Elasticsearch to index its content. By default, it's
installed as an embedded service. It works, but it's not a supported
configuration for a production server. Feel free to use it while testing
or developing, but when you're ready to put your site in production, you
must run Elasticsearch as a standalone process. This is better anyway,
because it frees you to design your infrastructure the way you want it.
If you've got hardware or a VM to spare, you can separate your search
infrastructure from Liferay DXP and reap some performance gains by
putting search on a separate box. If you're more budget-conscious, you
can still increase performance by running Elasticsearch in a separate,
individually tunable JVM on the same box.

Before installing Elasticsearch, refer to
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-install-elasticsearch}{Preparing
to Install Elasticsearch} for guidance on configuring the servers to
support an Elasticsearch deployment properly.

Here's an overview of the installation steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Download a supported version of Elasticsearch. See
  \href{https://www.elastic.co}{Elastic's} website.
\item
  Install Elasticsearch by extracting its archive to the system where
  you want it to run.
\item
  Install some required Elasticsearch plugins.
\item
  Name your Elasticsearch cluster.
\item
  Configure Liferay DXP to connect to your Elasticsearch cluster.
\item
  Restart Liferay DXP and reindex your search and spell check indexes.
\end{enumerate}

\noindent\hrulefill

\textbf{Prerequisites:} Before continuing, make sure you have set the
\href{https://docs.oracle.com/cd/E19182-01/820-7851/inst_cli_jdk_javahome_t/}{\texttt{JAVA\_HOME}
environment variable}.

If you have multiple JDKs installed, make sure Elasticsearch and Liferay
DXP are using the same version and distribution (e.g., Oracle Open JDK
1.8.0\_201). You can specify this in
\texttt{{[}Elasticsearch\ Home{]}/bin/elasticsearch.in.sh}:
\texttt{JAVA\_HOME=/path/to/java}.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Replacing the Default Elasticsearch 6 Connector:} If you're
installing Elasticsearch 6, use the connector application installed by
default. If you're installing Elasticsearch 7, you'll need to download
the connector from Liferay Marketplace for either
\href{https://web.liferay.com/en/marketplace/-/mp/application/170642090}{CE}
and
\href{https://web.liferay.com/en/marketplace/-/mp/application/170390307}{DXP}.
Always refer to the
\href{https://www.liferay.com/documents/10182/246659966/Liferay+DXP+7.2+Compatibility+Matrix.pdf/ed234765-db47-c4ad-7c82-2acb4c73b0f9}{compatibility
matrix to find the exact versions supported}. Before installing the
connector, blacklist the Elasticsearch 6 connector and APIs. The
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-elasticsearch-7\#blacklisting-elasticsearch-6}{upgrade
documentation} holds detailed blacklisting steps.

\noindent\hrulefill

When you perform these steps, you'll have a basic, production-ready
instance of Liferay DXP and Elasticsearch up and running. But that's
just the beginning of your server/connector configuration:

\begin{itemize}
\tightlist
\item
  Read about
  \href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{Configuring
  Elasticsearch} for Liferay DXP in more detail.
\item
  Learn how to
  \href{/docs/7-2/deploy/-/knowledge_base/d/installing-liferay-enterprise-search-security}{Secure
  Elasticsearch}.
\item
  {[}Liferay Enterprise Search{]} Learn how to configure
  \href{/docs/7-2/deploy/-/knowledge_base/d/installing-liferay-enterprise-search-monitoring}{Monitoring}.
\end{itemize}

For complete information on compatibility, check the
\href{https://help.liferay.com/hc/en-us/articles/360028982631-Liferay-DXP-7-2-Compatibility-Matrix}{Liferay
DXP compatibility matrix} and the
\href{https://help.liferay.com/hc/en-us/articles/360016511651\#Liferay-Enterprise-Search}{Liferay
Enterprise Search compatibility matrix} if you have a subscription.

\section{Step One: Download a Supported Version of
Elasticsearch}\label{step-one-download-a-supported-version-of-elasticsearch}

If Liferay DXP isn't running, start it.

Visit port 9200 on localhost to access the embedded Elasticsearch:

\begin{verbatim}
http://localhost:9200
\end{verbatim}

A JSON document is returned that looks similar to this:

\begin{verbatim}
{
  "name" : "01BT8H4",
  "cluster_name" : "LiferayElasticsearchCluster",
  "cluster_uuid" : "ziPGEBeSToGHc7lVqaYHnA",
  "version" : {
    "number" : "6.5.0",
    "build_flavor" : "unknown",
    "build_type" : "unknown",
    "build_hash" : "816e6f6",
    "build_date" : "2018-11-09T18:58:36.352602Z",
    "build_snapshot" : false,
    "lucene_version" : "7.5.0",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
\end{verbatim}

The version of Elasticsearch that's running is the value of the
\texttt{number} field. In this example, it's 6.5.0. You can install the
embedded version, but it might not be the most up-to-date version of
Elasticsearch that's supported with Liferay DXP. Consult the
\href{https://help.liferay.com/hc/en-us/articles/360016511651}{Compatibility
Matrix} for definitive information on what's supported.

\noindent\hrulefill

\textbf{Note:} Although the embedded server uses Elasticsearch 6.5,
Elasticsearch 6.8.x has been tested with 7.0 GA1, and is fully
supported. If you've upgraded to 7.0 Service Pack 1/Fix Pack 2 (or GA2
for CE users), Elasticsearch 7 is supported through the Liferay
Connector to Elasticsearch 7, which can be downloaded from Liferay
Marketplace for both
\href{https://web.liferay.com/en/marketplace/-/mp/application/170642090}{CE}
and
\href{https://web.liferay.com/en/marketplace/-/mp/application/170390307}{DXP}.
Always refer to the
\href{https://help.liferay.com/hc/en-us/articles/360016511651}{compatibility
matrix to find the exact versions supported}.

\noindent\hrulefill

Shut down the Liferay DXP server. In a local, single-machine testing
environment, if you continue without shutting down, the Elasticsearch
server you're about to install and start throws errors in the log if its
cluster name and HTTP port match the already-running embedded
Elasticsearch server. An alternative to shutting down Liferay DXP is to
use a different cluster name (i.e., not
\texttt{LiferayElasticsearchCluster}) and HTTP port (i.e., not
\texttt{9200}) in the remote Elasticsearch server.

When you know the version of Elasticsearch you need, go to
\href{https://www.elastic.co}{Elastic's} website and download that
version.

\section{Step Two: Install
Elasticsearch}\label{step-two-install-elasticsearch}

Most of this step entails deciding where you want to run Elasticsearch.
Do you want to run it on the same machine as Liferay DXP, or do you want
to run it on its own hardware? The answer to this question comes down to
a combination of the resources you have available and the size of your
installation. Regardless of what you decide, either way you get the
benefit of a separately tunable search infrastructure.

Once you have a copy of the right version of Elasticsearch, extract it
to a folder on the machine where you want it running. That's it!

\section{Step Three: Install Elasticsearch
Plugins}\label{step-three-install-elasticsearch-plugins}

Install the following required Elasticsearch plugins:

\begin{itemize}
\tightlist
\item
  \texttt{analysis-icu}
\item
  \texttt{analysis-kuromoji}
\item
  \texttt{analysis-smartcn}
\item
  \texttt{analysis-stempel}
\end{itemize}

To install these plugins, navigate to Elasticsearch Home and enter

\begin{verbatim}
./bin/elasticsearch-plugin install [plugin-name]
\end{verbatim}

Replace \emph{{[}plugin-name{]}} with the Elasticsearch plugin's name.

\section{Step Four: Name Your Elasticsearch
Cluster}\label{step-four-name-your-elasticsearch-cluster}

A \emph{cluster} in Elasticsearch is a collection of nodes (servers)
identified as a cluster by a shared cluster name. The nodes work
together to share data and workload. A one node cluster is discussed
here; to create a multi-node cluster, please refer to
\href{https://www.elastic.co/guide/index.html}{Elastic's documentation}.

Now that you've installed Elastic, it sits in a folder on your machine,
which is referred to here as \texttt{{[}Elasticsearch\ Home{]}}. To name
your cluster, you'll define the cluster name in both Elasticsearch and
in Liferay DXP. First, define it in Elasticsearch. Edit the following
file:

\begin{verbatim}
[Elasticsearch Home]/config/elasticsearch.yml
\end{verbatim}

Uncomment the line that begins with \texttt{cluster.name}. Set the
cluster name to whatever you want to name your cluster:

\begin{verbatim}
cluster.name: LiferayElasticsearchCluster
\end{verbatim}

Of course, this isn't a very imaginative name; you may choose to name
your cluster \texttt{finders\_keepers} or something else you can
remember more easily. Save the file.

\noindent\hrulefill

\textbf{Elasticsearch 6.x:} On Elasticsearch 6.x, you must also disable
X-Pack Security unless you have a Liferay Enterprise Search
subscription. Add this to \texttt{elasticsearch.yml}:
\texttt{xpack.security.enabled:\ false}.

\noindent\hrulefill

Now you can start Elasticsearch. Run the executable for your operating
system from the \texttt{{[}Elasticsearch\ Home{]}/bin} folder:

\begin{verbatim}
./elasticsearch
\end{verbatim}

Elasticsearch starts, and one of its status messages includes a
transport address:

\begin{verbatim}
[2019-04-01T16:55:50,127][INFO ][o.e.t.TransportService   ] [HfkqdKv] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
\end{verbatim}

Take note of this address; you'll need to give it to your Liferay DXP
server so it can find Elasticsearch on the network.

\section{Step Five: Configure Liferay DXP to Connect to your
Elasticsearch
Cluster}\label{step-five-configure-liferay-dxp-to-connect-to-your-elasticsearch-cluster}

Now that you're ready to configure Liferay DXP, start it if you haven't
already, log in, and then click on \emph{Control Panel} →
\emph{Configuration} → \emph{System Settings} → \emph{Search}. Enter the
term \emph{elasticsearch} in the search bar and click the
\emph{Elasticsearch {[}Version{]}} entry from the list of settings (at
the time of writing, the version will either be \emph{6} or \emph{7}).
Now you can configure it. Here are the configuration options to change:

\textbf{Cluster Name:} Enter the name of the cluster as you defined it
in Elasticsearch.

\textbf{Operation Mode:} Defaults to EMBEDDED. Change it to REMOTE to
connect to a standalone Elasticsearch.

\textbf{Transport Addresses:} Enter a delimited list of transport
addresses for Elasticsearch nodes. Here, you'll enter the transport
address from the Elasticsearch server you started. The default value is
\texttt{localhost:9300}, which will work.

When finished, click \emph{Save}. You're almost done.

\section{Step Six: Restart Liferay DXP and
Reindex}\label{step-six-restart-liferay-dxp-and-reindex}

If you're doing a local test installation, you probably only changed the
Operation Mode in the connector configuration, so there's no need to
restart; skip to re-indexing. If you've made more configuration changes
in the connector's configuration, stop and restart Liferay DXP. When
it's back up, log in as an administrative user and click on
\emph{Control Panel} → \emph{Configuration} → \emph{Search} and click
the \emph{Execute} button for \emph{Reindex all search indexes} and then
\emph{Reindex all spell check indexes}. When you do that, you'll see
some messages scroll up in the Elasticsearch log.

When restarting Liferay DXP, \texttt{update\_mappings} messages will
appear in the Elasticsearch logs:

\begin{verbatim}
[2019-04-01T17:08:57,462][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-0/m27eNsekTAyP27zDOjGojw] update_mapping [LiferayDocumentType]
[2019-04-01T17:08:57,474][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-0/m27eNsekTAyP27zDOjGojw] update_mapping [LiferayDocumentType]
[2019-04-01T17:08:58,393][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-0/m27eNsekTAyP27zDOjGojw] update_mapping [LiferayDocumentType]
[2019-04-01T17:08:58,597][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-0/m27eNsekTAyP27zDOjGojw] update_mapping [LiferayDocumentType]
[2019-04-01T17:09:07,040][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/OJidpYkgR5OcCD5dgWB8Aw] update_mapping [LiferayDocumentType]
\end{verbatim}

Once you reindex, more log messages appear in Elasticsearch:

\begin{verbatim}
[2019-04-01T17:11:17,338][INFO ][o.e.c.m.MetaDataDeleteIndexService] [HfkqdKv] [liferay-20101/OJidpYkgR5OcCD5dgWB8Aw] deleting index
[2019-04-01T17:11:17,389][INFO ][o.e.c.m.MetaDataCreateIndexService] [HfkqdKv] [liferay-20101] creating index, cause [api], templates [], shards [1]/[0], mappings [LiferayDocumentType]
[2019-04-01T17:11:17,471][INFO ][o.e.c.r.a.AllocationService] [HfkqdKv] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[liferay-20101][0]] ...]).
[2019-04-01T17:11:17,520][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:19,047][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:19,133][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:19,204][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:19,249][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:21,215][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:21,262][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:21,268][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:21,275][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:21,282][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
[2019-04-01T17:11:21,373][INFO ][o.e.c.m.MetaDataMappingService] [HfkqdKv] [liferay-20101/Meacn_uxR06g0tCJonS4eA] update_mapping [LiferayDocumentType]
\end{verbatim}

Reindexing the spell check dictionaries produces log messages like
these:

\begin{verbatim}
2019-04-29 14:02:22.034 INFO  [liferay/search_writer/SYSTEM_ENGINE-11][BaseSpellCheckIndexWriter:278] Start indexing dictionary for com/liferay/portal/search/dependencies/spellchecker/en_US.txt
2019-04-29 14:02:34.166 INFO  [liferay/search_writer/SYSTEM_ENGINE-11][BaseSpellCheckIndexWriter:299] Finished indexing dictionary for com/liferay/portal/search/dependencies/spellchecker/en_US.txt
2019-04-29 14:02:34.167 INFO  [liferay/search_writer/SYSTEM_ENGINE-11][BaseSpellCheckIndexWriter:278] Start indexing dictionary for com/liferay/portal/search/dependencies/spellchecker/es_ES.txt
2019-04-29 14:02:39.379 INFO  [liferay/search_writer/SYSTEM_ENGINE-11][BaseSpellCheckIndexWriter:299] Finished indexing dictionary for com/liferay/portal/search/dependencies/spellchecker/es_ES.txt
\end{verbatim}

For additional confirmation that Liferay DXP recognizes the remote
search engine, navigate to the Search Control Panel application and note
the subtle change there: the vendor name is now simply
\emph{Elasticsearch}, whereas prior to the installation of the remote
Elasticsearch server, it said \emph{Elasticsearch (Embedded)}.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/search-admin-engineinfo-remote.png}}
\caption{To see information about the currently connected search engine,
go to \emph{Control Panel → Configuration → Search}.}
\end{figure}

For additional details refer to the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/getting-started-install.html}{Elasticsearch
installation guide}.

\chapter{Configuring the Liferay Elasticsearch
Connector}\label{configuring-the-liferay-elasticsearch-connector}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

For detailed Elasticsearch configuration information, refer to the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/settings.html}{Elasticsearch
documentation}.

The name of your Elasticsearch cluster is important. When you're running
Elasticsearch in remote mode, the cluster name is used by Liferay DXP to
recognize the Elasticsearch cluster. To learn about setting the
Elasticsearch cluster name on the Liferay DXP side, refer below to the
section called Configuring the Liferay Elasticsearch Connector.

\noindent\hrulefill

\textbf{Note:} The \texttt{http.enabled} setting in Elasticsearch
corresponds to the \texttt{httpEnabled} setting in the Liferay Connector
to Elasticsearch 6 application. As this setting was
\href{https://www.elastic.co/guide/en/elasticsearch/reference/6.5/release-notes-6.3.0.html}{deprecated
in Elasticsearch 6.3}, the connector's corresponding setting is now also
deprecated. This setting was only used for configuring the embedded
Elasticsearch server, so its deprecation should have minimal impact to
production deployments.

\noindent\hrulefill

Elasticsearch's configuration files are written in
\href{http://www.yaml.org}{YAML} and kept in the
\texttt{{[}Elasticsearch\ Home{]}/config} folder. The main configuration
file is \texttt{elasticsearch.yml}, used for configuring Elasticsearch
modules.

To set the name of the Elasticsearch cluster, open
\texttt{{[}Elasticsearch\ Home{]}/config/elasticsearch.yml} and specify

\begin{verbatim}
cluster.name: LiferayElasticsearchCluster
\end{verbatim}

Since \texttt{LiferayElasticsearchCluster} is the default name given to
the cluster in the Liferay DXP Elasticsearch connector, this works just
fine. Of course, you can name your cluster whatever you want (we humbly
submit the recommendation
\texttt{clustery\_mcclusterface}).\hyperref[footnote1]{1} Configure your
node name using the same syntax (setting the \texttt{node.name}
property). There's no client setting for this, it exists only in each
Elasticsearch node's \texttt{elasticsearch.yml} file.

If you'd rather work from the command line than in the configuration
file, navigate to Elasticsearch Home and enter

\begin{verbatim}
./bin/elasticsearch --cluster.name clustery_mcclusterface --node.name nody_mcnodeface
\end{verbatim}

Feel free to change the node name or the cluster name. Once you
configure Elasticsearch to your liking, start it up.

\section{Starting Elasticsearch}\label{starting-elasticsearch}

Start Elasticsearch by navigating to Elasticsearch Home and typing

\begin{verbatim}
./bin/elasticsearch
\end{verbatim}

if you run Linux, or

\begin{verbatim}
\bin\elasticsearch.bat
\end{verbatim}

if you run Windows.

To run as a daemon in the background, add the \texttt{-d} switch to
either command:

\begin{verbatim}
./bin/elasticsearch -d
\end{verbatim}

Once both Elasticsearch and Liferay DXP are installed and running,
introduce them to each other.

\section{Configuring the Liferay Elasticsearch
Connector}\label{configuring-the-liferay-elasticsearch-connector-1}

The Elasticsearch connector provides integration between Elasticsearch
and the portal. Before configuring the connector, make sure
Elasticsearch is running.

There are two ways to configure the connector:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \hyperref[configuring-the-connector-in-the-control-panel]{Use the
  System Settings application in the Control Panel.}
\item
  \hyperref[configuring-the-connector-with-an-osgi-config-file]{Manually
  create an OSGi configuration file.}
\end{enumerate}

It's convenient to configure the Elasticsearch connector from System
Settings, but this is often only possible during development and
testing. If you're not familiar with System Settings, read about it
\href{/docs/7-2/user/-/knowledge_base/u/system-settings}{here}. Remember
that you can generate configuration files for deployment to other
systems by configuring System Settings, and then exporting the
\texttt{.config} file with your configuration.

\section{Configuring the Connector in the Control
Panel}\label{configuring-the-connector-in-the-control-panel}

To configure the Elasticsearch connector from the System Settings
application,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start Liferay DXP.
\item
  Navigate to \emph{Control Panel} → \emph{Configuration} → \emph{System
  Settings} → \emph{Platform}.
\item
  Find the \emph{Elasticsearch} entry (scroll down and browse to it or
  use the search box) and click the Actions icon
  (\pandocbounded{\includegraphics[keepaspectratio]{./images/icon-actions.png}}),
  then \emph{Edit}.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/cfg-elasticsearch-sys-settings.png}}
  \caption{Use the System Settings application in Liferay DXP's Control
  Panel to configure the Elasticsearch connector.}
  \end{figure}
\item
  Make any edits to the configuration and click \emph{Save}.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/cfg-elasticsearch-sys-settings2.png}}
  \caption{Configure the Elasticsearch connector's settings. Make sure
  you set the Operation Mode to \emph{Remote}.}
  \end{figure}
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} If you switch operation modes (\texttt{EMBEDDED} →
\texttt{REMOTE}), you must trigger a re-index. Navigate to \emph{Control
Panel} → \emph{Configuration} → \emph{Search}, and click \emph{Execute}
next to \emph{Reindex all search indexes.}

\noindent\hrulefill

\section{\texorpdfstring{Configuring the Connector with an OSGi
\texttt{.config}
File}{Configuring the Connector with an OSGi .config File}}\label{configuring-the-connector-with-an-osgi-.config-file}

When preparing a system for production deployment, you want to use a
repeatable deployment process. Therefore, it's best to use the OSGi
configuration file, where your configuration is maintained in a
controlled source.

Follow these steps to configure the Elasticsearch connector using a
configuration file:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create the following file:

\begin{verbatim}
 [Liferay_Home]/osgi/configs/com.liferay.portal.search.elasticsearch7.configuration.ElasticsearchConfiguration.config
\end{verbatim}
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Elasticsearch 6:** The name of the `.config` file for the Elasticsearch
 6 connector is
 `com.liferay.portal.search.elasticsearch6.configuration.ElasticsearchConfiguration.config`
\end{verbatim}

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Add configurations to the file, in the format
  \texttt{propertyName="Value"}. For example,

\begin{verbatim}
 operationMode="REMOTE"
 # If running Elasticsearch from a different computer:
 #transportAddresses="ip.of.elasticsearch.node:9300"
 # Highly recommended for all non-production usage (e.g., practice, tests, diagnostics):
 #logExceptionsOnly="false"
\end{verbatim}
\item
  Start Liferay DXP or re-index if already running.
\end{enumerate}

As you can see from the System Settings entry for Elasticsearch, there
are a lot more configuration options available that help you tune your
system for optimal performance.

What follows here are some known good configurations for clustering
Elasticsearch. These, however, can't replace the manual process of
tuning, testing under load, and tuning again, so we encourage you to
examine the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/important-settings.html}{Elasticsearch
documentation} and go through that process once you have a working
configuration.

\section{Configuring a Remote Elasticsearch
Host}\label{configuring-a-remote-elasticsearch-host}

In production systems Elasticsearch and Liferay DXP are installed on
different servers. To make Liferay DXP aware of the Elasticsearch
cluster, set

\begin{verbatim}
transportAddresses=[IP address of Elasticsearch Node]:9300
\end{verbatim}

Here's an example that sets the IP address of two nodes in the
Elasticsearch cluster:

\begin{verbatim}
transportAddresses=["192.168.1.1:9300","192.168.1.2:9300"]
\end{verbatim}

Set this in the Elasticsearch connector's OSGi configuration file. List
as many or as few Elasticsearch nodes in this property as you want. This
tells Liferay DXP the IP address or host name where search requests
should be sent. If using System Settings, set the value in the
\emph{Transport Addresses} property.

\noindent\hrulefill

\textbf{Note:} In an Elasticsearch cluster you can list the transport
addresses for multiple Elasticsearch nodes as a comma-separated list in
the \texttt{transportAddresses} property. If you set only one transport
address, Liferay DXP loses contact with Elasticsearch if that node goes
down.

\noindent\hrulefill

On the Elasticsearch side, set the \texttt{network.host} property in
your \texttt{elaticsearch.yml} file. This property simultaneously sets
both the \emph{bind host} (the host where Elasticsearch listens for
requests) and the \emph{publish host} (the host name or IP address
Elasticsearch uses to communicate with other nodes). See
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-network.html}{here}
for more information.

\section{Clustering Elasticsearch in Remote Operation
Mode}\label{clustering-elasticsearch-in-remote-operation-mode}

To cluster Elasticsearch, first set
\texttt{node.max\_local\_storage\_nodes} to be something greater than
\texttt{1}. When you run the Elasticsearch start script, a new local
storage node is added to the cluster. If you want four nodes running
locally, for example, run \texttt{./bin/elasticsearch} four times. See
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-node.html\#max-local-storage-nodes}{here}
for more information.

Configure the number of shards and replicas in the Elasticsearch 6
connector, using the \texttt{indexNumberOfShards} and
\texttt{indexNumberOfReplicas} properties to specify the number of
primary shards and number of replica shards, respectively.
Elasticsearch's default configuration works for a cluster of up to ten
nodes, since the default number of shards is \texttt{5} and the default
number of replica shards is \texttt{1}.

\noindent\hrulefill

\textbf{Note:} Elasticsearch uses the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/6.x/modules-discovery-zen.html}{Zen
Discovery Module} by default, which provides unicast discovery.
Additionally, nodes in the cluster communicate using the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-transport.html}{Transport
Module}, through TCP. See the Elasticsearch documentation for the
available properties (to be set in the \texttt{elasticsearch.yml} file),
and the Liferay DXP Elasticsearch connector's settings for the
connector's available settings.

At a minimum, provide the list of hosts (as \texttt{host:port}) to act
as gossip routers during unicast discovery in the
\texttt{elasticsearch.yml}:

\begin{verbatim}
 discovery.zen.ping.unicast.hosts: ["node1.ip.address", "node2.ip.address"]
\end{verbatim}

For example,

\begin{verbatim}
 discovery.zen.ping.unicast.hosts: ["10.10.10.5", "10.10.10,.5:9305"]
\end{verbatim}

For more information on configuring an Elasticsearch cluster, see the
documentation on
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index-modules.html}{Elasticsearch
Index Settings}.

\noindent\hrulefill

\section{Elasticsearch Connector System Settings, By Operation
Mode}\label{elasticsearch-connector-system-settings-by-operation-mode}

Some of the settings available for the Elasticsearch connector are
applicable for only one operation mode (REMOTE or EMBEDDED). Refer to
the table below:

Connector Setting/Operation Mode \textbar{} EMBEDDED \textbar{} REMOTE
\textbar{} \texttt{clusterName} \textbar{} x \textbar{} x
\texttt{operationMode} \textbar{} x \textbar{} x
\texttt{indexNamePrefix} \textbar{} x \textbar{} x
\texttt{indexNumberOfReplicas*} \textbar{} x \textbar{} x
\texttt{indexNumberOfShards*} \textbar{} x \textbar{} x
\texttt{bootstrapMlockAll} \textbar{} x \textbar{} -
\texttt{logExceptionsOnly} \textbar{} x \textbar{} x
\texttt{retryOnConflict} \textbar{} x \textbar{} x
\texttt{discoveryZenPingUnicastHostsPort} \textbar{} x \textbar{} -
\texttt{networkHost} \textbar{} x \textbar{} - \texttt{networkBindHost}
\textbar{} x \textbar{} - \texttt{networkPublishHost} \textbar{} x
\textbar{} - \texttt{transportTcpPort} \textbar{} x \textbar{} -
\texttt{transportAddresses} \textbar{} - \textbar{} x
\texttt{clientTransportSniff} \textbar{} - \textbar{} x
\texttt{clientTransportIgnoreClusterName} \textbar{} - \textbar{} x
\texttt{clientTransportPingTimeout*} \textbar{} - \textbar{} x
\texttt{clientTransportNodesSamplerInterval} \textbar{} - \textbar{} x
\texttt{httpEnabled} \textbar{} x \textbar{} - \texttt{httpCORSEnabled}
\textbar{} x \textbar{} - \texttt{httpCORSAllowOrigin} \textbar{} x
\textbar{} - \texttt{httpCORSConfigurations} \textbar{} x \textbar{} -
\texttt{additionalConfigurations} \textbar{} x \textbar{} x
\texttt{additionalIndexConfigurations} \textbar{} x \textbar{} x
\texttt{additionalTypeMappings} \textbar{} x \textbar{} x
\texttt{overrideTypeMappings} \textbar{} x \textbar{} x

1 This is, of course, a nod to all those fans of
\href{http://www.theatlantic.com/international/archive/2016/05/boaty-mcboatface-parliament-lessons/482046}{Boaty
Mcboatface}.

\chapter{Advanced Configuration of the Liferay Elasticsearch
Connector}\label{advanced-configuration-of-the-liferay-elasticsearch-connector}

The default configuration for Liferay's Elasticsearch connector module
is set in a Java class called \texttt{ElasticsearchConfiguration}.

While the Elasticsearch connector has a lot of configuration options out
of the box, you might find an Elasticsearch configuration you need that
isn't provided by default. In this case, add the configuration options
you need. If something is configurable for Elasticsearch, it's
configurable using the Elasticsearch connector.

\section{Adding Settings and Mappings to the Liferay Elasticsearch
Connector}\label{adding-settings-and-mappings-to-the-liferay-elasticsearch-connector}

Think of the available configuration options as being divided into two
groups: the most common ones that are easily configured, and more
complex configurations requiring a more brute-force approach: these
include the \texttt{additionalConfigurations},
\texttt{additionalIndexConfigurations}, \texttt{additionalTypeMappings},
and \texttt{overrideTypeMappings} settings.

\href{./images/cfg-elasticsearch-additional-configs.png}{Figure
1: You can add Elasticsearch configurations to the ones currently
available in System Settings.}

\section{Additional Configurations}\label{additional-configurations}

The \texttt{additionalConfigurations} configuration defines extra
settings (in YAML) for the embedded Elasticsearch. This is only useful
for testing environments using the embedded Elasticsearch server. Any
node settings normally set in \texttt{elasticsearch.yml} can be declared
here. See the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index.html}{Elasticsearch
documentation} for a description of all possible node settings.

\section{Adding Index Configurations}\label{adding-index-configurations}

The \texttt{additionalIndexConfigurations} configuration defines extra
settings (in JSON or YAML) that are applied to the Liferay DXP index
when it's created. For example, you can create custom analyzers and
filters using this setting. For a complete list of available settings,
see the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index-modules.html}{Elasticsearch
reference}.

Here's an example that shows how to configure
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index-modules-analysis.html}{analysis}
that can be applied to a field or a dynamic template (see
\hyperref[overriding-type-mappings]{below} for an example application to
a dynamic template).

\begin{verbatim}
{  
    "analysis": {
        "analyzer": {
            "kuromoji_liferay_custom": {
                "filter": [
                    "cjk_width",
                    "kuromoji_baseform",
                    "pos_filter"
                ],
                "tokenizer": "kuromoji_tokenizer"
            }
        },
        "filter": {
            "pos_filter": {
                "type": "kuromoji_part_of_speech"
            }
        }
    }
}
\end{verbatim}

\section{Adding Type Mappings}\label{adding-type-mappings}

\texttt{additionalTypeMappings} defines extra mappings for the
\texttt{LiferayDocumentType} type definition. These are applied when the
index is created. Add the mappings using JSON syntax. For more
information see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/mapping.html}{here}
and
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/indices-put-mapping.html}{here}.
Use \texttt{additionalTypeMappings} for new field (\texttt{properties})
mappings and new dynamic templates, but don't try to override existing
mappings. If any of the mappings set here overlap with existing
mappings, index creation fails. Use \texttt{overrideTypeMappings} to
replace default mappings.

As with dynamic templates, you can add sub-field mappings to Liferay
DXP's type mapping. These are referred to as
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/properties.html}{properties}
in Elasticsearch.

\begin{verbatim}
{ 
    "LiferayDocumentType": {  
        "properties": {   
            "fooName": {
                "index": "true",
                "store": "true",
                "type": "keyword"
            }
        }   
    }
}
\end{verbatim}

See
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/mapping-types.html}{here}
for more details on Elasticsearch's field datatypes.

The above example shows how a \texttt{fooName} field might be added to
Liferay DXP's type mapping. Because \texttt{fooName} is not an existing
property in the mapping, it works fine. If you try to override an
existing property mapping, index creation fails. Instead use the
\texttt{overrideTypeMappings} setting to override \texttt{properties} in
the mapping.

To see that your additional mappings have been added to the
\texttt{LiferayDocumentType}, use \texttt{curl} to access this URL after
saving your additions and re-indexing:

\begin{verbatim}
curl http://[HOST]:[ES_PORT]/liferay-[COMPANY_ID]/_mapping/LiferayDocumentType?pretty
\end{verbatim}

Here's what it would look like for an Elasticsearch instance running on
\texttt{localhost:9200}, with a Liferay DXP Company ID of
\texttt{20116}:

\begin{verbatim}
curl http://localhost:9200/liferay-20116/_mapping/LiferayDocumentType?pretty
\end{verbatim}

In the above URL, \texttt{liferay-20116}is the index name. Including it
indicates that you want to see the mappings that were used to create the
index with that name.

\section{Overriding Type Mappings}\label{overriding-type-mappings}

Use \texttt{overrideTypeMappings} to override Liferay DXP's default type
mappings. This is an advanced feature that should be used only if
strictly necessary. If you set this value, the default mappings used to
define the Liferay Document Type in Liferay DXP source code (for
example, \texttt{liferay-type-mappings.json}) are ignored entirely, so
include the whole mappings definition in this property, not just the
segment you're modifying. To make a modification, find the entire list
of the current mappings being used to create the index by navigating to
the URL

\begin{verbatim}
http://[HOST]:[ES_PORT]/liferay-[COMPANY_ID]/_mapping/LiferayDocumentType?pretty
\end{verbatim}

Copy the contents in as the value of this property (either into System
Settings or your OSGi configuration file). Leave the opening curly brace
\texttt{\{}, but delete lines 2-4 entirely:

\begin{verbatim}
"liferay-[COMPANY_ID]": {
    "mappings" : {
        "LiferayDocumentType" : {
\end{verbatim}

Then, from the end of the mappings, delete the concluding three curly
braces.

\begin{verbatim}
        }
    }
}
\end{verbatim}

Now modify whatever mappings you'd like. The changes take effect once
you save the changes and trigger a re-index from Server Administration.

Here's a partial example, showing a
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/dynamic-templates.html}{dynamic
template} that uses the analysis configuration from
\texttt{additionalIndexConfigurations} to analyze all string fields that
end with \texttt{\_ja}. You'd include this with all the other default
mappings, replacing the provided \texttt{template\_ja} with this custom
one:

\begin{verbatim}
{
    "LiferayDocumentType": {
        "dynamic_templates": [
            {
                "template_ja": {
                    "mapping": {
                        "analyzer": "kuromoji_liferay_custom",
                        "index": "analyzed",
                        "store": "true",
                        "term_vector": "with_positions_offsets",
                        "type": "string"
                    },
                    "match": "\\w+_ja\\b|\\w+_ja_[A-Z]{2}\\b",
                    "match_mapping_type": "string",
                    "match_pattern": "regex"
                }
                ...
            }
        ]
    }
}
\end{verbatim}

\section{Multi-line YAML
Configurations}\label{multi-line-yaml-configurations}

If you configure the settings from the last section using an OSGi
configuration file, you might find yourself needing to write YAML
snippets that span multiple lines. The syntax for that is
straightforward and just requires appending each line with
\texttt{\textbackslash{}n\textbackslash{}}, like this:

\begin{verbatim}
additionalConfigurations=\
                    cluster.routing.allocation.disk.threshold_enabled: false\n\
                    cluster.service.slow_task_logging_threshold: 600s\n\
                    index.indexing.slowlog.threshold.index.warn: 600s\n\
                    index.search.slowlog.threshold.fetch.warn: 600s\n\
                    index.search.slowlog.threshold.query.warn: 600s\n\
                    monitor.jvm.gc.old.warn: 600s\n\
                    monitor.jvm.gc.young.warn: 600s
\end{verbatim}

From simple configurations to overriding existing type mappings,
Elasticsearch and Liferay's connector to Elasticsearch are configurable.

\chapter{Elasticsearch Connector Settings:
Reference}\label{elasticsearch-connector-settings-reference}

Elasticsearch is the default search engine for 7.0. The connection is
managed through the \emph{Liferay Connector to Elasticsearch
{[}Version{]}}, and is configurable through System Settings or an OSGi
configuration file named

\begin{verbatim}
com.liferay.portal.search.elasticsearch6.configuration.ElasticsearchConfiguration.config
\end{verbatim}

If you are using Elasticsearch 7, your configuration file must be named

\begin{verbatim}
com.liferay.portal.search.elasticsearch7.configuration.ElasticsearchConfiguration.config
\end{verbatim}

Deploy the file to \texttt{{[}Liferay\_Home{]}/osgi/configs} and a
listener auto-detects it.

The list below is all the configuration settings for Liferay's default
Elasticsearch connector, in the order they appear in the System Settings
application (The \emph{Elasticsearch {[}Version{]}} entry under the
\emph{Search} category):

\begin{description}
\tightlist
\item[\texttt{clusterName=LiferayElasticsearchCluster}]
A String value that sets the name of the cluster to integrate with. This
name should match the remote cluster when Operation Mode is set to
remote. (See also: remote operation mode)
\item[\texttt{operationMode=EMBEDDED}]
There are two operation modes you can choose from: EMBEDDED or REMOTE.
Set to REMOTE to connect to a remote standalone Elasticsearch cluster.
Set to EMBEDDED to start Liferay with an internal Elasticsearch
instance. Embedded operation mode is unsupported for production
environments.
\item[\texttt{indexNamePrefix=liferay-}]
Set a String value to use as the prefix for the search index name. The
default value should not be changed under normal conditions. If you
change it, you must also perform a \emph{reindex all} operation for the
portal and then manually delete the old index using the Elasticsearch
administration console.
\end{description}

\texttt{indexNumberOfReplicas=} Set the number of replicas for each
index. If left unset, no replicas are used. A full reindex is required
to make changes take effect.

\texttt{indexNumberOfShards=} Set the number of index shards to use when
a Liferay index is created. If left unset, a single shard is used. A
full reindex is required to make changes take effect.

\begin{description}
\tightlist
\item[\texttt{bootstrapMlockAll=false}]
A boolean setting that, when set to \texttt{true}, tries to lock the
process address space into RAM, preventing any Elasticsearch memory from
being swapped out (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/setup-configuration-memory.html\#bootstrap-memory_lock}{here})
for more information)
\item[\texttt{logExceptionsOnly=true}]
A boolean setting that, when set to true, only logs exceptions from
Elasticsearch, and does not rethrow them.
\item[\texttt{retryOnConflict=5}]
Set an int value for the number of retries to attempt if a version
conflict occurs because the document was updated between getting it and
updating it (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/docs-update.html\#docs-update-api-query-params}{here}
for more information).
\item[\texttt{discoveryZenPingUnicastHostsPort=9300-9400}]
Set a String value for the range of ports to use when building the value
for discovery.zen.ping.unicast.hosts. Multiple Elasticsearch nodes on a
range of ports can act as gossip routers at the same computer (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-discovery-hosts-providers.html}{here}
for more information).
\item[\texttt{networkHost=}]
Set this String value to instruct the node to bind to this hostname or
IP address and publish (advertise) this host to other nodes in the
cluster. This is a shortcut which sets the bind host and the publish
host at the same time (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-network.html\#common-network-settings}{here}
for more information).
\item[\texttt{networkBindHost=}]
Set the String value of the network interface(s) a node should bind to
in order to listen for incoming requests (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-network.html\#advanced-network-settings}{here}
for more information).
\item[\texttt{networkPublishHost=}]
Set the String value of a single interface that the node advertises to
other nodes in the cluster, so that those nodes can connect to it (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-network.html\#advanced-network-settings}{here}
for more information).
\item[\texttt{transportTcpPort=}]
Set the String value for the port to bind for communication between
nodes. Accepts a single value or a range (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-transport.html\#_tcp_transport}{here}
for more information).
\item[\texttt{transportAddresses=localhost:9300}]
Set the String values for the addresses of the remote Elasticsearch
nodes to connect to. This value is required when Operation Mode is set
to remote (see
\href{https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.x/transport-client.html}{here}
for more information). Specify as many or few nodes as you see fit.
\item[\texttt{clientTransportSniff=true}]
Set this boolean to true to enable cluster sniffing and dynamically
discover available data nodes in the cluster (see
\href{https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.x/transport-client.html}{here}
for more information).
\item[\texttt{clientTransportIgnoreClusterName=false}]
Set this boolean to true to ignore cluster name validation of connected
nodes (see
\href{https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.x/transport-client.html}{here}
for more information).
\end{description}

\texttt{clientTransportPingTimeout=} The time (in seconds) the client
node waits for a ping response from a node. If unset, the default
Elasticsearch \texttt{client.transport.ping\_timeout} is used.

\begin{description}
\tightlist
\item[\texttt{clientTransportNodesSamplerInterval=}]
Set this String value to instruct the client node on how often to sample
/ ping the nodes listed and connected (see
\href{https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.x/transport-client.html}{here}
for more information).
\item[\texttt{httpEnabled=true}]
Set this boolean to false to disable the http layer entirely on nodes
which are not meant to serve REST requests directly. As this setting was
\href{https://www.elastic.co/guide/en/elasticsearch/reference/6.7/release-notes-6.3.0.html\#deprecation-6.3.0}{deprecated
in Elasticsearch 6.3}, the connector's corresponding setting is now also
deprecated. This setting was only used for configuring the embedded
Elasticsearch server, so its deprecation should have minimal impact to
production deployments.
\item[\texttt{httpCORSEnabled=true}]
Set this boolean to false to disable cross-origin resource sharing,
i.e.~whether a browser on another origin can do requests to
Elasticsearch. If disabled, web front end tools like elasticsearch-head
may be unable to connect (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-http.html\#_settings}{here}
for more information).
\item[\texttt{httpCORSAllowOrigin=/https?:\textbackslash{}\textbackslash{}/\textbackslash{}\textbackslash{}/localhost(:{[}0-9{]}+)?/}]
Set the String origins to allow when HTTP CORS is enabled (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-http.html\#_settings}{here}
for more information).
\item[\texttt{httpCORSConfigurations=}]
Set the String values for custom settings for HTTP CORS, in YML format
(\texttt{elasticsearch.yml}) (see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/modules-http.html\#_settings}{here}
for more information).
\item[\texttt{additionalConfigurations=}]
Set the String values for custom settings for embedded Elasticsearch, in
YML format. See: Adding Settings to the Liferay Elasticsearch Connector
\item[\texttt{additionalIndexConfigurations=}]
Set the String values for custom settings for the Liferay index, in JSON
or YML format (refer to the Elasticsearch Create Index API for more
information). See: Adding Settings to the Liferay Elasticsearch
Connector
\item[\texttt{additionalTypeMappings=}]
Set the String values for custom mappings for the
\texttt{LiferayDocumentType}, in JSON format (refer to the Elasticsearch
Put Mapping API for more information) See: Adding Settings to the
Liferay Elasticsearch Connector
\end{description}

\texttt{overrideTypeMappings=} Settings here override Liferay DXP's
default type mappings. This is an advanced feature that should be used
only if strictly necessary. If you set this value, the default mappings
used to define the Liferay Document Type in Liferay DXP source code (for
example, \texttt{liferay-type-mappings.json}) are ignored entirely, so
include the whole mappings definition in this property, not just the
segment you're modifying.

\section{Configurations only Affecting the Embedded Elasticsearch
Server}\label{configurations-only-affecting-the-embedded-elasticsearch-server}

These settings (defined above) are only meant to use while configuring
the embedded Elasticsearch server. Configuring these will elicit no
effect on remote Elasticsearch installations:

\begin{itemize}
\tightlist
\item
  \texttt{bootstrapMlockAll}
\item
  \texttt{discoveryZenPingUnicastHostsPort}
\item
  \texttt{networkHost}
\item
  \texttt{networkBindHost}
\item
  \texttt{networkPublishHost}
\item
  \texttt{transportTcpPort}
\item
  \texttt{httpEnabled}
\item
  \texttt{httpCORSEnabled}
\item
  \texttt{httpCORSAllowOrigin}
\item
  \texttt{httpCORSConfigurations}
\end{itemize}

You can easily configure these settings in the System Setting
application, or as mentioned above, you can specify them in a deployable
OSGi \texttt{.config} file.

\chapter{Installing Liferay Enterprise Search
Security}\label{installing-liferay-enterprise-search-security}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The very first thing you must do to secure Elasticsearch is enable
X-Pack Security. After that you can begin configuring authentication and
Transport Layer Security.

\noindent\hrulefill

\textbf{Elasticsearch 6.x:} If you're using Elasticsearch 6, you'll need
a Liferay Enterprise Search (LES) subscription to use X-Pack. Starting
with the Liferay Connector to Elasticsearch 7 (available on Liferay
Marketplace), X-Pack security is included by default. X-Pack monitoring
still requires LES.

\noindent\hrulefill

\section{Enabling X-Pack Security}\label{enabling-x-pack-security}

To enable security, add this setting in \texttt{elasticsearch.yml}:

\begin{verbatim}
xpack.security.enabled: true
\end{verbatim}

Now you can set up X-Pack users.

\section{Setting Up X-Pack Users}\label{setting-up-x-pack-users}

In a system using X-Pack Security and X-Pack Monitoring, these built-in
X-Pack users are important:

\begin{itemize}
\tightlist
\item
  \texttt{kibana}
\item
  \texttt{elastic}
\end{itemize}

Set the passwords for all X-Pack's
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/built-in-users.html}{built-in
users}. The \texttt{setup-passwords} command is the simplest method to
set the built-in users' first-use passwords for the first time. To
update a password subsequently, use Kibana's UI or the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/security-api-change-password.html}{Change
Password API}.

The \texttt{interactive} argument sets the passwords for all built-in
users. The configuration shown in these articles assumes you set all
passwords to \emph{liferay}. Of course, that's not recommended for
production systems.

\begin{verbatim}
./bin/elasticsearch-setup-passwords interactive
\end{verbatim}

Elastic's
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/setup-passwords.html}{setup-passwords
command} documentation describes additional options.

Since you're securing Elasticsearch, remember the \texttt{elastic}
user's password.

Enable transport layer security on each node.

\section{Enabling Transport Layer
Security}\label{enabling-transport-layer-security}

The following instructions for enabling TLS use \texttt{liferay} as the
password whenever one is needed. Use your own passwords for your
installation.

\noindent\hrulefill

\textbf{Important:} Elasticsearch and Liferay DXP must share the keys
and certificates used to configure TLS. Copy them between servers and
point to the local copy in the corresponding configuration files.

\noindent\hrulefill

\section{Generate Node Certificates}\label{generate-node-certificates}

\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/configuring-tls.html\#node-certificates}{Generate
a node certificate} for each node. Alternatively, use a Certificate
Authority to obtain node certificates.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a certificate authority, using
  \href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/certutil.html}{X-Pack's
  \texttt{certutil}} command:

\begin{verbatim}
./bin/elasticsearch-certutil ca --pem --ca-dn CN=localhost
\end{verbatim}

  This generates a ZIP file. Unzip the contents in the
  \texttt{{[}Elasticsearch\ Home{]}/config/certs} folder.
\item
  Generate X.509 certificates and private keys using the CA from Step 1:

\begin{verbatim}
./bin/elasticsearch-certutil cert --pem --ca-cert /path/to/ca.crt --ca-key /path/to/ca.key --dns localhost --ip 127.0.0.1 --name localhost
\end{verbatim}

  This generates another ZIP file. Extract the contents in the
  \texttt{{[}Elasticsearch\ Home{]}/config/certs} folder.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} The \texttt{certutil} command defaults to using the
\emph{PKSC\#12} format for certificate generation. Since Kibana does not
work with PKSC\#12 certificates, the \texttt{-\/-pem} option (generates
the certificate in PEM format) is important if you're using X-Pack
monitoring.

\noindent\hrulefill

\textbf{Checkpoint:} You now have the following files in your
\texttt{{[}Elasticsearch\ Home{]}/config/certs} folder:

\begin{verbatim}
ca.crt
ca.key
localhost.crt
localhost.key
\end{verbatim}

\section{Enable TLS for Elasticsearch
7}\label{enable-tls-for-elasticsearch-7}

\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/configuring-tls.html\#enable-ssl}{Enable
TLS} on each node via its \texttt{elasticsearch.yml}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Enable transport layer TLS with these settings in
  \texttt{elasticsearch.yml} for inter-node communication:

\begin{verbatim}
xpack.security.transport.ssl.enabled: true
\end{verbatim}
\item
  Add the certificate, key and certificate authority paths to each
  node's \texttt{elasticsearch.yml}:

\begin{verbatim}
xpack.security.transport.ssl.certificate: certs/localhost.key
xpack.security.transport.ssl.certificate_authorities: [ "certs/ca.crt" ]
xpack.security.transport.ssl.key: certs/localhost.crt
xpack.security.transport.ssl.verification_mode: certificate
\end{verbatim}

  The example paths above assume you added the certificate to
  \texttt{Elasticsearch\ Home/config/}.
\item
  Enable TLS on the HTTP layer to encrypt client communication:

\begin{verbatim}
xpack.security.http.ssl.enabled: true
\end{verbatim}
\item
  Configure the certificate, key, and certificate authority paths to
  each node's \texttt{elasticsearch.yml}:

\begin{verbatim}
xpack.security.http.ssl.certificate_authorities: [ "certs/ca.crt" ]
xpack.security.http.ssl.certificate: certs/localhost.crt
xpack.security.http.ssl.key: certs/localhost.key
xpack.security.http.ssl.verification_mode: certificate
\end{verbatim}
\end{enumerate}

\section{Elasticsearch 6 TLS}\label{elasticsearch-6-tls}

The settings on Elasticsearch 6 were slightly different than those
presented above for Elasticsearch 7.
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/configuring-tls.html\#enable-ssl}{Enable
TLS} on each node via its \texttt{elasticsearch.yml}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add the certificate, key and certificate authority paths to each
  node's \texttt{elasticsearch.yml}:

\begin{verbatim}
xpack.ssl.certificate: certs/localhost.crt
xpack.ssl.certificate_authorities: [ "certs/ca.crt" ]
xpack.ssl.key: certs/localhost.key
xpack.ssl.verification_mode: certificate 
\end{verbatim}

  The example paths above assume you added the certificate to
  \texttt{Elasticsearch\ Home/config/}.
\item
  Enable transport layer TLS with these settings in
  \texttt{elasticsearch.yml}:

\begin{verbatim}
xpack.security.transport.ssl.enabled: true
\end{verbatim}
\item
  Enable TLS on the HTTP layer to encrypt client communication:

\begin{verbatim}
xpack.security.http.ssl.enabled: true
\end{verbatim}
\end{enumerate}

After X-Pack is installed and TLS is enabled, configure the X-Pack
Security adapter in Liferay DXP.

\section{Example Elasticsearch Security
Configuration}\label{example-elasticsearch-security-configuration}

For ease of copying and pasting, here is the complete Elasticsearch
configuration (\texttt{elasticsearch.yml}) used in this guide (with the
Elasticsearch 6 example commented out):

\begin{verbatim}
# For Elasticsearch 7.3/7.4
cluster.name: LiferayElasticsearchCluster

# X-Pack Security
xpack.security.enabled: true

## TLS/SSL settings for Transport layer
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate 
xpack.security.transport.ssl.key: certs/localhost.key
xpack.security.transport.ssl.certificate: certs/localhost.crt
xpack.security.transport.ssl.certificate_authorities : [ "certs/ca.crt" ]

# TLS/SSL settings for HTTP layer
xpack.security.http.ssl.enabled: true
xpack.security.http.ssl.verification_mode: certificate 
xpack.security.http.ssl.key: certs/localhost.key
xpack.security.http.ssl.certificate: certs/localhost.crt
xpack.security.http.ssl.certificate_authorities : [ "certs/ca.crt" ]

# Comment out when Kibana and Liferay's X-Pack Monitoring are also configured
#xpack.monitoring.collection.enabled: true

# For Elasticsearch 6.5/6.8
#cluster.name: LiferayElasticsearchCluster
#
# X-Pack Security
#xpack.security.enabled: true
#
# Enable TLS/SSL
#xpack.security.transport.ssl.enabled: true # To enable Transport level SSL for internode-communication
#xpack.security.http.ssl.enabled: true # To enable HTTP level SSL required by Kibana
#
## General TLS/SSL settings for both Transport and HTTP levels
#xpack.ssl.verification_mode: certificate 
#xpack.ssl.key: certs/localhost.key
#xpack.ssl.certificate: certs/localhost.crt
#xpack.ssl.certificate_authorities : [ "certs/ca.crt" ]
#
# Comment out when Kibana and Liferay's X-Pack Monitoring are also configured
#xpack.monitoring.collection.enabled: true
\end{verbatim}

For both Elasticsearch 6 and Elasticsearch 7, the Liferay Connector
settings are the same.

\section{Install and Configure the Liferay Enterprise Search Security
app}\label{install-and-configure-the-liferay-enterprise-search-security-app}

If you have a Liferay Enterprise Search subscription,
\href{https://web.liferay.com/group/customer/dxp/downloads/enterprise-search}{download}
the Liferay Enterprise Search Security app . Install the LPKG file by
copying it into the \texttt{Liferay\ Home/deploy} folder.

To configure the X-Pack adapter, navigate to \emph{Control Panel} →
\emph{Configuration} → \emph{System Settings}. Find the \emph{Search}
category and click on the \emph{X-Pack Security} entry. You can enter
the property values here, but it's more common to use a
\href{/docs/7-2/user/-/knowledge_base/u/understanding-system-configuration-files}{configuration
file} deployed to \texttt{{[}Liferay\ Home{]}/osgi/configs}. For the
X-Pack security connector, create a file called

\begin{verbatim}
com.liferay.portal.search.elasticsearch7.configuration.XPackSecurityConfiguration.config
\end{verbatim}

The exact contents of the file depend on your X-Pack setup. To configure
the adapter according to the Elasticsearch setup documented here,
populate the file like this:

\begin{verbatim}
sslKeyPath="/path/to/localhost.key"
sslCertificatePath="/path/to/localhost.crt"
certificateFormat="PEM"
requiresAuthentication="true"
username="elastic"
password="liferay"
sslCertificateAuthoritiesPaths="/path/to/ca.crt"
transportSSLVerificationMode="certificate"
transportSSLEnabled="true"
\end{verbatim}

The \texttt{password} should match what you set during the X-Pack
password setup above.

The certificate and key files referenced here are the same ones used on
the Elasticsearch server. Copy them to the Liferay DXP server and update
their paths in the configuration accordingly.

Enable authentication by setting \texttt{requiresAuthentication} to
\texttt{true} and providing the credentials for the Elasticsearch user.
For TLS, enable transport TLS, set the certificate verification mode and
certificate format, and provide the path to the certificate, key, and
certificate authority. Of course, the exact values depend on your X-Pack
configuration.

Here's the complete list of configuration options for the X-Pack
Connector:

\begin{itemize}
\tightlist
\item
  \texttt{sslKeyPath}
\item
  \texttt{sslCertificatePath}
\item
  \texttt{sslCertificateAuthoritiesPaths}
\item
  \texttt{certificateFormat}
\item
  \texttt{requiresAuthentication}
\item
  \texttt{username}
\item
  \texttt{password}
\item
  \texttt{transportSSLVerificationMode}
\item
  \texttt{transportSSLEnabled}
\item
  \texttt{sslKeystorePath}
\item
  \texttt{sslKeystorePassword}
\item
  \texttt{sslTruststorePath}
\item
  \texttt{sslTruststorePassword}
\end{itemize}

When you're finished configuring X-Pack Security, restart Elasticsearch.
These steps require a full cluster restart.

\section{Disabling Elasticsearch Deprecation
Logging}\label{disabling-elasticsearch-deprecation-logging}

Some Elasticsearch APIs used by Liferay's Elasticsearch 6 connector were
deprecated as of Elasticsearch 6.6 and 6.7. This can result WARN log
entries in Elasticsearch's deprecation log when Liferay DXP is
configured with Elasticsearch 6.8.x and X-Pack Security is enabled:

\begin{verbatim}
2019-07-16T14:47:05,779][WARN ][o.e.d.c.j.Joda           ] [
ode_name]'y' year should be replaced with 'u'. Use 'y' for year-of-era. Prefix your date format with '8' to use the new specifier.
[2019-07-16T14:47:06,007][WARN ][o.e.d.c.s.Settings       ] [
ode_name][xpack.ssl.certificate] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.
[2019-07-16T14:47:06,007][WARN ][o.e.d.c.s.Settings       ] [
ode_name][xpack.ssl.certificate_authorities] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.
[2019-07-16T14:47:06,008][WARN ][o.e.d.c.s.Settings       ] [
ode_name][xpack.ssl.key] setting was deprecated in Elasticsearch and will be removed in a future release! See the breaking changes documentation for the next major version.
[2019-07-16T14:47:06,463][WARN ][o.e.d.x.c.s.SSLService   ] [
ode_name]SSL configuration [xpack.http.ssl] relies upon fallback to another configuration for [key configuration, trust configuration], which is deprecated.
[2019-07-16T14:47:06,464][WARN ][o.e.d.x.c.s.SSLService   ] [
ode_name]SSL configuration [xpack.security.transport.ssl.] relies upon fallback to another configuration for [key configuration, trust configuration], which is deprecated.
\end{verbatim}

These warnings do not signal any functional issues, and can be disabled
(see
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/logging.html\#deprecation-logging}{here}
to learn how).

\chapter{Backing Up Elasticsearch}\label{backing-up-elasticsearch}

\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index-modules.html\#index-modules-settings}{Elasticsearch
replicas} protect against a node going down, but they won't help you
with a catastrophic failure. Only good backup practices can help you
then.

Back up and restore your Elasticsearch cluster in three steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Configure a repository
\item
  Make a snapshot of the cluster
\item
  Restore from the snapshot
\end{enumerate}

For more detailed information, refer to the
\href{https://www.elastic.co/guide/en/elasticsearch/guide/master/administration.html}{Elasticsearch
administration guide}, and in particular to the documentation on the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/snapshot-restore.html}{Snapshot
and Restore module}.

\section{Creating a Repository}\label{creating-a-repository}

First
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/snapshots-register-repository.html}{create
a repository} to store your snapshots. Several repository types are
supported:

\begin{itemize}
\tightlist
\item
  Shared file system, such as a Network File System or NAS
\item
  Amazon S3
\item
  HDFS (Hadoop Distributed File System)
\item
  Azure Cloud
\end{itemize}

If using a shared file system repository type, first register the path
to the shared file system in each node's \texttt{elasticsearch.yml}
using
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/snapshots-register-repository.html\#snapshots-filesystem-repository}{the
path.repo setting}.

\begin{verbatim}
path.repo: ["path/to/shared/file/system/"]
\end{verbatim}

Once the path to the folder hosting the repository is registered (make
sure the folder exists), create the repository with a PUT command. For
example,

\begin{verbatim}
curl -X PUT "localhost:9200/_snapshot/test_backup" -H 'Content-Type: application/json' -d'
{
  "type": "fs",
  "settings": {
    "location": "/path/to/shared/file/system/"
  }
}'
\end{verbatim}

Replace \texttt{localhost:9200} with the proper \texttt{hostname:port}
combination for your system, replace \texttt{test\_backup} with the name
of the repository to create, and use the absolute path to your shared
file system in the \texttt{location}.

If the repository is set up successfully, you see this message:

\begin{verbatim}
{"acknowledged":true}
\end{verbatim}

Once the repository exists, you can start creating snapshots.

\section{Taking Snapshots of the
Cluster}\label{taking-snapshots-of-the-cluster}

The easiest snapshot approach is to create a
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/snapshots-take-snapshot.html}{snapshot
of all the indexes in your cluster}. For example,

\begin{verbatim}
curl -XPUT localhost:9200/_snapshot/test_backup/snapshot_1
\end{verbatim}

If \texttt{\{"accepted":true\}} appears in the terminal, the snapshot
was a success.

It's possible to be more selective when taking snapshots. For example,
if you use LES Monitoring, you can exclude the monitoring indexes.
Explicitly declare the indexes to include in the snapshot. For example,

\begin{verbatim}
curl -XPUT localhost:9200/_snapshot/test_backup/snapshot_2
{ "indices": "liferay-0,liferay-20116" }
\end{verbatim}

\textbf{Note:} For a list of all the Elasticsearch indexes, use this
command:

\begin{verbatim}
curl -X GET "localhost:9200/_cat/indices?v"
\end{verbatim}

This shows the index metrics:

\begin{verbatim}
health status index         uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   liferay-20099 obqiNE1_SDqfuz7rincrGQ   1   0        195            0    303.1kb        303.1kb
green  open   liferay-47206 3YEjtye1S9OVT0i0EZcXcw   1   0          7            0     69.7kb         69.7kb
green  open   liferay-0     shBWwpkXRxuAmGEaE475ug   1   0        147            1    390.9kb        390.9kb
\end{verbatim}

It's important to note that Elasticsearch uses a \emph{smart snapshots}
approach. To understand what that means, consider a single index. The
first snapshot includes a copy of the entire index, while subsequent
snapshots only include the delta between the first, complete index
snapshot and the current state of the index.

Eventually you'll end up with a lot of snapshots in your repository, and
no matter how cleverly you name the snapshots, you may forget what some
snapshots contain. For this purpose, the Elasticsearch API provides
getting information about any snapshot. For example:

\begin{verbatim}
curl -XGET localhost:9200/_snapshot/test_backup/snapshot_1
\end{verbatim}

returns

\begin{verbatim}
{"snapshots":[
    {"snapshot":"snapshot_1",
    "uuid":"WlSjvJwHRh-xlAny7zeW3w",
    "version_id":6.80399,
    "version":"6.8.2",
    "indices":["liferay-20099","liferay-0","liferay-47206"],
    "state":"SUCCESS",
    "start_time":"2018-08-15T21:40:17.261Z",
    "start_time_in_millis":1534369217261,
    "end_time":"2018-08-15T21:40:17.482Z",
    "end_time_in_millis":1534369217482,
    "duration_in_millis":221,
    "failures":[],
    "shards":{
        "total":3,
        "failed":0,
        "successful":3
        
        }
    }
]}
\end{verbatim}

There's lots of useful information here, including which indexes were
included in the snapshot.

If you want to get rid of a snapshot, use the \texttt{DELETE} command.

\begin{verbatim}
curl -XDELETE localhost:9200/_snapshot/test_backup/snapshot_1
\end{verbatim}

You might trigger creation of a snapshot and regret it (for example, you
didn't want to include all the indexes in the snapshot). If your
snapshots contain a lot of data, this can cost time and resources. To
cancel the ongoing creation of a snapshot, use the same \texttt{DELETE}
command. The snapshot process is terminated and the partial snapshot is
deleted from the repository.

\section{Restoring from a Snapshot}\label{restoring-from-a-snapshot}

What good is a snapshot if you can't use it to
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/snapshots-restore-snapshot.html}{restore
your search indexes} in case of catastrophic failure? Use the
\texttt{\_restore} API to restore all the snapshot's indexes:

\begin{verbatim}
curl -XPOST localhost:9200/_snapshot/test_backup/snapshot_1/_restore
\end{verbatim}

Restore only specific indexes from a snapshot by passing in the
\texttt{indices} option, and rename the indexes using the
\texttt{rename\_pattern} and \texttt{rename\_replacement} options:

\begin{verbatim}
curl -XPOST
localhost:9200/_snapshot/test_backup/snapshot_1/_restore
{
    "indices": "liferay-20116",
    "rename_pattern": "liferayindex_(.+)",
    "rename_replacement": "restored_liferayindex_$1"
}
\end{verbatim}

This restores only the index named \texttt{liferay-20116index\_1} from
the snapshot. The \texttt{rename...} settings specify that the beginning
\texttt{liferayindex\_} are replaced with
\texttt{restored\_liferayindex\_}, so \texttt{liferay-20116index\_1}
becomes \texttt{restored\_liferay-20116index\_1}.

As with the process for taking snapshots, an errant restored index can
be canceled with the \texttt{DELETE} command:

\begin{verbatim}
curl -XDELETE localhost:9200/restored_liferay-20116index_3
\end{verbatim}

Nobody likes catastrophic failure on a production system, but
Elasticsearch's API for taking snapshots and restoring indexes can help
you rest easy knowing that your search cluster can be restored if
disaster strikes. For more details and options, read Elastic's
documentation on the
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/snapshot-restore.html}{Snapshot
and Restore Module}.

\chapter{Upgrading to Elasticsearch
6.5}\label{upgrading-to-elasticsearch-6.5}

Elasticsearch 6.5.x is the default, most up-to-date supported version of
Elasticsearch for Liferay DXP. If you're upgrading @product@ and still
running Elasticsearch 6.1, it's time to upgrade your Elasticsearch
servers too. If you're setting up a new system and not already running a
remote Elasticsearch 6.1.x server, follow the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{installation
guide} to install Elasticsearch and the
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{configuration
guide} to configure the Elasticsearch adapter. Here, you'll learn to
upgrade an existing Elasticsearch 6.1.x server (or cluster) to
Elasticsearch 6.5.x:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/elasticsearch}{Install and
  configure Elasticsearch 6.5.x}.
\item
  Disable X-Pack Security in \texttt{elasticsearch.yml} unless you have
  an Liferay Enterprise Search subscription, which gives you access to
  the Liferay Enterprise Search Security app:

\begin{verbatim}
xpack.security.enabled: false
\end{verbatim}
\item
  Configure the bundled Liferay Connector to Elasticsearch 6.
\item
  Re-index all search and spell check indexes.
\end{enumerate}

\noindent\hrulefill

\textbf{Before Proceeding,} back up your existing data before upgrading
Elasticsearch. If something goes wrong during or after the upgrade, roll
back to the previous version using the uncorrupted index snapshots. See
\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-elasticsearch}{here}
for more information.

\noindent\hrulefill

Learn about configuring Elasticsearch
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{here}.

\section{Re-index}\label{re-index}

Once the Elasticsearch adapter is installed and talking to the
Elasticsearch cluster, navigate to \emph{Control Panel} →
\emph{Configuration} → \emph{Server Administration}, and click
\emph{Execute} for the \emph{Reindex all search indexes} entry.

You must also re-index the spell check indexes.

\section{Reverting to Elasticsearch
6.1}\label{reverting-to-elasticsearch-6.1}

Stuff happens. If that stuff involves an unrecoverable failure during
the upgrade to Elasticsearch 6.5, roll back to Elasticsearch 6.1 and
regroup.

Since your 6.1 and 6.5 are currently two separate installations, this
procedure is straightforward:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Stop the Liferay Connector to Elasticsearch 6.
\item
  Stop Elasticsearch 6.5 and make sure that the Elasticsearch 6.1
  \texttt{elasticsearch.yml} and the connector app are configured to use
  the same port (9200 by default).
\item
  Start the Elasticsearch server, and then restart the Liferay Connector
  to Elasticsearch 6.
\end{enumerate}

\chapter{Upgrading to Elasticsearch
6.8}\label{upgrading-to-elasticsearch-6.8}

Elasticsearch 6.8.x is supported for 7.0. If you're upgrading Liferay
DXP and still running Elasticsearch 6.1, it's time to upgrade your
Elasticsearch servers too. If you're setting up a new system and not
already running a remote Elasticsearch 6.1.x server, follow the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{installation
guide} to install Elasticsearch and the
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{configuration
guide} to configure the Elasticsearch adapter. Here, you'll learn to
upgrade an existing Elasticsearch 6.1.x server (or cluster) to
Elasticsearch 6.8.x:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/elasticsearch}{Install and
  configure Elasticsearch 6.8.x}.
\item
  Disable X-Pack Security in \texttt{elasticsearch.yml} unless you have
  an Liferay Enterprise Search subscription which gives you access to
  the LES Security app:

\begin{verbatim}
xpack.security.enabled: false
\end{verbatim}
\item
  Configure the bundled Liferay Connector to Elasticsearch 6.
\item
  Re-index all search and spell check indexes.
\end{enumerate}

\noindent\hrulefill

\textbf{Before Proceeding,} back up your existing data before upgrading
Elasticsearch. If something goes wrong during or after the upgrade, roll
back to the previous version using the uncorrupted index snapshots. See
\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-elasticsearch}{here}
for more information.

\noindent\hrulefill

Learn about configuring Elasticsearch
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{here}.

\section{Re-index}\label{re-index-1}

Once the Elasticsearch adapter is installed and talking to the
Elasticsearch cluster, navigate to \emph{Control Panel} →
\emph{Configuration} → \emph{Server Administration}, and click
\emph{Execute} for the \emph{Reindex all search indexes} entry.

You must also re-index the spell check indexes.

\section{Reverting to Elasticsearch
6.1}\label{reverting-to-elasticsearch-6.1-1}

Stuff happens. If that stuff involves an unrecoverable failure during
the upgrade to Elasticsearch 6.8, roll back to Elasticsearch 6.1 and
regroup.

Since your 6.1 and 6.8 are currently two separate installations, this
procedure is straightforward:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Stop the Liferay Connector to Elasticsearch 6.
\item
  Stop Elasticsearch 6.8 and make sure that the Elasticsearch 6.1
  \texttt{elasticsearch.yml} and the connector app are configured to use
  the same port (9200 by default).
\item
  Start the Elasticsearch server, and then restart the Liferay Connector
  to Elasticsearch 6.
\end{enumerate}

\chapter{Upgrading to Elasticsearch
7}\label{upgrading-to-elasticsearch-7}

Elasticsearch 7 is supported for 7.0. If you're upgrading Liferay DXP
and still running Elasticsearch 6, consider upgrading your Elasticsearch
servers too. If you're setting up a new system and not already running a
remote Elasticsearch 6 server, follow the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{installation
guide} to install Elasticsearch and the
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{configuration
guide} to configure the Elasticsearch adapter.

\noindent\hrulefill

\textbf{Before Proceeding,} back up your existing data before upgrading
Elasticsearch. If something goes wrong during or after the upgrade, roll
back to the previous version using the uncorrupted index snapshots. See
\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-elasticsearch}{here}
for more information.

\noindent\hrulefill

Here, you'll learn to upgrade an existing Elasticsearch 6 server (or
cluster) to Elasticsearch 7:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{Install
  and configure Elasticsearch 7}.
\item
  Back up the application specific indexes for Workflow Metrics and
  Result Rankings.
\item
  In 7.0, security is now provided out of the box. If you're using
  X-Pack security, enable it (it's disabled by default):

\begin{verbatim}
xpack.security.enabled: true
\end{verbatim}
\item
  Blacklist the bundled Liferay Connector to Elasticsearch 6.
\item
  Install and configure the Liferay Connector to Elasticsearch 7.
\item
  Re-index all search and spell check indexes.
\end{enumerate}

\noindent\hrulefill

\textbf{Known Issue:} See
\href{https://issues.liferay.com/browse/LPS-103938}{LPS-103938}. The
Liferay Connector to Elasticsearch 7 throws an exception in the log when
the LPKG file is deployed. There are no known functional impacts. If
unexpected errors occur, re-start the Liferay DXP server.

\noindent\hrulefill

Learn about configuring Elasticsearch
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{here}.

\section{Backing up Application-Specific
Indexes}\label{backing-up-application-specific-indexes}

To preserve data stored in application-specific indexes, use a
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/rolling-upgrades.html}{rolling
upgrade} for each index you need to preserve across the upgrade.

\noindent\hrulefill

\textbf{Synonym Sets:} If you follow the workaround for the bug
\href{https://issues.liferay.com/browse/LPS-100272}{LPS-100272}, your
Synonym sets are preserved across the upgrade, as they are stored in the
index settings directly, and not in their own index.

\noindent\hrulefill

\section{Blacklisting Elasticsearch
6}\label{blacklisting-elasticsearch-6}

To blacklist Elasticsearch 6,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a configuration file named

\begin{verbatim}
com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
\end{verbatim}
\item
  Give it these contents:

\begin{verbatim}
blacklistBundleSymbolicNames=[ \
    "com.liferay.portal.search.elasticsearch6.api", \
    "com.liferay.portal.search.elasticsearch6.impl", \
    "com.liferay.portal.search.elasticsearch6.spi", \
    "com.liferay.portal.search.elasticsearch6.xpack.security.impl", \
    "Liferay Connector to X-Pack Security [Elastic Stack 6.x] - Impl", \
    "Liferay Enterprise Search Security  - Impl" \
]
\end{verbatim}
\end{enumerate}

\section{Re-index}\label{re-index-2}

Once the Elasticsearch adapter is installed and talking to the
Elasticsearch cluster, navigate to \emph{Control Panel} →
\emph{Configuration} → \emph{Search}, and click \emph{Execute} for the
\emph{Reindex all search indexes} entry.

You must also re-index the spell check indexes.

\section{Reverting to Elasticsearch
6}\label{reverting-to-elasticsearch-6}

Stuff happens. If that stuff involves an unrecoverable failure during
the upgrade to Elasticsearch 7, roll back to Elasticsearch 6 and
regroup.

Since your Elasticsearch 6 and 7 are currently two separate
installations, this procedure takes only a few steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Stop the Liferay Connector to Elasticsearch 6.
\item
  Stop Elasticsearch 7 and make sure that the Elasticsearch 6
  \texttt{elasticsearch.yml} and the connector app are configured to use
  the same port (9200 by default).
\item
  Start the Elasticsearch server, and then restart the Liferay Connector
  to Elasticsearch 6.
\end{enumerate}

\chapter{Installing Liferay Enterprise
Search}\label{installing-liferay-enterprise-search}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

A Liferay Enterprise Search (LES) subscription gets you additional
features beyond what's available out of the box with your Liferay DXP
subscription. It includes

\begin{itemize}
\tightlist
\item
  Liferay Enterprise Search Security*
\item
  Liferay Enterprise Search Monitoring
\item
  Liferay Enterprise Search Learning to Rank
\end{itemize}

* A LES subscription is not necessary if using Elasticsearch 7 via the
\_Liferay Connector to Elasticsearch 7\_as X-Pack's security features
are bundled. See the
\href{https://help.liferay.com/hc/en-us/articles/360016511651\#Liferay-Enterprise-Search}{LES
compatibility matrix} for more information.

X-Pack is an
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/setup-xpack.html}{Elasticsearch
extension} for securing and monitoring Elasticsearch clusters. If you
use Elasticsearch, you should secure it with X-Pack. The security
features of X-Pack include authenticating access to the Elasticsearch
cluster's data and encrypting Elasticsearch's internal and external
communications. These are necessary security features for most
production systems. A LES subscription gets you access to two connectors
if you're using Elasticsearch 6: monitoring and security. Elasticsearch
7 bundles these security features, and Liferay has followed suit.
Therefore, security is bundled with the Liferay Connector to
Elasticsearch 7, and no LES subscription is necessary. Because of this,
the documentation for
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-liferay-enterprise-search-security}{installing
Liferay Enterprise Search Security} on Liferay DXP has been moved from
the LES documentation section (this section) to the
\href{/docs/7-2/deploy/-/knowledge_base/d/elasticsearch}{Elasticsearch}
installation and configuration guide. Contact
\href{https://www.liferay.com/contact-us\#contact-sales}{Liferay's Sales
department for more information}.

Here's an overview of using the LES applications with Liferay DXP:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Get an
  \href{https://help.liferay.com/hc/en-us/articles/360014400932}{Enterprise
  Search subscription}.
\item
  You'll receive a license for X-Pack monitoring. Install it on your
  Elasticsearch servers.

  \textbf{Note:} If using Elasticsearch 6, you'll also need a LES
  subscription for X-Pack security.
\item
  Download and install the Liferay Enterprise Search apps you purchased.
  Find them in the \href{https://customer.liferay.com/en/downloads}{Help
  Center Downloads page}, choosing Enterprise Search from the Product
  drop-down menu.
\item
  Configure the connectors with the proper credentials, encryption
  information, and settings.
\item
  Restart Elasticsearch. These steps require a full cluster restart.
\end{enumerate}

More detailed installation instructions are available in the article for
each LES feature.

Elastic's documentation explains additional configuration options,
features, and the architecture of
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/configuring-security.html}{X-Pack}.

\noindent\hrulefill

\textbf{Note:} Out of the box, X-Pack comes with a
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/start-trial.html}{30-day
trial}. This can be useful if there's a delay between your subscription
and receipt of your production X-Pack license.

\noindent\hrulefill

Now configure security, monitoring, and/or Learning to Rank, depending
on your needs.

\chapter{Installing Liferay Enterprise Search
Monitoring}\label{installing-liferay-enterprise-search-monitoring}

First configure security if you're using X-Pack's security features.
Then come back here for instructions on installing and configuring
Kibana (the monitoring server) with X-Pack so that Elasticsearch
(secured with X-Pack), Kibana (secured with X-Pack), and Liferay DXP can
communicate effortlessly and securely. A Liferay Enterprise Search (LES)
subscription is necessary for this integration. Contact
\href{https://www.liferay.com/contact-us\#contact-sales}{Liferay's Sales
department for more information}.

\noindent\hrulefill

\textbf{The same monitoring connector is used for Elasticsearch 6 and
7}: When first created, the Liferay Enterprise Search Monitoring app was
intended to be used only with Elasticsearch 6. However, testing revealed
that the same connector works with Elasticsearch 7, so a new connector
is not necessary if you're using Elasticsearch 7.

\noindent\hrulefill

To install X-Pack monitoring,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Tell Elasticsearch to enable data collection.
\item
  Download and install Kibana.
\item
  Configure Kibana with the proper security settings.
\item
  Install the Liferay Enterprise Search Monitoring app.
\item
  Configure the connector to communicate with Elasticsearch.
\end{enumerate}

This document assumes you're enabling security (with authentication and
encrypted communication) \emph{and} monitoring for Elasticsearch 7, but
differences in the process for Elasticsearch 6 are noted where
necessary.

\section{Enable Encrypting Communication (TLS/SSL) in Elasticsearch and
in Liferay
DXP}\label{enable-encrypting-communication-tlsssl-in-elasticsearch-and-in-liferay-dxp}

Start by following the steps in this
\href{/docs/7-2/deployment/-/knowledge_base/u/installing-liferay-enterprise-search-security}{article}
to enable TLS/SSL in your Elasticsearch and Liferay DXP installation.

Then continue by enabling data collection in Elasticsearch.

\section{Enable Data Collection}\label{enable-data-collection}

Monitoring is enabled on Elasticsearch by default, but data collection
isn't. Enable data collection by adding this line to
\texttt{elasticsearch.yml}.

\begin{verbatim}
xpack.monitoring.collection.enabled: true
\end{verbatim}

Now install Kibana.

\section{Install Kibana}\label{install-kibana}

Make sure to install the correct version of Kibana. Check the
\href{https://help.liferay.com/hc/en-us/articles/360016511651\#Liferay-Enterprise-Search}{Liferay
Enterprise Search compatibility matrix} for details.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{https://www.elastic.co/downloads/kibana}{Download Kibana} and
  extract it. The root folder is referred to as \emph{Kibana Home}.
\item
  Tell Kibana where to send monitoring data by setting Elasticsearch's
  URL in \texttt{kibana.yml}:

\begin{verbatim}
elasticsearch.hosts: [ "https://localhost:9200" ]
\end{verbatim}

  On 6.5 and below, use

\begin{verbatim}
elasticsearch.url: "https://localhost:9200"
\end{verbatim}

  If TLS/SSL is not enabled on Elasticsearch, this is an \texttt{http}
  URL, otherwise use \texttt{https}.
\item
  If not using X-Pack security, start Kibana by opening a command prompt
  to Kibana Home and entering this command:

\begin{verbatim}
./bin/kibana
\end{verbatim}
\end{enumerate}

If you're using X-Pack's security features on the Elasticsearch server,
there's additional configuration required before starting Kibana.

\section{Configure Kibana with
Authentication}\label{configure-kibana-with-authentication}

If X-Pack requires authentication to access the Elasticsearch cluster,
follow these steps or refer to
\href{https://www.elastic.co/guide/en/kibana/7.x/monitoring-xpack-kibana.html}{Elastic's
documentation}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Set the password for the built-in \texttt{kibana} user in
  \texttt{{[}Kibana\ Home{]}/config/kibana.yml}:

\begin{verbatim}
elasticsearch.username: "kibana"
elasticsearch.password: "liferay"
\end{verbatim}

  Use your \texttt{kibana} user password from your X-Pack setup. Once
  Kibana is installed, you can change the built-in user passwords from
  the \emph{Management} user interface.
\item
  If you're not encrypting communication with the Elasticsearch cluster,
  start Kibana from Kibana home.

\begin{verbatim}
./bin/kibana
\end{verbatim}
\item
  Go to \texttt{http://localhost:5601} and make sure you can sign in as
  a
  \href{https://www.elastic.co/guide/en/elasticsearch/reference/current/realms.html}{user}
  who has the \texttt{kibana\_user}
  \href{https://www.elastic.co/guide/en/elasticsearch/reference/current/built-in-roles.html}{role}
  or a superuser (like the \texttt{elastic} user).
\end{enumerate}

\section{Configuring Kibana with Encryption
(TLS/SSL)}\label{configuring-kibana-with-encryption-tlsssl}

Follow these steps to configure Kibana if X-Pack encrypts communication
with the Elasticsearch cluster. Consult
\href{https://www.elastic.co/guide/en/kibana/7.x/using-kibana-with-security.html\#using-kibana-with-security}{Elastic's
guide} for more information.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Copy the \texttt{{[}Elasticsearch\ Home{]}/config/certs} folder into
  the \texttt{{[}Kibana\ Home{]}/config/} folder.

  This example reuses the certificate files
  \href{/docs/7-2/deployment/-/knowledge_base/u/installing-liferay-enterprise-search-security}{created
  for Elasticsearch itself}. If you wish to generate a separate
  certificate for your Kibana instance, make sure it is signed by the
  same CA as the Elasticsearch node certificates.
\item
  Add these settings to \texttt{kibana.yml}:

\begin{verbatim}
xpack.security.encryptionKey: "xsomethingxatxleastx32xcharactersx"
xpack.security.sessionTimeout: 600000

elasticsearch.hosts: [ "https://localhost:9200" ]

elasticsearch.ssl.verificationMode: certificate
elasticsearch.ssl.certificateAuthorities: [ "config/certs/ca.crt" ]
elasticsearch.ssl.certificate: config/certs/localhost.crt
elasticsearch.ssl.key: config/certs/localhost.key

server.ssl.enabled: true
server.ssl.certificateAuthorities: [ "config/certs/ca.crt" ]
server.ssl.certificate: config/certs/localhost.crt
server.ssl.key: config/certs/localhost.key
\end{verbatim}
\end{enumerate}

Elasticsearch/Kibana 6.5 and below use a different property for
specifying the host URL. Replace the \texttt{elasticsearch.hosts}
property with

\begin{verbatim}
elasticsearch.url: "https://localhost:9200"
\end{verbatim}

For more information about monitoring and security best practices in a
clustered environment, refer to
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/setup-xpack.html}{Elastic's
documentation}.

After this step you can access Kibana at \texttt{https://localhost:5601}
and sign in with a Kibana user. The last step is to connect Kibana to
Liferay DXP.

\section{Configuring the Liferay Enterprise Search Monitoring
app}\label{configuring-the-liferay-enterprise-search-monitoring-app}

If you have a LES subscription, download the Liferay Enterprise Search
Monitoring app . Install the LPKG file by copying it into the
\texttt{Liferay\ Home/deploy} folder.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Once the connector is installed and Kibana and Elasticsearch are
  securely configured, create a
  \href{/docs/7-2/user/-/knowledge_base/u/understanding-system-configuration-files}{configuration
  file} named

\begin{verbatim}
com.liferay.portal.search.elasticsearch6.xpack.monitoring.web.internal.configuration.XPackMonitoringConfiguration.config
\end{verbatim}
\item
  Place these settings in the \texttt{.config} file:

\begin{verbatim}
kibanaPassword="liferay"
kibanaUserName="elastic"
kibanaURL="https://localhost:5601"
\end{verbatim}

  The values depend on your Kibana configuration. For example, use a URL
  such as \texttt{kibanaURL="http://localhost:5601"} if you are not
  using X-Pack Security TLS/SSL features.

  Alternatively, configure the monitoring adapter from
  \href{/docs/7-2/user/-/knowledge_base/u/system-settings}{System
  Settings}. Navigate to \emph{Control Panel} → \emph{Configuration} →
  \emph{System Settings} and find the X-Pack Monitoring entry in the
  Search category. All the configuration options for the monitoring
  connector appear there.
\item
  Deploy this configuration file to \texttt{Liferay\ Home/osgi/configs},
  and your running instance applies the settings. There's no need to
  restart the server.
\item
  There are two more settings to add to Kibana itself. The first forbids
  Kibana from rewriting requests prefixed with \texttt{server.basePath}.
  The second sets Kibana's base path for the Monitoring portlet to act
  as a proxy for Kibana's monitoring UI. Add this to
  \texttt{kibana.yml}:

\begin{verbatim}
server.rewriteBasePath: false
server.basePath: "/o/portal-search-elasticsearch-xpack-monitoring/xpack-monitoring-proxy"
\end{verbatim}

  Note that once you set the \texttt{server.basePath}, you cannot access
  the Kibana UI through Kibana's URL (e.g.,
  \texttt{https://localhost:5601}). All access to the Kibana UI is
  through the Monitoring portlet, which is only accessible to signed in
  Liferay DXP users. Navigate directly to the portlet using this URL:

  \url{http://localhost:8080/o/portal-search-elasticsearch-xpack-monitoring/xpack-monitoring-proxy/app/monitoring}
\item
  Because you're using the Monitoring portlet in Liferay DXP as a proxy
  to Kibana's UI, if you are using X-Pack Security with TLS/SSL, you
  must configure the application server's startup JVM parameters to
  recognize a valid \emph{truststore} and \emph{password}.

  First, navigate to Elasticsearch Home and generate a PKSC\#12
  certificate from the CA you created when setting up X-Pack security:

\begin{verbatim}
./bin/elasticsearch-certutil cert --ca-cert /path/to/ca.crt --ca-key /path/to/ca.key --ip 127.0.0.1 --dns localhost --name localhost --out /path/to/Elasticsearch_Home/config/localhost.p12
\end{verbatim}

  Next use the \texttt{keytool} command to generate a truststore:

\begin{verbatim}
keytool -importkeystore -deststorepass liferay -destkeystore /path/to/truststore.jks -srckeystore /path/to/Elasticsearch_Home/config/localhost.p12 -srcstoretype PKCS12 -srcstorepass liferay
\end{verbatim}

  Add the trustore path and password to your application server's
  startup JVM parameters. Here are example truststore and path
  parameters for appending to a Tomcat server's \texttt{CATALINA\_OPTS}:

\begin{verbatim}
-Djavax.net.ssl.trustStore=/path/to/truststore.jks -Djavax.net.ssl.trustStorePassword=liferay
\end{verbatim}
\end{enumerate}

Restart Liferay DXP and Kibana.

\section{Monitoring in Liferay DXP}\label{monitoring-in-liferay-dxp}

Once Kibana and X-Pack are successfully installed and configured and all
the servers are running, add the X-Pack Monitoring portlet to a page:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open the \emph{Add} menu on a page and choose \emph{Widgets}
\item
  Search for \emph{monitoring} and drag the \emph{X-Pack Monitoring}
  widget from the Search category onto the page.
\end{enumerate}

See the Elastic documentation for information on
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/es-monitoring.html}{monitoring
Elasticsearch}.

\section{Example Kibana
Configuration}\label{example-kibana-configuration}

Here are the \texttt{kibana.yml} properties demonstrated in this
article, for convenient copy/pasting:

\begin{verbatim}
# X-Pack Security enabled (Basic Auth)
elasticsearch.username: "kibana"
elasticsearch.password: "liferay"

# When TLS/SSL is enabled in X-Pack Security
xpack.security.encryptionKey: "xsomethingxatxleastx32xcharactersx"
xpack.security.sessionTimeout: 600000

# If on Elasticsearch 6.5 or below, replace the next property with:
# elasticsearch.url: "http://localhost:9200"
elasticsearch.hosts: [ "https://localhost:9200" ]

# Enable TLS/SSL for out-bound traffic: from Kibana to Elasticsearch
elasticsearch.ssl.verificationMode: certificate
elasticsearch.ssl.certificateAuthorities: [ "config/certs/ca.crt" ]
elasticsearch.ssl.certificate: config/certs/localhost.crt
elasticsearch.ssl.key: config/certs/localhost.key

# Enable TLS/SSL for in-bound traffic: from browser or
#  DXP (X-Pack Monitoring widget, proxy) to Kibana
server.ssl.enabled: true
server.ssl.certificateAuthorities: [ "config/certs/ca.crt" ]
server.ssl.certificate: config/certs/localhost.crt
server.ssl.key: config/certs/localhost.key

# To use Kibana inside the X-Pack Monitoring widget
server.rewriteBasePath: false
server.basePath: "/o/portal-search-elasticsearch-xpack-monitoring/xpack-monitoring-proxy"
\end{verbatim}

\chapter{Liferay Enterprise Search: Learning to
Rank}\label{liferay-enterprise-search-learning-to-rank}

Search engines like Elasticsearch have well-tuned relevance algorithms,
good for general search purposes. Sometimes, this ``generally good''
relevance scoring just isn't good enough. You can attain more perfect
search results by employing machine learning.

Learning to Rank harnesses machine learning to improve search result
rankings. It combines the expertise of data scientists with machine
learning to produce a smarter scoring function that's applied to search
queries.

7.0, Service Pack 1/Fix Pack 2 and later, supports Learning to Rank
through its support of Elasticsearch versions 6.x and 7.4.x. It requires
a \href{https://help.liferay.com/hc/en-us/articles/360014400932}{LES}
subscription. It's important to understand that the
\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/index.html}{Elasticsearch
Learning to Rank plugin} is not produced by Elastic, and there is not a
pre-built plugin for all of Liferay DXP's supported Elasticsearch
versions.

\section{Disabling Learning to Rank on a Search
Page}\label{disabling-learning-to-rank-on-a-search-page}

Learning to Rank does not work with the
\href{/docs/7-2/user/-/knowledge_base/u/sorting-search-results-with-the-sort-widget}{Sort
widget}.

If you must use Learning to Rank in your Liferay DXP instance, but want
to disable it on a particular Search page (perhaps to use the Sort
widget), you can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add a
  \href{/docs/7-2/user/-/knowledge_base/u/low-level-search-options-searching-additional-or-alternate-indexes}{Low
  Level Search Options} widget to the Search page.
\item
  Open the widget's Configuration screen by clicking

  \emph{Configure additional low level search options in this page.}
\item
  In the \emph{Contributors to Exclude} field, enter

  \texttt{com.liferay.portal.search.learning.to.rank}
\end{enumerate}

Now the Learning to Rank re-scoring process is skipped for queries
entered into the page's Search Bar, and results are sortable in the Sort
widget and returned using the default relevance algorithm.

\section{Prerequisites}\label{prerequisites}

There are some prerequisites for using Learning to Rank to re-score
Liferay queries sent to Elasticsearch:

\begin{itemize}
\item
  If using Elasticsearch 7, 7.0 Service Pack 1/Fix Pack 2 or later is
  required, with the appropriate Elasticsearch Connector version
  installed.
\item
  If using Elasticsearch 6, 7.0 Fix Pack 3 or later is required, with
  the appropriate Elasticsearch Connector version installed.
\item
  A
  \href{https://help.liferay.com/hc/en-us/articles/360014400932}{Liferay
  Enterprise Search} (LES) subscription is required for Learning to
  Rank. Once you have a subscription,
  \href{https://customer.liferay.com/downloads}{download the Liferay
  Enterprise Search Learning to Rank} LPKG file and
  \href{/docs/7-2/user/-/knowledge_base/u/installing-apps-manually\#installing-apps-manually}{install
  it to your Liferay DXP server.}
\item
  A remote Elasticsearch server, with your data indexed into it.
\item
  The corresponding version of the
  \href{https://github.com/o19s/elasticsearch-learning-to-rank}{Elasticsearch
  Learning to Rank} plugin installed into Elasticsearch.
\item
  A
  \href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/training-models.html}{trained
  model} uploaded into the Learning to Rank plugin.
\end{itemize}

To understand more about the compatibility requirements for LES, see its
\href{https://help.liferay.com/hc/en-us/articles/360016511651\#Liferay-Enterprise-Search}{compatibility
matrix}.

How does Learning to Rank work?

\section{Technical Overview}\label{technical-overview}

In a normal search, the User sends a query to the search engine via
Liferay DXP's
\href{/docs/7-2/user/-/knowledge_base/u/searching-for-assets\#search-bar}{Search
Bar}. The order of returned results is dictated by the search engine's
\href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/index-modules-similarity.html\#bm25}{relevance
scoring algorithm}.

Here's where Learning to Rank intervenes and makes that process
different:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  User enters a query into the search bar.
\item
  Liferay sends the query to Elasticsearch, and retrieves the first 1000
  results as usual, using the search engine's relevance algorithm.
\item
  The top 1000 results are not returned as search hits, but are used by
  Elasticsearch for
  \href{https://www.elastic.co/guide/en/elasticsearch/reference/7.x/search-request-body.html\#request-body-search-rescore}{re-scoring}
  via the
  \href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/searching-with-your-model.html\#rescore-top-n-with-sltr}{rescore
  functionality}.
\item
  The results are re-scored by the
  \href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/searching-with-your-model.html}{SLTR
  query}, which includes the keywords and the trained model to use for
  re-scoring.
\item
  Once the trained model re-ranks the results, they're returned in
  Liferay's
  \href{/docs/7-2/user/-/knowledge_base/u/search-results}{Search
  Results} in their new order.
\end{enumerate}

Though it's just a sub-bullet point in the ordered list above, much of
the work in this paradigm is in creating and honing the trained model.
That's beyond the scope of Liferay's role, but we'll help you get all
the pieces in place to orchestrate the magic of machine learning on your
Liferay queries. Here's a brief overview of what constitutes \emph{model
training}.

\section{Model Training}\label{model-training}

A useful trained model is produced when a good judgment list and a good
feature set are fed to a Learning to Rank algorithm (this is the machine
learning part of the puzzle). Therefore, it's incumbent on you to
assemble

\begin{itemize}
\item
  The Learning to Rank algorithm you wish to use for creating a training
  model. This demonstration uses
  \href{https://sourceforge.net/p/lemur/wiki/RankLib/}{RankLib}.
\item
  A \emph{judgment list}, containing a graded list of search results.
  The algorithm is designed to produce a model that honors the ordering
  of the judgment list.
\item
  A feature set, containing all the \emph{features} you're handing to
  the Learning to Rank algorithm, which it uses in conjunction with the
  judgment list to produce a reliable model. An example feature set for
  Liferay DXP data is shown in the next article.
\end{itemize}

\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html\#judgments-expression-of-the-ideal-ordering}{Judgment
lists} are lists of graded search results.

\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html\#features-the-raw-material-of-relevance}{Features}
are the variables that the algorithm uses to create a function that can
score results in a smarter way. If you don't give enough, or the
correct, relevant features, your model will not be ``smart'' enough to
provide improved results.

In the next article you'll see the steps required to configure Learning
to Rank with Liferay DXP.

\chapter{Configuring Learning to
Rank}\label{configuring-learning-to-rank}

Before beginning, you must have a remote
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-elasticsearch-7}{Elasticsearch
6 or 7} cluster communicating with 7.0. See the
\href{https://help.liferay.com/hc/en-us/articles/360016511651\#Liferay-Enterprise-Search}{compatibility
matrix for more information}

\noindent\hrulefill

\textbf{Helpful hint:} Use
\href{/docs/7-2/user/-/knowledge_base/u/searching-for-assets\#search-suggestions}{Suggestions}
to discover the most common queries (this can be one way to decide which
queries to create Learning to Rank models for).

\noindent\hrulefill

\section{Step 1: Install the Learning to Rank Plugin on
Elasticsearch}\label{step-1-install-the-learning-to-rank-plugin-on-elasticsearch}

See
\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/\#installing}{the
Elasticsearch Learning to Rank plugin documentation} to learn about
installing the Learning to Rank plugin.

You'll be running a command like this one, depending on the plugin
version you're installing:

\begin{verbatim}
./bin/elasticsearch-plugin install http://es-learn-to-rank.labs.o19s.com/ltr-1.1.0-es6.5.4.zip
\end{verbatim}

If using X-Pack security in your Elasticsearch cluster, there
\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/x-pack.html}{may
be additional steps.}

\section{Step 2: Training and Uploading a
Model}\label{step-2-training-and-uploading-a-model}

Detailed instructions on training models is outside the scope of this
guide. This requires the intervention of data scientists, who can
recommend appropriate tools and models. Use what works for you. In doing
so, you'll almost certainly be compiling
\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html\#judgments-expression-of-the-ideal-ordering}{Judgment
lists} and
\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/building-features.html}{feature
sets} that can be used by the training tool you select to generate a
model that produces good search results. This can be a long journey, but
once you get to the end of it, you'll want to upload the model to the
Learning to Rank plugin.

\section{Upload the Model to the Learning to Rank
Plugin}\label{upload-the-model-to-the-learning-to-rank-plugin}

You'll upload the model using a \texttt{POST} request, but first you
need to make sure you have a \texttt{\_ltr} index and a feature set
uploaded to the Learning to Rank plugin. Use Kibana (or even better, the
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-liferay-enterprise-search-monitoring}{Monitoring
widget}), to make these tasks easier.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If you don't already have an \texttt{\_ltr} index, create one:

\begin{verbatim}
PUT _ltr
\end{verbatim}
\item
  Add a feature set to the \texttt{\_ltr} index. In this example the set
  is called \texttt{liferay}:

\begin{verbatim}
POST _ltr/_featureset/liferay
{
  "featureset": {
    "name": "liferay",
    "features": [
      {
        "name": "title",
        "params": [
          "keywords"
        ],
        "template": {
          "match": {
            "title_en_US": "{{keywords}}"
          }
        }
      },
      {
        "name": "content",
        "params": [
          "keywords"
        ],
        "template": {
          "match": {
            "content_en_US": "{{keywords}}"
          }
        }
      },
      {
        "name": "asset tags",
        "params": [
          "keywords"
        ],
        "template": {
          "match": {
            "assetTagNames": "{{keywords}}"
          }
        }
      }
    ]
  }
}
\end{verbatim}

  Take note of the syntax used here, since it's required.
\item
  Add the trained model to the feature set:

\begin{verbatim}
POST _ltr/_featureset/liferay/_createmodel
{
  "model": {
    "name": "linearregression",
    "model": {
      "type": "model/ranklib",
      "definition": """
# Linear Regression
# Lambda = 1.0E-10
0:-0.717621803830712 1:-0.717621803830712 2:-2.235841905601106 3:19.546816765721594
"""
    }
  }
}
\end{verbatim}
\end{enumerate}

This is a very high level set of instructions, because there's not much
to do in Liferay DXP. To learn in more detail about what's required, see
the
\href{https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/index.html}{Learning
to Rank plugin's documentation}.

Keep reworking those judgment lists!

\section{Step 3: Enable Learning to
Rank}\label{step-3-enable-learning-to-rank}

Enable Learning to Rank from Control Panel → Configuration → System
Settings → Search → Learning to Rank. There's a simple on/off
configuration and a text field where you must enter the name of the
trained model to apply to search queries.

The model in the previous step was named \texttt{linearregression}, so
that's what you'd enter.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/search-learning-to-rank.png}}
\caption{Enable Learning to Rank in Liferay DXP from the System Settings
entry.}
\end{figure}

That's all the configuration required to get the Elasticsearch Learning
to Rank plugin ingesting a trained model, a feature set, and search
queries from Liferay DXP.

\chapter{Installing Solr}\label{installing-solr}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Solr is a popular enterprise search platform built on Apache Lucene.
It's reliable, scalable, and fault tolerant. Read more about it
\href{http://lucene.apache.org/solr/}{here}.

\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-liferay-elasticsearch-connector}{Elasticsearch}
is the default search engine that ships with Liferay DXP, and some
Liferay Search features are only available on Elasticsearch. It's valid,
however, to use Solr instead. In particular, if you've already been
using Solr with a previous version of Liferay DXP, or your platform (for
example, your OS or JVM)
\href{https://www.elastic.co/support/matrix}{isn't supported by
Elasticsearch}, you might choose to use Solr to search and index your
Liferay DXP data.

There are circumstances that force you to use Elasticsearch instead of
Solr. Read
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-a-search-engine\#choosing-a-search-engine}{here}
for more information.

Liferay DXP 7.2, Fix Pack 1, supports Solr 7.5.x through the Liferay
Connector to Solr 7 application, version 2.0.0.

Liferay DXP 7.2, Service Pack 1/Fix Pack 2 and later, supports Solr
7.5.x through the Liferay Connector to Solr 7 application, version
2.0.1.

Liferay Portal CE 7.2, GA2 and later (not available at time of writing),
support Solr 7.5.x through the Liferay CE Connector to Solr 7
application.

\noindent\hrulefill

\textbf{Upgrading to Service Pack 1 or Fix Pack 2 (or later) requires
installation of a new Solr connector:} If you were running version 2.0.0
of the Liferay Connector to Solr 7 application, and you want to install
Service Pack 1/Fix Pack 1 (or later), you must install version 2.0.1 of
the Liferay Connector to Solr 7 application.

\noindent\hrulefill

\section{Blacklisting Elasticsearch-Only
Features}\label{blacklisting-elasticsearch-only-features}

Before installing Solr, you must
\href{/docs/7-2/user/-/knowledge_base/u/blacklisting-osgi-bundles-and-components}{blacklist}
certain DXP
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-a-search-engine\#choosing-a-search-engine}{features
that only work with Elasticsearch}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a configuration file named

\begin{verbatim}
com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
\end{verbatim}
\item
  Give it these contents:

\begin{verbatim}
blacklistBundleSymbolicNames=["com.liferay.portal.search.tuning.web.api","com.liferay.portal.search.tuning.web","com.liferay.portal.search.tuning.synonyms.web","com.liferay.portal.search.tuning.rankings.web"]
\end{verbatim}
\item
  Place the file in \texttt{Liferay\ Home/osgi/configs}.
\end{enumerate}

It is required during the Solr installation process to also
\href{https://portal.liferay.dev/docs/7-2/deploy/-/knowledge_base/d/installing-solr-basic-installation\#stopping-the-elasticsearch-connector}{stop
the Elasticsearch Connectors} that ship with Liferay DXP. If you're
ready to blacklist those bundles now, use these contents in the
blacklist configuration file:

\begin{verbatim}
    blacklistBundleSymbolicNames=["com.liferay.portal.search.tuning.web.api","com.liferay.portal.search.tuning.web","com.liferay.portal.search.tuning.synonyms.web","com.liferay.portal.search.tuning.rankings.web","com.liferay.portal.search.elasticsearch6.spi","com.liferay.portal.search.elasticsearch6.api","com.liferay.portal.search.elasticsearch6.impl","Liferay Enterprise Search Monitoring ","Liferay Enterprise Search Security "]
\end{verbatim}

The Liferay Enterprise Search bundles must be excluded if you don't have
a LES subscription.

\chapter{Installing Solr: Basic
Installation}\label{installing-solr-basic-installation}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

There are two ways to install the Liferay Connector to Solr 7:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Navigate to \href{https://web.liferay.com/marketplace/}{Liferay
  Marketplace} and download the app that corresponds to your portal.
\end{enumerate}

Once the app LPKG is downloaded, copy it to
\texttt{Liferay\_Home/osgi/marketplace}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In your running portal instance, navigate to \emph{Control Panel} →
  \emph{Apps} → \emph{Store}. Sign in using your credentials, search for
  Solr Search Engine, and purchase (it's free) the Liferay Connector to
  Solr 7 entry.
\end{enumerate}

As you proceed, remember these terms:

\emph{Solr Home}: The center of the Solr system (pun intended). This
directory is \texttt{solr-{[}version{]}/server/solr}.

\emph{Liferay Home}: The root folder of your Liferay DXP installation.
It contains the \texttt{osgi}, \texttt{deploy}, \texttt{data}, and
\texttt{license} folders, among others.

There are two installation steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Installing and configuring Solr 7.
\item
  Installing and configuring the Solr 7 connector for Liferay DXP.
\end{enumerate}

Before configuring Liferay DXP for Solr, install and set up Solr.

\section{Installing and Configuring Solr
7}\label{installing-and-configuring-solr-7}

To install and properly configure Solr for Liferay DXP:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Download
  \href{http://archive.apache.org/dist/lucene/solr/7.5.0/}{Solr} and
  unzip it.
\item
  Navigate to \texttt{solr-{[}version{]}/server/solr}. This is Solr
  Home.
\item
  Create a new folder called \texttt{liferay}.
\item
  In the \texttt{liferay} folder, create two new folders: \texttt{conf}
  and \texttt{data}.
\item
  Copy the contents of \texttt{Solr\_Home/configsets/\_default/conf} to
  \texttt{Solr\_Home/liferay/conf}.
\item
  Open the Liferay Connector to Solr 7's LPKG file with an archive
  manager.

  Open the \texttt{com.liferay.portal.search.solr7.impl.jar} file, and
  extract

\begin{verbatim}
META-INF/resources/solrconfig.xml
\end{verbatim}

  and

\begin{verbatim}
META-INF/resources/schema.xml
\end{verbatim}

  to

\begin{verbatim}
Solr_Home/liferay/conf
\end{verbatim}

  This replaces the current \texttt{solrconfig.xml} and
  \texttt{schema.xml} files with ones that tell Solr how to index data
  coming from Liferay DXP.
\item
  Create a \texttt{core.properties} file in \texttt{Solr\_Home/liferay}
  and add this configuration:

\begin{verbatim}
config=solrconfig.xml
dataDir=data
name=liferay
schema=schema.xml
\end{verbatim}
\item
  Checkpoint: your \texttt{Solr\_Home/liferay} folder now has this
  structure:

\begin{verbatim}
liferay
├── conf
│   ├── lang
│   │   ├── contractions_ca.txt
│   │   ├── ....txt
│   ├── managed-schema
│   ├── params.json
│   ├── protwords.txt
│   ├── schema.xml
│   ├── solrconfig.xml
│   ├── stopwords.txt
│   └── synonyms.txt
├── core.properties
└── data
\end{verbatim}
\item
  Start the Solr server by entering

\begin{verbatim}
./bin/solr start -f
\end{verbatim}

  from the top-level folder of your Solr installation
  (\texttt{solr-{[}version{]}}).
\item
  The Solr server listens on port \texttt{8983} by default. Navigate to
  \texttt{http://localhost:8983/solr/\#/\textasciitilde{}cores}
  (assuming you're testing locally with \texttt{localhost} as your
  host), and confirm that the \texttt{liferay} core is available.
\end{enumerate}

Solr is now installed. Next install and configure the Solr connector.

\section{Installing and Configuring the Liferay Solr
Adapter}\label{installing-and-configuring-the-liferay-solr-adapter}

Since Elasticsearch is the default search engine, the Elasticsearch
connector is already installed and running. You must stop it before
configuring the Solr connector.

\section{Stopping the Elasticsearch
Connector}\label{stopping-the-elasticsearch-connector}

Stop the Elasticsearch connector bundle using the App Manager, the Felix
Gogo shell, or the bundle blacklist. If you're a Liferay DXP customer,
use the blacklist feature as described below. The App Manager and Gogo
shell rely on the \texttt{osgi/state} folder to ``remember'' the state
of the bundle. If you delete this folder (recommended during patching)
the Elasticsearch connector is reinstalled and started automatically.

Navigate to Control Panel → Apps → App Manager.

Once in the App Manager, search for \emph{elasticsearch}. Find the
Liferay Connector to Elasticsearch 6 module and click the Actions
((\pandocbounded{\includegraphics[keepaspectratio]{./images/icon-actions.png}}))
button. Choose the Deactivate option. This leaves the bundle installed,
but stops it in the OSGi runtime.

Alternatively, use the
\href{/developer/tutorials/-/knowledge_base/7-2/using-the-felix-gogo-shell}{Felix
Gogo shell} to stop the Elasticsearch connector. Enter

\begin{verbatim}
lb elasticsearch
\end{verbatim}

You'll see two active bundles for the Liferay Connector to Elasticsearch
6: an API and an IMPL bundle.

\begin{verbatim}
ID|State      |Level|Name
476|Active     |   10|Liferay (CE) Connector to Elasticsearch 6 - API (3.0.0)
478|Active     |   10|Liferay Portal Search Elasticsearch 6 API (3.0.4)
480|Active     |   10|Liferay Portal Search Elasticsearch 6 SPI (3.2.1)
706|Active     |   10|Liferay (CE) Connector to Elasticsearch 6 - Impl (3.0.0)
707|Active     |   10|Liferay Portal Search Elasticsearch 6 Implementation (3.0.15)
\end{verbatim}

Stop the API bundle by entering

\begin{verbatim}
stop [bundle ID]
\end{verbatim}

In the example above, the \texttt{{[}bundle\ ID{]}} is \texttt{476}.

\textbf{Liferay DXP:} DXP customers should
\href{/docs/7-2/user/-/knowledge_base/u/blacklisting-osgi-bundles-and-components}{blacklist}
the Elasticsearch, Shield, and Marvel plugins.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a

\begin{verbatim}
com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
\end{verbatim}

  file with these contents:

\begin{verbatim}
blacklistBundleSymbolicNames=["com.liferay.portal.search.elasticsearch6.spi","com.liferay.portal.search.elasticsearch6.api","com.liferay.portal.search.elasticsearch6.impl","Liferay Enterprise Search Monitoring ","Liferay Enterprise Search Security "]
\end{verbatim}

  If the LES Security and Monitoring LPKG files are installed, you must
  blacklist these too.
\item
  Place the file in \texttt{Liferay\ Home/osgi/configs}.
\end{enumerate}

\section{Install and Configure the Solr
Connector}\label{install-and-configure-the-solr-connector}

Now you're ready to install the connector:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start Liferay DXP, then deploy the Solr connector by copying the LPKG
  you downloaded to \texttt{Liferay\_Home/deploy}.

  You'll see a \texttt{STARTED} message in your Liferay DXP log once the
  Solr connector is installed. Here's what the log message looks like:

\begin{verbatim}
2018-11-06 19:59:49.396 INFO  [pipe-start 943 944][BundleStartStopLogger:39] STARTED com.liferay.portal.search.solr7.api_2.0.5 [943]
2018-11-06 19:59:49.490 INFO  [pipe-start 943 944][BundleStartStopLogger:39] STARTED com.liferay.portal.search.solr7.impl_2.0.11 [944]
\end{verbatim}
\item
  To re-index against Solr, navigate to \emph{Control Panel} →
  \emph{Configuration} → \emph{Search}, and click \emph{Execute} next to
  the \emph{Reindex all search indexes} option.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/solr-reindex.png}}
\caption{Once the Solr connector is installed, you can re-index your
Liferay DXP data against your Solr server.}
\end{figure}

In production deployments, specify your edits to the Solr connector's
default configurations using a configuration file deployed to the
\texttt{Liferay\_Home/osgi/configs} folder. Name the file

\begin{verbatim}
com.liferay.portal.search.solr7.configuration.SolrConfiguration.config
\end{verbatim}

During testing and development, use the Solr 7 System Settings entry
Control Panel → Configuration → System Settings for editing the default
configurations.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/solr-system-settings.png}}
\caption{You can configure Solr from Liferay DXP's System Settings
application. This is most useful during development and testing.}
\end{figure}

The next article covers clustering Solr with SolrCloud.

\chapter{Installing Solr: High Availability with
SolrCloud}\label{installing-solr-high-availability-with-solrcloud}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Use SolrCloud if you need a cluster of Solr servers. Note that to use
SolrCloud in production, you should set up an
\href{https://cwiki.apache.org/confluence/display/solr/Setting+Up+an+External+ZooKeeper+Ensemble}{external
ZooKeeper ensemble}. \href{http://zookeeper.apache.org/}{ZooKeeper} is a
centralized coordination service for managing distributed systems like
your SolrCloud cluster.

The steps included here should be considered the bare minimum of what
must be done to configure SolrCloud with Liferay DXP. For example, these
instructions cover configuring SolrCloud on a single machine, whereas a
production environment would feature multiple physical or virtual
machines. These instructions also assume you've followed the earlier
section on \emph{Installing and Configuring Solr 7}. Refer to the
\href{https://cwiki.apache.org/confluence/display/solr/SolrCloud}{SolrCloud
guide for more information}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Stop the Solr server if it's running.
\item
  Navigate to the \texttt{Solr\_Home/configsets} folder and create a
  folder called

\begin{verbatim}
 liferay_configs
\end{verbatim}
\item
  Copy the \texttt{conf} folder from \texttt{Solr\_Home/liferay} to the
  \texttt{liferay\_configs} folder you just created.

  The \texttt{configset/liferay\_configs} folder contains the SolrCloud
  Liferay DXP collection configuration and is uploaded to ZooKeeper. By
  copying the \texttt{conf} folder from the \texttt{liferay} server
  configured earlier, you're using the \texttt{schema.xml} and
  \texttt{solrconfig.xml} files provided with the Liferay Solr Adapter.
\item
  Next launch an interactive SolrCloud session to configure your
  SolrCloud cluster. Use this command:

\begin{verbatim}
 ./bin/solr -e cloud
\end{verbatim}
\item
  Complete the setup wizard. These steps demonstrate creating a two-node
  cluster:

  \begin{itemize}
  \item
    Enter \texttt{2} for the number of nodes.
  \item
    Specify ports \texttt{8983} and \texttt{7574} (the defaults). Both
    nodes are started with the start commands printed in the log:

\begin{verbatim}
 Starting up Solr on port 8983 using command:
 "bin/solr" start -cloud -p 8983 -s "example/cloud/node1/solr"

 Waiting up to 180 seconds to see Solr running on port 8983 [|]  [-]  
 Started Solr server on port 8983 (pid=8846). Happy searching!


 Starting up Solr on port 7574 using command:
 "bin/solr" start -cloud -p 7574 -s "example/cloud/node2/solr" -z localhost:9983

 Waiting up to 180 seconds to see Solr running on port 7574 [|]  [/]  
 Started Solr server on port 7574 (pid=9026). Happy searching!
\end{verbatim}
  \item
    Name the collection \emph{liferay}.
  \item
    Split the collection into two shards.
  \item
    Specify two replicas per shard.
  \item
    When prompted to choose a configuration, enter
    \emph{liferay\_configs}. You should see a log message that concludes
    like this when the cluster has been started:
  \end{itemize}

\begin{verbatim}
 SolrCloud example running, please visit http://localhost:8983/solr
\end{verbatim}
\end{enumerate}

Now you have a new collection called \emph{liferay} in your local
SolrCloud cluster. Verify its status by running the \emph{status}
command:

\begin{verbatim}
./bin/solr status
\end{verbatim}

You'll see log output like this:

\begin{verbatim}
Found 2 Solr nodes: 

Solr process 12828 running on port 8983
INFO  - 2019-07-18 16:46:35.137; org.apache.solr.util.configuration.SSLCredentialProviderFactory; Processing SSL Credential Provider chain: env;sysprop
{
  "solr_home":"/home/russell/liferay-bundles/liferay-portal-7.2.10-ga1/solr-7.5.0/example/cloud/node1/solr",
  "version":"7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:07:55",
  "startTime":"2019-07-18T20:44:13.138Z",
  "uptime":"0 days, 0 hours, 2 minutes, 22 seconds",
  "memory":"56.4 MB (%11.5) of 490.7 MB",
  "cloud":{
    "ZooKeeper":"localhost:9983",
    "liveNodes":"2",
    "collections":"1"}}


Solr process 12995 running on port 7574
INFO  - 2019-07-18 16:46:35.848; org.apache.solr.util.configuration.SSLCredentialProviderFactory; Processing SSL Credential Provider chain: env;sysprop
{
  "solr_home":"/home/russell/liferay-bundles/liferay-portal-7.2.10-ga1/solr-7.5.0/example/cloud/node2/solr",
  "version":"7.5.0 b5bf70b7e32d7ddd9742cc821d471c5fabd4e3df - jimczi - 2018-09-18 13:07:55",
  "startTime":"2019-07-18T20:44:16.847Z",
  "uptime":"0 days, 0 hours, 2 minutes, 19 seconds",
  "memory":"108.2 MB (%22.1) of 490.7 MB",
  "cloud":{
    "ZooKeeper":"localhost:9983",
    "liveNodes":"2",
    "collections":"1"}}
\end{verbatim}

To stop Solr while running in SolrCloud mode, use the \emph{stop}
command, like this:

\begin{verbatim}
bin/solr stop -all
\end{verbatim}

\section{Configure the Solr Adapter for
SolrCloud}\label{configure-the-solr-adapter-for-solrcloud}

There's only one thing left to do: specify the client type as
\emph{CLOUD} in Liferay's Solr connector.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From System Settings or your OSGi configuration file, set the
  \emph{Client Type} to \emph{CLOUD}.

\begin{verbatim}
clientType="CLOUD"
\end{verbatim}
\item
  Start Liferay DXP if it's not running already.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/solr-client-type.png}}
\caption{From the Solr 7 System Settings entry, set the \emph{Client
Type} to \emph{Cloud}.}
\end{figure}

Now you can configure Liferay DXP for Solr and Solr for @product@.
Remember that Elasticsearch is the default search engine, so if you're
not constrained to use Solr or already a Solr expert, consider
Elasticsearch for your search engine requirements. If you do use Solr,
tell all your colleagues that your Liferay DXP installation's search
capability is Solr powered (pun intended).

\chapter{Solr Connector Settings}\label{solr-connector-settings}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Solr can be configured for use with 7.0. Liferay Marketplace includes a
Solr connector app called the Liferay Connector to Solr 7. The connector
is configurable through System Settings or an OSGi configuration file
named
\texttt{com.liferay.portal.search.solr7.configuration.SolrConfiguration.config}
and deployed to \texttt{{[}Liferay\_Home{]}/osgi/configs}.

The list below is all the configuration settings for Liferay's Solr
connector, in the order they appear in the System Settings application:

\section{Solr 7}\label{solr-7}

\begin{description}
\tightlist
\item[\texttt{authenticationMode=BASIC}]
A String with the value of \emph{BASIC} or \emph{CERT}. Use BASIC when
connecting using the
\href{https://cwiki.apache.org/confluence/display/solr/Basic+Authentication+Plugin}{Basic
Authentication plugin}, otherwise select CERT to connect using
\href{https://cwiki.apache.org/confluence/display/solr/Enabling+SSL}{2-way
SSL authentication}.
\item[\texttt{clientType=REPLICATED}]
A String with the value of \emph{REPLICATED} or \emph{CLOUD}. Use the
default (REPLICATED) when connecting to a single-node Solr server.
Specify CLOUD to connect to SolrCloud (see the next section, titled
\emph{High Availability with SolrCloud} for more information).
\item[\texttt{logExceptionsOnly=true}]
A boolean value that, when set to true, only logs exceptions from Solr,
without rethrowing them.
\item[\texttt{readURL=http://localhost:8983/solr/liferay}]
A String array with the URLs to which Liferay will send search requests.
This will be different from the \texttt{writeURL} if you use separate
servers for indexing (write) and searching (read).
\item[\texttt{writeURL=http://localhost:8983/solr/liferay}]
A String array with the URLs to which Liferay will send indexing
requests. This is different from the \texttt{readURL} if you use
separate servers for indexing (write) and searching (read).
\item[\texttt{zkHost=localhost:9983}]
A String with the ZooKeeper host and port. This is required when using
the adapter in CLOUD mode.
\end{description}

\chapter{Securing Liferay DXP}\label{securing-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay follows the OWASP Top 10 (2013) and CWE/SANS Top 25 lists to
ensure Liferay DXP is as secure as possible. Following these
recommendations protects the product against known kinds of attacks and
security vulnerabilities. For example, Liferay DXP's persistence layer
is generated and maintained by the Service Builder framework which
prevents SQL Injection using Hibernate and parameter based queries.

To prevent Cross Site Scripting (XSS), user-submitted values are escaped
on output. To support integration features, Liferay DXP doesn't encode
input. Data is stored in the original form as submitted by the user.
Liferay DXP includes built-in protection against CSRF attacks, Local
File Inclusion, Open Redirects, Uploading and serving files of dangerous
types, Content Sniffing, Clickjacking, Path Traversal, and many other
common attacks.

To stay on top, Liferay DXP also contains fixes for state-of-the-art
attacks and techniques to improve product security. For example, Liferay
DXP uses PBKDF2 to store passwords. Liferay DXP also contains mitigation
for Quadratic Blowup XXE attack, Rosetta Flash vulnerability, Reflected
File Download, and other kinds of attacks.

This section of tutorials shows you how to configure various security
and login features, such as LDAP, single sign-on, Service Access
Policies, and more. What follows is an overview of what's available.

\section{Authentication Overview}\label{authentication-overview}

Liferay DXP user authentication can take place using any of a variety of
prepared solutions:

\begin{itemize}
\tightlist
\item
  Form authentication using the Sign In Portlet with extensible adapters
  for checking and storing credentials (portal database, LDAP)
\item
  Single-Sign-On (SSO) solutions - NTLM, CAS, SiteMinder, OpenSSO,
  OpenID, Facebook
\item
  \href{https://www.liferay.com/marketplace/-/mp/application/15188711}{SAML
  plugin}
\item
  JAAS integration with application server
\end{itemize}

Note: Although Liferay's SSO solutions are incompatible with WebDAV,
they can be used with Liferay Sync. See the
\href{/docs/7-1/user/-/knowledge_base/u/publishing-files}{Publishing
Files} article for more information on WebDAV and Liferay Sync.

You can authenticate and authorize apps remotely using the
\texttt{AuthVerifier} layer:

\begin{itemize}
\tightlist
\item
  Password based HTTP Basic + Digest authentication
\item
  Token based OAuth plugin
\item
  Portal session based solution for JavaScript applications
\end{itemize}

Both user authentication and remote application authentication are
\href{/docs/7-2/frameworks/-/knowledge_base/f/authentication-pipelines}{extensible}.
Developers can create custom Login portlets and plugins, extend the
default Login portlet \texttt{auth.pipeline}, create \texttt{AutoLogin}
extensions for SSO, or create custom \texttt{AuthVerifier}
implementations.

\section{Authorization and Permission
Checking}\label{authorization-and-permission-checking}

There are several adjustable authorization layers in place to prevent
unauthorized or unsecured access to data:

\begin{itemize}
\tightlist
\item
  Remote IP and HTTPS transport check to limit access to Liferay DXP's
  Java servlets
\item
  Extensible Access Control Policies layer to perform any portal service
  related authorization check
\item
  Extensible role-based permission framework for almost any portal
  entity or data (stored in the portal database or elsewhere)
\item
  Portlet Container security checks to control portlet access
\item
  Remote IP check for portal remote API authentication methods
\item
  Service Access Policies to control access to portal remote API
\end{itemize}

\section{Additional Security
Features}\label{additional-security-features}

Users can be assigned to sites, teams, user groups, or organizations.
Custom roles can be created, permissions can be assigned to those roles,
and those roles can be applied to users. Roles are scoped to apply only
with a specific context like a site, an organization, or globally. See
the \href{/docs/7-1/user/-/knowledge_base/u/roles-and-permissions}{Roles
and Permissions} documentation for more information.

\noindent\hrulefill

Note: Liferay DXP relies on the application server for sanitizing CRLF
in HTTP headers. You should, therefore, make sure this is configured
properly in your application server, or you may experience false
positives in reports from automatic security verification software such
as Veracode. There is one exception to this for Resin, which does not
have support for this feature. In this case, Liferay DXP sanitizes HTTP
headers.

\noindent\hrulefill

There are additional security plugins available from
\href{https://www.liferay.com/marketplace}{Liferay Marketplace}. For
example, you can find an Audit plugin for tracking user actions or an
AntiSamy plugin for clearing HTML from XSS vectors.

There are many ways to fine-tune or disable various security features.
Here are a few examples of these kinds of configuration actions:

\begin{itemize}
\tightlist
\item
  Disable the Sign In portlet's \emph{Create Account} link
\item
  Configure Liferay DXP's HTTPS web server address
\item
  Configure the list of allowed servers to which users can be redirected
\item
  Configure the list of portlets that can be accessed from any page
\item
  Configure the file types allowed to be uploaded and downloaded
\end{itemize}

\section{Secure Configuration and Run
Recommendations}\label{secure-configuration-and-run-recommendations}

Liferay DXP is built using the ``secure by default'' concept in mind.
It's not recommended to disable built-in protections or to allow all
values in security white-lists. Such acts may lead to security
misconfiguration and an insecure deployment.

Also, customers are advised to deploy security patches as described on
the
\href{https://www.liferay.com/group/customer/products/portal/security-vulnerability}{customer
portal}.

For community and CE deployments, the stay secure by always using the
latest community version, which contains all previous security patches.

\chapter{Logging into Liferay DXP}\label{logging-into-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

One of the primary functions of a security system is to make pages,
content, and web applications accessible only to the appropriate users.
A student logging into a university portal should not be able to access
the same resources a professor can. A patient logging into a health care
portal should not be able to access a doctor's resources. Some content
(at least a login page) should be available to everybody, including
unauthenticated users (called \emph{guest} users). To learn more about
how Liferay DXP restricts access to portal resources to different users,
please see the
\href{/docs/7-2/user/-/knowledge_base/u/roles-and-permissions}{Roles and
Permissions} documentation.

\section{Authentication Types}\label{authentication-types}

There are three authentication types: by email address, screen name, or
user ID. To choose an authentication type, navigate to the Control
Panel, click on \emph{Configuration} → \emph{Instance Settings} →
\emph{Platform} → \emph{User Authentication} and use the \emph{How do
users authenticate?} selector to make a selection. Alternatively, add
the following lines to your \texttt{portal-ext.properties} file,
uncomment the appropriate line, comment out the others, and restart your
server.

\begin{verbatim}
company.security.auth.type=emailAddress
#company.security.auth.type=screenName
#company.security.auth.type=userId
\end{verbatim}

The default authentication type is by email address, but you can choose
screen names or user IDs instead. Users choose screen names when they
create their accounts or administrators can choose them. User IDs are
auto-generated when the account is created. Regardless of which
authentication type is configured, users must always enter a password.
For information on adding restrictions on the kinds of passwords that
are allowed or required (e.g., to require a minimum password length or
require special characters), please see the
\href{/docs/7-2/user/-/knowledge_base/u/password-policies}{Password
Policies} documentation.

\section{The Sign In Portlet}\label{the-sign-in-portlet}

Sign In portlet is how users log in. By default, the Sign In portlet can
create new accounts or request a password reset. The default home page
contains a Sign In portlet. You can access this page at
\url{http://localhost:8080/web/guest/home}.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/sign-in-portlet.png}}
\caption{By default, the Sign In portlet allows users to log in, create
a new account, or request a password reset.}
\end{figure}

If the Sign In portlet doesn't appear on any page, you can still access
it here:

\url{localhost:8080/c/portal/login}

By default, guest users can create accounts by clicking on the
\emph{Create Account} link in the Sign In portlet, completing the form,
and submitting it. If a user has an account but has forgotten its
password, the user can click the \emph{Forgot Password} link to request
a password reset.

Both the \emph{Create Account} form and the \emph{Forgot Password} form
include a CAPTCHA-based text verification field. Using
\href{http://www.captcha.net}{CAPTCHA} prevents bots from submitting
these forms.

You can use
\href{https://www.google.com/recaptcha/intro/index.html}{reCAPTCHA}
instead of CAPTCHA. One advantage of reCAPTCHA is that it can allow
visually impaired users to pass the test. To use reCAPTCHA, navigate to
the Control Panel, then click on \emph{Configuration} → \emph{System
Settings} → \emph{CAPTCHA}.

You can prevent guest users from creating new user accounts, if your
site requires users be registered by administrators. Navigate to the
Control Panel → \emph{Configuration} → \emph{Instance Settings} →
\emph{Platform} → \emph{User Authentication} and uncheck the \emph{Allow
strangers to create accounts?} box. You can also prevent users from
requesting forgotten passwords or from requesting password reset links
by unchecking the appropriate boxes. With these options, the Create
Account and Forgot Password links no longer appear in the Sign-In
portlet.

Remember that the Sign In portlet is the default way for users to log
in, but it's not the only way. User accounts can be imported from and
exported to LDAP directories. You can use single-sign-on (SSO) solutions
or token-based authentication, which allows remote web applications to
authenticate. Please refer to the other articles in this section for
more information. Finally, remember that user authentication and remote
application authentication mechanisms are
\href{/docs/7-2/frameworks/-/knowledge_base/f/authentication-pipelines}{extensible}.

\chapter{Service Access Policies}\label{service-access-policies}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

\emph{Service access policies} comprise a layer of web service security
that defines services or service methods that can be invoked remotely.
You can apply many of them at once to produce a combined effect. To help
you understand how service access policies fit into the big picture,
here's a summary of Liferay DXP's web service security layers:

\textbf{IP permission layer:} The IP address from which a web service
invocation request originates must be white-listed in the portal
properties file. A web service invocation coming from a non-whitelisted
IP address automatically fails.

\textbf{Service access policy layer:} Methods corresponding to a web
service invocation request must be whitelisted by each service access
policy that's in effect. You can use wildcards to reduce the number of
service classes and methods that must be explicitly whitelisted.

\textbf{Authentication/verification layer (browser-only):} If a web
service invocation request comes from a browser, the request must
include an authentication token. This authentication token is the value
of the \texttt{p\_auth} URL parameter. The token is generated by Liferay
DXP and associated with your browser session. The \texttt{p\_auth}
parameter is automatically supplied when you invoke a Liferay DXP web
service via the JSON web services API page or via JavaScript using
\texttt{Liferay.Service(...)}. If Liferay DXP cannot associate the
caller's authentication token with a User, the web service invocation
request fails.

\textbf{User permission layer:} Properly implemented web services have
permission checks. The user invoking a web service must have permission
to invoke the service.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/service-access-policies-security-layers.png}}
\caption{To get to a service, a request must pass through the door lock
of user permissions, the padlock of the verification layer, the brick
wall of service access policies, and finally the safe of predefined IP
permissions.}
\end{figure}

Note that service access policies respect the permissions system. If a
service access policy grants a user access to a remote service, the user
must still have the appropriate permissions to invoke that service.

Service access policies are especially useful when remote applications
such as mobile devices or Liferay Sync instances must access web
services. Administrators can use service access policies to ensure that
these devices can only invoke remote services from approved lists that
can be modified at runtime.

\section{Managing Service Access
Policies}\label{managing-service-access-policies}

Navigate to the Control Panel and click on \emph{Service Access Policy}
under the Configuration heading. Here, you can see the default service
access policies and add new ones. When creating or editing service
access policies, keep these points in mind:

\begin{itemize}
\item
  Service access policy names must be unique per portal instance.
\item
  Service access policy names can include only these allowed characters:

\begin{verbatim}
  0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#:@-./_
\end{verbatim}
\item
  Service access policy titles can be localized; service access policy
  names cannot be localized.
\item
  Allowed service signatures must be entered one per line. Wildcards
  (\texttt{*}) are allowed for both class names and method names. The
  \texttt{\#} symbol must be used to separate a class name from a method
  name.
\end{itemize}

For example, \texttt{com.liferay.portal.kernel.service.UserService}
allows any method from the \texttt{UserService} class to be invoked.
\texttt{com.liferay.document.library.kernel.service.DLAppService\#get*}
allows any method from the \texttt{DLAppService} that starts with
\texttt{get} to be invoked. Thus,

\begin{verbatim}
com.liferay.portal.kernel.service.UserService
com.liferay.document.library.kernel.service.DLAppService#get*
\end{verbatim}

allows any method from the \texttt{UserService} class to be invoked and
any method from the \texttt{DLAppService} whose name starts with
\texttt{get} to be invoked.

There are 16 service access policies that are enabled by default. Six of
these have to do with the system:

\textbf{ASSET\_ENTRY\_DEFAULT:} Allows the view counter for assets to be
updated when an asset is retrieved.

\textbf{CALENDAR\_DEFAULT:} Makes it possible to search public events in
the calendar.

\textbf{SYNC\_DEFAULT:} Allows only the
\texttt{com.liferay.sync.service.SyncDLObjectService.getSyncContext}
method. It applies to every Liferay Sync request, including
unauthenticated Sync requests.

\textbf{SYNC\_TOKEN:} Allows \texttt{com.liferay.sync.service.*},
meaning that any API function that's a method of a class in this package
can be invoked. It applies to Sync requests which are accompanied by an
authentication token.

\textbf{SYSTEM\_DEFAULT:} Allows access to country/region services by
JavaScript calls, so users can switch languages on the fly. Applies to
every request, including unauthenticated requests.

\textbf{SYSTEM\_USER\_PASSWORD:} Allows any method to be invoked. Of
course, since API functions include permission checks, this call works
only if the user has the required permission. It applies to requests for
which \texttt{AuthVerifierResult.isPasswordBasedAuthentication} is
\texttt{true}: i.e., whenever user authentication took place using a
password. If you want to completely disallow certain API functions from
being invoked, you can change the \texttt{SYSTEM\_USER\_PASSWORD} policy
to something more restrictive than \texttt{*}.

\texttt{SYNC\_DEFAULT} and \texttt{SYSTEM\_DEFAULT}, as their names
suggest, are default service access policies. Default service access
policies are applied to all incoming requests, including unauthenticated
requests.

The other 10 policies have to do with OAuth and JSON web services:

\textbf{OAUTH2\_analytics.read/write:} Integrates with
\href{https://www.liferay.com/products/analytics-cloud}{Liferay
Analytics Cloud}, allowing it access to JSON web services.

\textbf{OAUTH2\_everything/read/documents/userprofile/write:} The
Everything policies grant access to all the JSON web services for
various reasons. Everything is everything: all JSON web services
(matches \texttt{*}). The others match method signatures appropriate to
their description. For example, OAUTH2\_everything.read matches all
methods starting with \texttt{fetch}, \texttt{get}, \texttt{has},
\texttt{is}, or \texttt{search}.

\textbf{OAUTH\_READ/WRITE:} These provide access to JSON web services
via the OAuth 1.0a plugin.

The default configuration makes available corresponding scopes that
provide access to all web services shipped with the system. The scopes
must be assigned to OAuth 1 or 2 applications before they become usable.
Administrators should review the ones you want to use and disable the
others.

You can create new default service access policies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Navigate to the \emph{Configuration} → \emph{Service Access Policy}
  section of the Control Panel.
\item
  Click \emph{Add}
  (\pandocbounded{\includegraphics[keepaspectratio]{./images/icon-add.png}}).
\item
  Give your policy a name.
\item
  Flip the switch to enable your policy.
\item
  If you want the policy applied to unauthenticated requests as well as
  authenticated requests, flip the switch labeled \emph{Default}.
\item
  Give your policy a localized title.
\item
  Under Allowed Service Signatures, start typing the fully qualified
  name of a service class that's installed. Code completion helps you
  find the class. For example, if you're creating a policy for Liferay's
  Knowledge Base application, you could enter
  \texttt{com.liferay.knowledge.base.service.KBArticleService}.
\item
  Under Method Name, start typing a service method call. Again, code
  completion helps you. For Knowledge Base, you could enter
  \texttt{getKBArticle}.
\item
  To specify another service or method, click the plus icon to add
  another entry.
\item
  When done, click \emph{Save}.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} If you know all the method signatures ahead of time, you
can click \emph{Switch to Advanced Mode} and enter them all in one field
on separate lines.

\noindent\hrulefill

Liferay applications can declare their own default policies (the
\texttt{SYNC\_DEFAULT} policy is a good example). This policy can then
be changed or disabled by administrators. In this case, the plugin can
still verify that the policy exists so there is no need to redefine or
update it.

By default, Liferay's tunneling servlet uses the
\texttt{SYSTEM\_USER\_PASSWORD} service access policy. You can, however,
create your own policy for the tunneling servlet and use the property
\texttt{service.access.policy.name} for the
\texttt{TunnelingServletAuthVerifier} to specify that your policy should
be used instead.

\section{Service Access Policy
Module}\label{service-access-policy-module}

Liferay's service access policy functionality is provided by the Service
Access Policy module. This module includes the following important
classes:

\begin{itemize}
\tightlist
\item
  \texttt{com.liferay.portal.kernel.security.service.access.policy.ServiceAccessPolicy}:
  defines the public interface for \texttt{ServiceAccessPolicy}.
\item
  \texttt{com.liferay.portal.kernel.security.service.access.policy.ServiceAccessPolicyManager}:
  defines the public interface for retrieving instances of
  \texttt{ServiceAccessPolicy}.
\item
  \texttt{com.liferay.portal.kernel.security.service.access.policy.ServiceAccessPolicyManagerUtil}:
  bridges service access policy functionality to the parts of Liferay's
  core that have not yet been modularized.
\item
  \texttt{com.liferay.portal.kernel.security.service.access.policy.ServiceAccessPolicyThreadLocal}:
  makes \texttt{ServiceAccessPolicy} instances active.
\end{itemize}

Liferay's Service Access Policy module resides in the
\texttt{modules/apps/service-access-policy} folder in the source code.
When running, these three bundles provide the service access policy
functionality (they're in the \texttt{{[}Liferay\ Home{]}/osgi/modules}
folder):

\begin{itemize}
\tightlist
\item
  \texttt{com.liferay.service.access.policy.api.jar}
\item
  \texttt{com.liferay.service.access.policy.service.jar}
\item
  \texttt{com.liferay.service.access.policy.web.jar}
\end{itemize}

These modules provide the service access policy management UI that's
accessible from the Control Panel. They also provide the interface and
default implementation for \texttt{ServiceAccessPolicy}.

To configure the Service Access Policy module, navigate to the Control
Panel, click on \emph{System Settings}, and find the \emph{Service
Access Policies} module in the Security section. Click on its name to
edit it. Here, you can edit the default service access policy
configuration. You can also force a default policy to be applied even
when no policies are applied by the \texttt{AuthVerifier}.

There's also an \texttt{AuthenticatedAccessControlPolicy}. This policy
doesn't do anything if a \texttt{ServiceAccessPolicyManager}
implementation is present. If the service access policy module is
disabled, however, the \texttt{AuthenticatedAccessControlPolicy}
provides a fallback that still requires authenticated access for web
services.

\section{Summary}\label{summary}

Great! Now you know service access policies can restrict access to
Liferay DXP's web services. Custom service access policies can be
created by portal administrators. They are applied by the portal's token
authenticator, e.g., by OAuth.

\section{Related Topics}\label{related-topics-3}

\href{/docs/7-2/frameworks/-/knowledge_base/f/service-access-policies}{Creating
Service Access Policies}

\chapter{Authentication Verifiers}\label{authentication-verifiers}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The Authentication Verification Layer is a centralized and extensible
way to authenticate remote invocations of Liferay DXP's API.

The main responsibilities of the authentication verification layer are
to

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Verify provided credentials using registered \texttt{AuthVerifier}
  instances
\item
  Create portal authorization contexts based on verification results
\end{enumerate}

If no available \texttt{AuthVerifier} can verify request credentials, an
authorization context supporting non-authenticated access is created for
a guest user. This allows each API to expose only a single API endpoint.
In contrast, legacy (prior to 6.2) versions of Liferay DXP exposed two
API endpoints for each API: the \texttt{/api/endpoint} URI was for
non-authenticated access and the URI \texttt{/api/secure/endpoint} was
for authenticated access.

There are built-in \texttt{AuthVerifier} implementations for the most
common situations, such as when remote clients use HTTP Basic or HTTP
Digest authentication, send credentials in request parameters, send
authenticated \texttt{JSESSIONID}s, or use shared secrets to establish
trust. Other \texttt{AuthVerifier} implementations can be deployed as
modules containing implementations of the \texttt{AuthVerifier}
interface that are registered as services in the OSGi runtime.

Note: The authentication verification layer's focus is on verifying
authentication, not on providing credentials. It does NOT issue tokens,
credentials, or display Sign In portlets. Instead, the layer verifies
existing credentials and authenticated sessions and is therefore a
complement to authentication endpoints. To ensure backwards
compatibility, however, the default implementations support requests
providing user name and password credentials. Thus, the authentication
verification layer stands on the border between authentication and
authorization.

\section{Authentication Verification Process
Overview}\label{authentication-verification-process-overview}

This layer and surrounding processes are provided by the
\texttt{AuthVerifierFilter} class that implements the
\texttt{javax.servlet.Filter} interface.

\textbf{Step 1: Verify Request Credentials}

The layer uses the chain of responsibility design pattern to support
both built-in and third party \texttt{AuthVerifier} implementations.
Each \texttt{AuthVerifier} can provide configurations where it specifies
mapped URLs and other properties.

Each incoming request is matched against all registered
\texttt{AuthVerifier}s to select the final list of
\texttt{AuthVerifier}s that is used to process the request. It's the
responsibility of each \texttt{AuthVerifier} to verify the incoming
request credentials.

\textbf{Step 2: Create an Authorization Context}

When a request is processed by all matching \texttt{AuthVerifier}s,
Liferay DXP creates an authorization context for the resolved user.

This encompasses setting the \texttt{HttpServletRequest}
\texttt{remoteUser} to return the resolved user ID setting
\texttt{ThreadLocal}s to the resolved user.

The resolved user can be the user returned by one of the
\texttt{AuthVerifier} instances or a guest user if no instance was able
to verify the provided credentials. \texttt{AuthVerifier}s are created
by developers, and are processed automatically as long as they're
registered in the OSGi runtime. Each Auth Verifier gets its own
configuration in \emph{Control Panel} → \emph{System Settings} →
\emph{Security} → \emph{API Authentication}. Configuration for Auth
Verifiers that ship with the product include

\begin{itemize}
\tightlist
\item
  Basic Auth Header
\item
  Digest Authentication
\item
  HTTP Tunnel Extender
\item
  Image Request
\item
  Portal Sessions
\item
  Request Parameter
\item
  Tunnel Auth
\end{itemize}

The following Auth Verifiers are enabled by default and can be used to
access remote API out-of-the-box:

\begin{itemize}
\tightlist
\item
  Basic Auth Header
\item
  Portal Sessions
\end{itemize}

\section{Basic Auth Header}\label{basic-auth-header}

This Auth Verifier allows the remote client to authenticate using
\href{https://en.wikipedia.org/wiki/Basic_access_authentication}{HTTP
Basic Authentication}. Configure it by providing URL paths that should
be authenticated this way. When Force Basic Authentication field is
checked then HTTP Basic Authentication is required.

The default URLs are \texttt{/api/*,/xmlrpc*} for web services. The
mapping excludes \texttt{/api/liferay*} to prevent accessing
\texttt{TunnelServlet}. For more information please see Tunnel
Authentication Verifiers.

\section{Digest Auth Header}\label{digest-auth-header}

This Auth Verifier allows the remote client to authenticate using
\href{https://en.wikipedia.org/wiki/Digest_access_authentication}{HTTP
Digest Authentication}. Configure it by providing URL paths that should
be authenticated this way. When Force Digest Authentication field is
checked then HTTP Basic Authentication is required.

This Auth Verifier is not enabled by default.

\section{HTTP Tunnel Extender}\label{http-tunnel-extender}

As Liferay embraced modularity, this extender was written to enable
modules to be part of \texttt{TunnelServlet}. It maps
\texttt{TunnelServlet} and \texttt{TunnelingServletAuthVerifier} to the
module servlet context. Modules with \texttt{Http-Tunnel} in the
manifest can make use of the Tunnel Servlet, and can expose the API via
\texttt{/o/\_module\_/api/liferay/do}.

Configure it by setting client IP addresses allowed to tunnel. For more
information, please see
\href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#HTTP\%20Tunneling}{the
properties documentation} as well as
\href{/docs/7-2/user/-/knowledge_base/u/enabling-remote-live-staging}{remote
staging}.

Note that this is not a recommended way to export remote APIs; it's far
better to expose remote services using JAX-RS or Liferay JSON Web
Service technologies.

\section{Image Request Authentication
Verifier}\label{image-request-authentication-verifier}

When connected to LibreOffice/OpenOffice, the Office process must
download images from Liferay DXP to render docs with images. To do this,
a \href{https://jwt.io}{JWT Token} is created to access the images
securely.

Configure this by setting the Hosts Allowed, URLs included, and URLs
excluded if necessary.

This Auth Verifier is not enabled by default.

\section{Portal Sessions Auth
Verifiers}\label{portal-sessions-auth-verifiers}

Enables JavaScript in a browser to access Liferay JSON Web Services
using an existing portal session.

In the default configuration, the URLs included field shields access to
the legacy JSON remote services layer:
\texttt{/api/json*,/api/jsonws*,/c/portal/json\_service*}.

\section{Request Parameter Auth
Verifiers}\label{request-parameter-auth-verifiers}

For backwards compatibility with \texttt{RequestParameterAutoLogin} you
can authenticate and access portal endpoints with credentials inside
HTTP request parameters \texttt{parameterAutoLoginLogin} and
\texttt{parameterAutoLoginPassword}.

This Auth Verifier is not enabled by default.

\section{Tunnel Authentication
Verifiers}\label{tunnel-authentication-verifiers}

\texttt{TunnelServlet} is a legacy remote API endpoint mapped at
\texttt{/api/liferay/do} to provide access to the portal remote
services. The Tunnel Auth Verifier allows trusted remote clients
authenticated access using any user ID provided, on behalf of the user.

An example of a trusted remote client is the Staging remote publishing
feature.

Trusted remote clients authenticate using a shared secret stored in the
portal property \texttt{tunneling.servlet.shared.secret}. The default
value is empty and forbids all access.

Even though the default configuration is enabled by default, access is
limited to localhost only. Configure it by setting client IP addresses
allowed to tunnel. For more information, please see
\href{https://docs.liferay.com/portal/7.2-latest/propertiesdoc/portal.properties.html\#HTTP\%20Tunneling}{the
properties documentation} as well as
\href{/docs/7-2/user/-/knowledge_base/u/enabling-remote-live-staging}{remote
staging}.

\section{Related Topics}\label{related-topics-4}

\href{/docs/7-2/deploy/-/knowledge_base/d/service-access-policies}{Service
Access Policies}

\chapter{LDAP}\label{ldap}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

LDAP is a common user store for Liferay DXP. You can configure LDAP at
the system scope in System Settings or at the instance scope in Instance
settings. Users can be imported from LDAP or exported to LDAP. To access
LDAP configuration settings, navigate to \emph{Control Panel →
Configuration} → \emph{Instance Settings}. At the bottom of the list on
the left, click \emph{Servers}.

Click the \emph{Add} button to add an LDAP server connection. If you
have more than one LDAP server, you can arrange the servers by order of
preference using the up/down arrows. Regardless of how many LDAP servers
you add, each server has the same configuration options.

\textbf{Server Name:} Enter a name for your LDAP server.

\textbf{Default Values:} Several common directory servers appear here.
If you use one of these, select it. The rest of the form is populated
with default values for that directory.

\section{Connection}\label{connection}

These settings cover the connection to LDAP.

\textbf{Base Provider URL:} The link to the LDAP server. Make sure the
Liferay DXP server can communicate with the LDAP server. If there is a
firewall between the two systems, make sure the appropriate ports are
opened.

\textbf{Base DN:} The Base Distinguished Name for your LDAP directory.
It is usually modeled after your organization. It may look similar to
this: \texttt{dc=companynamehere,dc=com}.

\textbf{Principal:} The default LDAP administrator user ID is populated
here. If your administrator ID differs, use that credential instead. You
need an administrative credential because Liferay DXP uses this ID to
synchronize user accounts to and from LDAP.

\textbf{Credentials:} This is the password for the LDAP administrative
user.

This is all you need to make a regular connection to an LDAP directory.
The rest of the configuration, however, may need to be customized, as it
represents ``best guesses'' as to correct defaults. The default
attribute mappings usually provide enough data to synchronize back to
the Liferay DXP database when a user attempts to log in. To test the
connection to your LDAP server, click the \emph{Test LDAP Connection}
button.

\section{Checkpoint}\label{checkpoint-1}

Before proceeding to fine tune Liferay DXP's LDAP connections, ensure
the following steps have been taken:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The LDAP connection is enabled. Depending on your needs, LDAP
  authentication may be required so that only users who have been bound
  may log in.
\item
  \emph{Export/Import}: for users in a clustered environment, Enable
  Import/Export on Startup should be disabled so that there are no
  massive imports on every node upon start up.
\item
  When adding the LDAP server, the \emph{Server Name}, \emph{Default
  Values}, \emph{Connection} values are correct. It is always a good
  idea to click the \emph{Test LDAP Connection} before saving.
\end{enumerate}

\section{Instance Settings vs.~System
Settings}\label{instance-settings-vs.-system-settings}

You can define an LDAP server connection at the System Settings scope as
well. Because this user interface is auto-generated, it's not as helpful
as the one in Instance Settings. For this reason, you should define and
troubleshoot your settings in Instance Settings first. If you decide you
want your LDAP connection at the system scope, you can copy your
configuration from Instance Settings and then delete the server from
Instance Settings.

Of course, you can also configure LDAP servers at the system scope using
OSGi \texttt{.config} files. The easiest way to do this is to use the
GUI and export the configuration. Then you can use the resulting
\texttt{.config} file anywhere you need it (such as other nodes in a
cluster).

\textbf{Note:} To use \texttt{config} files for LDAP server
configuration, you must specify the Virtual Instance ID (in the source,
the variable name is \texttt{companyId}) in the exported configuration
file, because servers are defined at the instance scope, not the system
scope. To do this, specify the virtual instance ID somewhere in the file
like this:

\begin{verbatim}
companyId=1234
\end{verbatim}

You can find your Virtual Instance ID in Control Panel → Configuration →
Virtual Instances.

\section{Security}\label{security}

If you run your LDAP directory in SSL mode to encrypt credential
information on the network, you must perform extra steps to share the
encryption key and certificate between the two systems.

For example, if your LDAP directory is Microsoft Active Directory on
Windows Server 2003, you'd share the certificate like this:

Click \emph{Start} → \emph{Administrative Tools} → \emph{Certificate
Authority}. Highlight the machine that is the certificate authority,
right-click on it, and click \emph{Properties}. From the General menu,
click \emph{View Certificate}. Select the Details view, and click
\emph{Copy To File}. Use the resulting wizard to save the certificate as
a file. You must also import the certificate into the \emph{cacerts
keystore} like this:

\begin{verbatim}
keytool -import -trustcacerts -keystore /some/path/java-8-jdk/jre/lib/security/cacerts -storepass changeit -noprompt -alias MyRootCA -file /some/path/MyRootCA.cer
\end{verbatim}

The \texttt{keytool} utility ships as part of the Java SDK.

Once this is done, go back to the LDAP page in the Control Panel. Modify
the LDAP URL in the Base DN field to the secure version by changing the
protocol to \texttt{ldaps} and the port to \texttt{636} like this:

\begin{verbatim}
ldaps://myLdapServerHostname:636
\end{verbatim}

Save the changes. Communication to LDAP is now encrypted.

\section{Configuring LDAP
Import/Export}\label{configuring-ldap-importexport}

The other settings configure mappings between LDAP and Liferay DXP so
users and groups can be imported.

\section{Users}\label{users}

This section contains settings for finding users in your LDAP directory.

\textbf{Authentication Search Filter:} Use this search filter box to
determine the search criteria for user logins. By default, Liferay DXP
uses users' email addresses for their login names. The value here must
use the authentication method you use. For example, if you changed
Liferay DXP's authentication method to use screen names instead of the
email addresses, you would modify the search filter so it can match the
entered log in name:

\begin{verbatim}
(cn=@screen_name@)
\end{verbatim}

\textbf{Import Search Filter:} Depending on the LDAP schema, there are
different ways to identify the user. The default setting is usually
fine:

\begin{verbatim}
(objectClass=inetOrgPerson)
\end{verbatim}

If you want to search for only a subset of users or users that have
different LDAP object classes, you can change this.

\textbf{User Mapping:} Next, you can define mappings from LDAP
attributes to Liferay fields. Though LDAP user attributes may be
different from LDAP server to LDAP server, there are five fields Liferay
DXP requires to be mapped for the user to be recognized:

\begin{itemize}
\tightlist
\item
  \emph{Screen Name} (e.g., \texttt{uid} or \texttt{cn})
\item
  \emph{Password} (e.g., \texttt{userPassword})
\item
  \emph{Email Address} (e.g., \texttt{mail} or \texttt{email})
\item
  \emph{First Name} (e.g., \texttt{name} or \texttt{givenName})
\item
  \emph{Last Name} (e.g., \texttt{sn})
\end{itemize}

\textbf{Note:} If you intend to create or import users with no email
addresses, you must set \texttt{users.email.address.required=false} in
\texttt{portal-ext.properties}. With this set, Liferay auto-generates an
email address combining the user ID plus the suffix defined in the
property \texttt{users.email.address.auto.suffix=}. Finally, make sure
to set Liferay and LDAP authentication to something other than email
address.

If you want to import LDAP groups as Liferay DXP user groups, make sure
define a mapping for the Liferay DXP group field so that membership
information is preserved:

\begin{itemize}
\tightlist
\item
  \emph{Group} (e.g., \emph{member})
\end{itemize}

The other LDAP user mapping fields are optional.

The Control Panel provides default mappings for commonly used LDAP
attributes. You can also add your own mappings.

\textbf{Test LDAP Users:} Once you have your attribute mappings set up
(see above), click the \emph{Test LDAP Users} button and Liferay DXP
attempts to pull LDAP users and match them with their mappings as a
preview.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/testing-ldap-users.png}}
\caption{You should see a list of users when you click the \emph{Test
LDAP Users} button.}
\end{figure}

\section{Groups}\label{groups}

This section contains settings for mapping LDAP groups to Liferay DXP
user groups.

\textbf{Import Search Filter:} This is the filter for mapping LDAP
groups to Liferay DXP user groups. For example,

\begin{verbatim}
(objectClass=groupOfNames)
\end{verbatim}

Enter the LDAP group attributes you want retrieved for this mapping. The
following attributes can be mapped. The \emph{Group Name} and
\emph{User} fields are required, the \emph{Description} is optional.

\begin{itemize}
\item
  \emph{Group Name} (e.g., \texttt{cn} or \texttt{o})
\item
  \emph{Description} (e.g., \texttt{description})
\item
  \emph{User} (e.g., \texttt{member})
\end{itemize}

\textbf{Test LDAP Groups:} Click the \emph{Test LDAP Groups} button to
display a list of the groups returned by your search filter.

\section{Export}\label{export}

This section contains settings for exporting user data from LDAP.

\textbf{Users DN:} Enter the location in your LDAP tree where the users
are stored. Liferay DXP exports the users to this location.

\textbf{User Default Object Classes:} Users are exported with the listed
default object classes. To find out what your default object classes
are, use an LDAP browser tool such as Apache Directory Studio to locate
a user and view the Object Class attributes stored in LDAP for that
user.

\textbf{Groups DN:} Enter the location in your LDAP tree where the
groups are stored. When Liferay DXP does an export, it exports the
groups to this location.

\textbf{Group Default Object Classes:} When a group is exported, the
group is created with the listed default object classes. To find out
what your default object classes are, use an LDAP browser tool such as
\href{https://directory.apache.org/studio}{Apache Directory Studio} to
locate a group and view the Object Class attributes stored in LDAP for
that group.

When you've set all your options and tested your connection, click
\emph{Save}.

\noindent\hrulefill

\textbf{Note:} If a user changes a value like a password in Liferay DXP,
that change is passed to the LDAP server, provided Liferay DXP has
enough schema access to make the change.

\noindent\hrulefill

Now you know how to connect an LDAP server to Liferay DXP and how to
configure user import behavior, export behavior, and other LDAP
settings.

\section{Related Topics}\label{related-topics-5}

\href{/docs/7-0/deploy/-/knowledge_base/d/liferay-portal-security-overview}{Liferay
DXP Security Overview}
\href{/docs/7-0/deploy/-/knowledge_base/d/logging-in-to-liferay}{Logging
into Liferay DXP}

\chapter{Configuring LDAP}\label{configuring-ldap}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

In this article, you'll learn how to configure import settings, export
settings, and related LDAP configuration settings.

To access LDAP configuration settings, navigate to \emph{Control Panel →
Configuration} → \emph{Instance Settings} → \emph{Security} →
\emph{LDAP}. There are four categories on the left: Export, General,
Import, and Servers. The Servers category was covered in
\href{/docs/7-2/deploy/-/knowledge_base/d/ldap}{the last article}. The
rest are covered below.

\section{Export}\label{export-1}

\textbf{Enable Export:} Check this box to export user accounts to LDAP.
A listener tracks changes made to the \texttt{User} object and pushes
updates to the LDAP server whenever a \texttt{User} object is modified.
Note that by default on every login, fields such as
\texttt{lastLoginDate} are updated. When export is enabled, this causes
a user export every time the user logs in. You can prevent updates to
users' \texttt{lastLoginDate} fields from triggering LDAP user exports
by setting the following property in your \texttt{portal-ext.properties}
file:

\begin{verbatim}
users.update.last.login=false
\end{verbatim}

\textbf{Enable Group Export:} Export groups to LDAP.

\section{General}\label{general}

\textbf{Enabled:} Check this box to enable LDAP Authentication.

\textbf{Required:} Check this box if LDAP authentication is required.
Users can't log in unless they can bind to the LDAP directory
successfully. Uncheck this box if users with Liferay DXP accounts but no
LDAP accounts can log in.

\textbf{Use LDAP Password Policy:} Liferay DXP uses its own password
policy by default. This can be configured on the Control Panel's
Password Policies page. Check the \emph{Use LDAP Password Policy} box if
you want to use the password policies defined by your LDAP directory.
Once this is enabled, the Password Policies tab states that you are not
using a local password policy. You must now use your LDAP directory's
mechanism for setting password policies. Liferay DXP cannot enforce
these policies; the best it can do is pass through the messages returned
by your LDAP server. It does this by parsing the messages in the LDAP
controls the server returns. By default, Liferay DXP is configured to
parse the messages returned by the Fedora Directory Server. If you use a
different LDAP server, you must customize the messages in \emph{System
Settings} → \emph{Security} → \emph{LDAP} → \emph{Connection}.

\textbf{Method:} Choose \emph{Bind} (the default) or \emph{Password
Compare}. Bind does a standard LDAP bind; Password Compare attempts to
compare Liferay and LDAP passwords using the encryption algorithm
specified in the field below. Password Compare is rarely used.

\textbf{Password Encryption Algorithm:} Choose the password encryption
algorithm your LDAP server uses to encrypt passwords so they can be
compared if using the Password Compare bind method. This is rarely used.

\section{Import}\label{import}

You can import user data from LDAP directories using the following
options:

\textbf{Enable Import:} Check this box to do a mass import from your
LDAP directories. Otherwise, Users are imported as they log in.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/imported-ldap-users.png}}
\caption{Ziltoid and Rex have been imported because they logged in.}
\end{figure}

\textbf{Enable Import on Startup:} Check this box to do the mass import
when Liferay DXP starts. Note: this box only appears if you check
\textbf{Enable Import}, described above. Definitely leave this unchecked
if you have a Liferay DXP cluster, or all your nodes will do a mass
import when each of them starts up.

\textbf{Import Interval:} When mass importing users, import users every
X minutes.

\textbf{Import Method:} Set either User or Group. If you set this to
User, Liferay DXP imports all users from the location specified in the
server connection. If you set this to Group, Liferay DXP searches all
the groups and imports the users in each group. If you have users who do
not belong to any groups, they are not imported.

\textbf{Lock Expiration Time:} Set the account lock expiration time for
LDAP User import. The default is one day.

\textbf{Import User Sync Strategy:} Set the strategy used to sync user
accounts. Options are Auth Type (i.e., the way the user authenticates,
like with screen name) and UUID (requires a UUID attribute in LDAP).

\textbf{Enable User Password on Import:} Assign a default password (see
below) when users are imported, so they can be synced between the two
systems.

\textbf{Autogenerate User Password on Import:} Create a random password
on user import.

\textbf{Default User Password:} Enter the default password users are
assigned when they first log in via LDAP.

\textbf{Enable Group Cache on Import:} Cache the imported groups so
import isn't slowed by database access.

\textbf{Create Role per Group on Import:} For every LDAP group, create a
corresponding Liferay Role.

\section{Servers}\label{servers}

\textbf{LDAP Servers:} Liferay DXP supports connections to multiple LDAP
servers. Use the \emph{Add} button to add LDAP servers. Each LDAP server
has several configuration options
\href{/docs/7-2/deploy/-/knowledge_base/d/ldap}{explained here}.

Once you've finished configuring LDAP, click the \emph{Save} button.

\section{LDAP Options Available in System
Settings}\label{ldap-options-available-in-system-settings}

Although most LDAP configuration can be done from Instance Settings,
there are several configuration parameters that are only available in
System Settings. There are also settings duplicated from the ones in
Instance Settings. These change the \emph{default} settings for new
virtual instances (see note below).

\noindent\hrulefill

\textbf{Note}: When you make a change in System Settings, it takes
effect for the virtual instance you're in. If after changing a setting
you create a new virtual instance, that virtual instance inherits the
settings of the one it was created from as defaults. For example, say
you have virtual instances named A, B, and C. From A, you modify
\emph{Error password history keywords}. This change appears only in A,
not in B or C. Then from A, you create virtual instance D. The change to
\emph{Error password history keywords} appears in D (not B or C), since
D defaults to A's settings because you created it from A.

\noindent\hrulefill

If you must change any of these options, navigate to \emph{Control
Panel} → \emph{Configuration} → \emph{System Settings}. Go to the
\emph{Security} section and find the entries with LDAP in the title. The
only new settings here are in the \emph{Connection} entry.

Use the \emph{Connection} entry to manage error properties like
\emph{Error password age keywords} which lets you set a list of phrases
from error messages which can possibly be returned by the LDAP server.
When a user binds to LDAP, the server returns \emph{controls} with its
response of success or failure. These controls contain a message
describing the error or the information that is returned with the
response. Though the controls are the same across LDAP servers, the
messages can be different. The properties described here contain
snippets of words from those messages and work with Red Hat's Fedora
Directory Server. If you are not using that server, the word snippets
may not work with your LDAP server. If they don't, you can replace the
values of these properties with phrases from your server's error
messages. This enables Liferay DXP to recognize them.

\chapter{Token-based Single Sign On
Authentication}\label{token-based-single-sign-on-authentication}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Token-based SSO authentication was introduced in Liferay DXP 7.0 to
standardize support for Shibboleth, SiteMinder, Oracle OAM, or any other
SSO product that works by propagating a token via one of the following
mechanisms:

\begin{itemize}
\tightlist
\item
  HTTP request parameter
\item
  HTTP request header
\item
  HTTP cookie
\item
  Session attribute
\end{itemize}

Since these providers have a built-in web server module, you should use
the Token SSO configuration.

The authentication token contains the Liferay DXP user's screen name or
email address, whichever Liferay DXP has been configured to use for the
particular company (portal instance). Recall that Liferay DXP supports
three authentication methods:

\begin{itemize}
\tightlist
\item
  By email address
\item
  By screen name
\item
  By user ID
\end{itemize}

Token-based authentication only supports email address and screen name.
If Liferay DXP is configured to use user ID when a token-based
authentication is attempted, the \texttt{TokenAutoLogin} class logs this
warning:

\begin{verbatim}
Incompatible setting for: company.security.auth.type
\end{verbatim}

Please note that the above sources are fully trusted.

Furthermore, you must use a security mechanism external to Liferay DXP,
such as a fronting web server like Apache. The chosen fronting solution
must prevent malicious Liferay DXP user impersonation that otherwise
might be possible by sending HTTP requests directly to Liferay DXP from
the client's web browser.

Token-based authentication is disabled by default. To manage token-
based SSO authentication, navigate to Control Panel → \emph{System
Settings}, → \emph{Security} → \emph{SSO}. Token Based SSO appears in
Virtual Instance Scope at the bottom. Here are the configuration options
for the Token Based SSO module:

\textbf{Enabled:} Check this box to enable token-based SSO
authentication.

\textbf{Import from LDAP:} Check this box to import users automatically
from LDAP if they don't exist.

\textbf{User token name:} Set equal to the name of the token. This is
retrieved from the specified location. (Example: SM\_USER)

\textbf{Token location:} Set this to the location of the user token. As
mentioned earlier, the options are:

\begin{itemize}
\tightlist
\item
  HTTP request parameter
\item
  HTTP request header
\item
  HTTP cookie
\item
  Session attribute
\end{itemize}

\textbf{Authentication cookies:} Set this to the cookie names that must
be removed after logout. (Example: \texttt{SMIDENTITY},
\texttt{SMSESSION})

\textbf{Logout redirect URL:} When user logs out of Liferay DXP, the
user is redirected to this URL.

Remember to click \emph{Save} to activate Token Based SSO.

\section{Required SiteMinder
Configuration}\label{required-siteminder-configuration}

If you use SiteMinder, note that Liferay DXP sometimes uses the tilde
character in its URLs. By default, SiteMinder treats the tilde character
(and others) as bad characters and returns an HTTP 500 error if it
processes a URL containing any of them. To avoid this issue, change this
default setting in the SiteMinder configuration to this one:

\begin{verbatim}
BadUrlChars       //,./,/.,/*,*.,\,%00-%1f,%7f-%ff,%25
\end{verbatim}

The configuration above is the same as the default except the
\texttt{\textasciitilde{}} was removed from the bad URL character list.
Restart SiteMinder to make your configuration update take effect. For
more information, please refer to SiteMinder's
\href{https://support.ca.com/cadocs/0/CA\%20SiteMinder\%20r6\%200\%20SP6-ENU/Bookshelf_Files/HTML/index.htm?toc.htm?258201.html}{documentation}

\section{Summary}\label{summary-1}

Liferay DXP's token-based SSO authentication mechanism is highly
flexible and compatible with any SSO solution that provides it with a
valid Liferay DXP user's screen name or email address. These include
Shibboleth and SiteMinder.

\chapter{Authenticating with OpenID
Connect}\label{authenticating-with-openid-connect}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

OpenID Connect is a lightweight authentication layer built on top of the
\href{/docs/7-2/deploy/-/knowledge_base/d/oauth-2-0}{OAuth 2.0}
authorization protocol. It compliments local accounts by enabling users
to authenticate using accounts they have on other systems. Users who
avoid signing up for new accounts can then use an account they already
have to sign into your website. By using OpenID Connect, you
\emph{delegate} user authentication to other providers, making it easy
for users with existing accounts to authenticate to your system.

\noindent\hrulefill

\textbf{Note:} You can add multiple providers to your installation, but
Liferay DXP can't be an OpenID Connect provider.

\noindent\hrulefill

Because OpenID Connect is built on OAuth 2.0, its token flow is similar.
OAuth 2.0 is only an authorization protocol, so it sends an \emph{access
token} that grants access to particular APIs. OpenID Connect adds to
this an \emph{identity token} that passes user information like name and
email, provided the user has authenticated and granted permission.

\section{Creating a Client in OpenID Connect
Provider}\label{creating-a-client-in-openid-connect-provider}

To use OpenID Connect, you must first register it as a client in your
provider. This is an OAuth 2.0 client. The process varies by provider:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Navigate to the provider's website and create a client.
\item
  During the creation process, you must supply an \emph{authorized
  redirect URL} that can process the tokens sent from the provider.
  Liferay DXP's URL is

\begin{verbatim}
https://[server.domain]/c/portal/login/openidconnect
\end{verbatim}
\item
  The provider sends several pieces of information. Some of these, like
  the Discovery Endpoint, Authorization Endpoint, or Issuer URL are the
  same regardless of the client. The two pieces of information unique to
  your request are the \texttt{client\_id} and the
  \texttt{client\_secret}.
\end{enumerate}

Collect the information from the provider. You'll need it create the
provider next.

\section{Configuring an OpenID Connect Provider
Connection}\label{configuring-an-openid-connect-provider-connection}

Go to \emph{Control Panel} → \emph{Configuration} → \emph{System
Settings} → \emph{Security} → \emph{SSO} and select \textbf{\emph{OpenID
Connect Provider}} under the \emph{System Scope} and follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add the provider by clicking the \emph{Add} button.
\item
  Use the information you received from the provider to fill out the
  form:
\end{enumerate}

\textbf{Provider Name:} This name appears in the Sign-In Portlet when
users use OpenID Connect to log in.

\textbf{OpenID Client ID:} Provide the OAuth 2.0 Client ID you received
from your provider.

\textbf{OpenID Connect Client Secret:} Provide the OAuth 2.0 Client
Secret you received from your provider.

\textbf{Scopes:} Leave the default, which requests the user name and the
email. Your provider may offer other scopes of user information.

\textbf{Discovery Endpoint:} Other URLs may be obtained from this URL,
and they vary by provider.

\textbf{Discovery Endpoint Cache in Milliseconds:} Cache the endpoints
(URLs) discovered for this amount of time.

\textbf{Authorization Endpoint:} This URL points to the provider's URL
for authorizing the user (i.e., signing the user in).

\textbf{Issuer URL:} The provider's URL that points to information about
the provider who is issuing the user information.

\textbf{JWKS URI:} A URL that points to the provider's JSON Web Key Set
that contains the public keys that can verify the provider's tokens.

\textbf{ID Token Signing Algorithms:} Set the supported ID token
algorithms manually. Normally, this is ``discovered'' at the discovery
endpoint. You can add as many of these as you need.

\textbf{Subject Types:} A Subject Identifier is a unique and never
reassigned identifier the provider uses to establish who the user is,
and is consumed by the client (i.e., Liferay DXP). There are two types:
public (provides the same value to all clients) and private (provides a
different value to each client).

\textbf{Token Endpoint:} The provider's URL where tokens can be
requested.

\textbf{User Information Endpoint:} The OAuth 2.0 protected URL from
which user information can be obtained.

Once you've filled out the form, click \emph{Save}, and you're ready to
enable OpenID Connect authentication.

\noindent\hrulefill

System Settings configuration file:

\begin{verbatim}
 com.liferay.portal.security.sso.openid.connect.internal.configuration.OpenIdConnectProviderConfiguration-[name].config
\end{verbatim}

where \texttt{{[}name{]}} is a descriptive, but unique name for example
\texttt{provider1}.

\noindent\hrulefill

\section{Enabling OpenID Connect
Authentication}\label{enabling-openid-connect-authentication}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to \emph{Control Panel} → \emph{Configuration} → \emph{System
  Settings} → \emph{Security} → \emph{SSO} and select
  \textbf{\emph{OpenID Connect}} under \emph{Virtual Instance Scope}.
\item
  Click the \emph{Enabled} check box, and then click \emph{Save}.
\end{enumerate}

\textbf{Note:} You can also enable OpenID Connect authentication for the
given virtual instance through the \emph{Control Panel} →
\emph{Configuration} → \emph{Instance Settings} → \emph{OpenID Connect}
tab.

\noindent\hrulefill

System Settings configuration file:

\begin{verbatim}
 com.liferay.portal.security.sso.openid.connect.configuration.OpenIdConnectConfiguration.config
\end{verbatim}

\noindent\hrulefill

Now users can sign in with OpenID Connect.

\section{Signing In With OpenID
Connect}\label{signing-in-with-openid-connect}

There's a new link in the Sign-In Portlet for signing in with OpenID
Connect:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From the Sign-In Portlet, click the OpenID Connect link at the bottom.
\item
  Choose a provider and click \emph{Sign In}.
\item
  This takes you to your provider's sign in page. Enter your credentials
  and log in.
\item
  Upon successful authentication, you're redirected back to Liferay DXP
  in an authenticated state.
\end{enumerate}

OpenID is a standards-based, secure way to authenticate users from other
systems.

\chapter{OpenAM Single Sign On
Authentication}\label{openam-single-sign-on-authentication}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

OpenAM is an open source single sign-on solution that comes from the
code base of Sun's System Access Manager product. Liferay DXP integrates
with OpenAM, allowing you to use OpenAM to integrate Liferay DXP into an
infrastructure that contains a multitude of different authentication
schemes against different repositories of identities.

Note that OpenAM relies on cookie sharing between applications. Thus, in
order for OpenAM to work, \textbf{all applications that require SSO must
be in the same web domain}. You should also add the following property
if you have enabled HTTPOnly cookies due to the way some web containers
(like Apache Tomcat™) parse cookies that contain special characters:

\begin{verbatim}
com.iplanet.am.cookie.encode=true
\end{verbatim}

You can install OpenAM on the same or different server as Liferay DXP.
Be sure to review the context path and server hostname for your OpenAM
server.

If you want to install OpenAM on the same server as Liferay DXP, you
must deploy the OpenAM \texttt{.war}, downloadable from
\href{https://backstage.forgerock.com/downloads/browse/am/archive/productId:openam}{here}.
Otherwise, follow the instructions at the
\href{https://backstage.forgerock.com/docs/openam/13/install-guide/}{OpenAM
13 site} to install OpenAM.

\noindent\hrulefill

\textbf{Note}: OpenAM 12 and below work with Liferay DXP, but are at end
of life. Because of this, we recommend only OpenAM 13 for production
use.

\noindent\hrulefill

Once you have it installed, create the Liferay DXP administrative user
in it. Users are mapped back and forth by screen names. By default, the
Liferay DXP administrative user has a screen name of \emph{test}, so if
you were to use that account, register the user in OpenAM with the ID of
\emph{test} and the email address specified in the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Admin\%20Portlet}{\texttt{admin.email.from.address}}
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{portal
property}). Once you have the user set up, log in to OpenAM using this
user.

In the same browser window, log in to Liferay DXP as the administrative
user (using the previous admin email address). Go to the Control Panel
and click \emph{Configuration} → \emph{Instance Settings} →
\emph{Security} → \emph{SSO}. Then choose \emph{OpenSSO} in the list on
the left.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/opensso-configuration.png}}
\caption{OpenSSO Configuration.}
\end{figure}

Modify the three URL fields (Login URL, Logout URL, and Service URL) so
they point to your OpenAM server (in other words, only modify the host
name portion of the URLs), check the \emph{Enabled} box, and click
\emph{Save}. Liferay DXP then redirects users to OpenAM when they
request the \texttt{/c/portal/login} URL \emph{for example, when they
click on the }Sign In* link).

Liferay DXP's OpenAM configuration can be applied at either the system
scope or at the instance scope. To configure the OpenAM SSO module at
the system scope, navigate to the Control Panel, click on
\emph{Configuration} → \emph{System Settings} → \emph{Security} →
\emph{SSO} → \emph{OpenSSO}. Click on it and you'll find these settings
to configure. The values configured here provide the default values for
all portal instances. Enter them in the same format as you would when
initializing a Java primitive type with a literal value.

Property Label \textbar{} Property Key \textbar{} Description \textbar{}
Type \textbf{Version} \textbar{} \texttt{version} \textbar{} OpenAM
version to use (12 and below or 13) \textbar{} \texttt{String}
\textbf{Enabled} \textbar{} \texttt{enabled} \textbar{} Check this box
to enable OpenAM authentication. Note that OpenAM works only if LDAP
authentication is also enabled and Liferay DXP's authentication type is
set to screen name. \textbar{} \texttt{boolean} \textbf{Import from
LDAP} \textbar{} \texttt{importFromLDAP} \textbar{} If this is checked,
users authenticated from OpenAM that do not exist in Liferay DXP are
imported from LDAP. LDAP must be enabled. \textbar{} \texttt{boolean}
\textbf{Login URL} \textbar{} \texttt{loginURL} \textbar{} The URL to
the login page of the OpenAM server \textbar{} \texttt{String}
\textbf{Logout URL} \textbar{} \texttt{logoutURL} \textbar{} The URL to
the logout page of the OpenAM server \textbar{} \texttt{String}
\textbf{Service URL} \textbar{} \texttt{serviceURL} \textbar{} The URL
by which OpenAM can be accessed to use the authenticated web services.
If you are using OpenAM Express 8 or higher, you need to have the server
running Java 6. \textbar{} \texttt{String} \textbf{Screen Name
Attribute} \textbar{} \texttt{screenNameAttr} \textbar{} The name of the
attribute on the OpenAM representing the user's screen name \textbar{}
\texttt{String} \textbf{Email Address Attribute} \textbar{}
\texttt{emailAddressAttr} \textbar{} The name of the attribute on the
OpenAM representing the user's email address \textbar{} \texttt{String}
\textbf{First Name Attribute} \textbar{} \texttt{firstNameAttr}
\textbar{} The name of the attribute on the OpenAM representing the
user's first name \textbar{} \texttt{String} \textbf{Last Name
Attribute} \textbar{} \texttt{lastNameAttr} \textbar{} The name of the
attribute on the OpenAM representing the user's last name \textbar{}
\texttt{String}

To override these default settings for a particular portal instance,
navigate to the Control Panel and click \emph{Configuration} →
\emph{Instance Settings} → \emph{Security} → \emph{SSO}. Then choose
\emph{OpenSSO} in the list on the left.

\chapter{CAS (Central Authentication Service) Single Sign On
Authentication}\label{cas-central-authentication-service-single-sign-on-authentication}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

CAS is an authentication system originally created at Yale University.
It is a widely used open source single sign-on solution and was the
first SSO product to be supported by Liferay DXP. @product@'s CAS module
includes the CAS client, so there's no need to install it separately.

\noindent\hrulefill

\textbf{Note:} Liferay DXP supports CAS 3.3.x. If you use a later
version of CAS, it is best to use CAS's support for standards such as
OpenID Connect or SAML to interface with Liferay DXP.

\noindent\hrulefill

The CAS Server application requires your server to have a properly
configured Secure Socket Layer (SSL) certificate. To generate one
yourself, use the \texttt{keytool} utility that comes with the JDK.
First generate the key, then export the key into a file. Finally, import
the key into your local Java key store. For public, Internet-based
production environments, you must purchase a signed key from a
recognized certificate authority or have your key signed by a recognized
certificate authority. For Intranets, you should have your IT department
pre-configure users' browsers to accept the certificate so they don't
get warning messages about the certificate.

To generate a key, use the following command:

\begin{verbatim}
keytool -genkey -alias tomcat -keypass changeit -keyalg RSA
\end{verbatim}

Instead of the password in the example (\texttt{changeit}), use a
password you can remember. If you are not using Tomcat, you may want to
use a different alias as well. For first and last names, enter
\texttt{localhost} or the host name of your server. It cannot be an IP
address.

To export the key to a file, use the following command:

\begin{verbatim}
keytool -export -alias tomcat -keypass changeit -file server.cert
\end{verbatim}

Finally, to import the key into your Java key store, use the following
command:

\begin{verbatim}
keytool -import -alias tomcat -file server.cert -keypass changeit -keystore $JAVA_HOME/jre/lib/security/cacerts
\end{verbatim}

If you are on a Windows system, replace \texttt{\$JAVA\_HOME} above with
\texttt{\%JAVA\_HOME\%}. Of course, all of this must be done on the
system where CAS is running.

Once your CAS server is up and running, configure Liferay DXP to use it.
CAS configuration can be applied either at the system scope or at the
scope of a portal instance. To configure the CAS SSO module at the
system or instance scope, navigate to the Control Panel, click on
\emph{Configuration} → \emph{System Settings} (or \emph{Instance
Settings}) → \emph{Security} → \emph{SSO}. The values configured in
System Settings provide the default values for all portal instances.
Enable CAS authentication and then modify the URL properties to point to
your CAS server.

\textbf{Enabled:} Check this box to enable CAS single sign-on.

\textbf{Import from LDAP:} A user may be authenticated from CAS and not
yet exist in Liferay DXP. Select this to automatically import users from
LDAP if they do not exist in Liferay DXP. For this to work, LDAP must be
enabled.

The rest of the settings are various URLs with defaults included. Change
\emph{localhost} in the default values to point to your CAS server. When
you are finished, click \emph{Save}. After this, when users click the
\emph{Sign In} link, they are directed to the CAS server to sign in to
Liferay DXP.

For some situations, it might be more convenient to specify the system
configuration via files on the disk. To do so, create the following
file:

\begin{verbatim}
{LIFERAY_HOME}/osgi/configs/com.liferay.portal.security.sso.cas.configuration.CASConfiguration.cfg
\end{verbatim}

The format of this file is the same as any properties file. The key to
use for each property that can be configured is shown below. Enter
values in the same format as you would when initializing a Java
primitive type with a literal value.

Property Label \textbar{} Property Key \textbar{} Description \textbar{}
Type \textbf{Enabled} \textbar{} \texttt{enabled} \textbar{} Check this
box to enable CAS SSO authentication. \textbar{} \texttt{boolean}
\textbf{Import from LDAP} \textbar{} \texttt{importFromLDAP} \textbar{}
Users authenticated from CAS that do not exist in Liferay DXP are
imported from LDAP. LDAP must be enabled separately. \textbar{}
\texttt{boolean} \textbf{Login URL} \textbar{} \texttt{loginURL}
\textbar{} Set the CAS server login URL. \textbar{} \texttt{String}
\textbf{Logout on session expiration} \textbar{}
\texttt{logoutOnSessionExpiration} \textbar{} If checked, browsers with
expired sessions are redirected to the CAS logout URL. \textbar{}
\texttt{boolean} \textbf{Logout URL} \textbar{} \texttt{logoutURL}
\textbar{} The CAS server logout URL. Set this if you want Liferay DXP's
logout function to trigger a CAS logout \textbar{} \texttt{String}
\textbf{Server Name} \textbar{} \texttt{serverName} \textbar{} The name
of the Liferay DXP instance (e.g., \texttt{liferay.com}). If the
provided name includes the protocol (\texttt{https://}, for example)
then this will be used together with the path \texttt{/c/portal/login}
to construct the URL to which the CAS server will provide tickets. If no
scheme is provided, the scheme normally used to access the @product@
login page will be used. \textbar{} \texttt{String} \textbf{Server URL}
\textbar{} \texttt{serviceURL} \textbar{} If provided, this will be used
as the URL to which the CAS server provides tickets. This overrides any
URL constructed based on the Server Name as above. \textbar{}
\texttt{String} \textbf{No Such User Redirect URL} \textbar{}
\texttt{noSuchUserRedirectURL} \textbar{} Set the URL to which to
redirect the user if the user can authenticate with CAS but cannot be
found in Liferay DXP. If import from LDAP is enabled, the user is
redirected if the user could not be found or could not be imported from
LDAP. \textbar{} \texttt{String}

To override system defaults for a particular portal instance, navigate
to the Control Panel, click on \emph{Configuration} → \emph{Instance
Settings}, click on \emph{Authentication} on the right and then on
\emph{CAS} at the top.

\chapter{Authenticating Using SAML}\label{authenticating-using-saml}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The SAML (Security Assertion Markup Language) adapter provides Single
Sign On (SSO) and Single Log Off (SLO) in your deployment. Each Liferay
DXP instance serves as either the Service Provider (SP) or the Identity
Provider (IdP). An identity provider is a trusted provider that provides
single sign-on for users to access other websites. A service provider is
a website that hosts applications and grants access only to identified
users with proper credentials.

\noindent\hrulefill

\textbf{Note:} A single Liferay DXP instance is \emph{either} the SP or
the IdP in your SSO setup; it can't be both. You can, however, use
separate instances for both purposes (for example, one instance is the
SP and another is the IdP).

\noindent\hrulefill

Below is background on how SAML works. To jump right to its
configuration, see the articles on
\href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-liferay-as-a-saml-identity-provider}{Setting
Up SAML as an Identity Provider} or
\href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-liferay-as-a-saml-service-provider}{Setting
Up SAML as a Service Provider} for instructions on using the
\href{https://web.liferay.com/marketplace/-/mp/application/15188711}{SAML
adapter}. Use the instructions to make the conceptual magic from this
article come to life!

\section{What's new in Liferay Connector to SAML
2.0}\label{whats-new-in-liferay-connector-to-saml-2.0}

The \texttt{5.0.0} version of the application for Liferay DXP brings
some long-awaited improvements:

\begin{itemize}
\tightlist
\item
  Liferay DXP acting as a Service Provider (SP) can now connect to
  multiple Identity Providers (IdP).
\item
  Developers have an extension point for customizing which Identity
  Providers to users can use to sign in.
\item
  Support for other Signature Algorithms (like \texttt{SHA-256})
\item
  Signature method algorithm URL's can now be blacklisted from the
  metadata (for example, disabling \texttt{SHA-1}:
  \texttt{http://www.w3.org/2000/09/xmldsig\#rsa-sha1})
\end{itemize}

\noindent\hrulefill

\textbf{Note:} If you're migrating from a Liferay SAML adapter prior to
version 3.1.0, your portal properties are automatically migrated to
System Settings configurations. Please see the
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-saml}{Configuring
SAML} article for details on settings.

\noindent\hrulefill

\section{Important SAML Paths}\label{important-saml-paths}

For reference, here are a few important SAML paths.

This URL is the default location of the metadata XML file:

\begin{verbatim}
[host]:[port]/c/portal/saml/metadata
\end{verbatim}

Note that when configuring SAML, no importing of SAML certificates is
required. Liferay DXP reads certificates from the SAML metadata XML
file. If you want a third-party application like Salesforce to read a
Liferay SAML certificate, you can export the Liferay DXP certificate
from the keystore. The default keystore file is

\begin{verbatim}
[Liferay Home]/data/keystore.jks 
\end{verbatim}

You can change this path in System Settings → SSO → SAML Configuration →
Key Store Path.

\section{Single Sign On}\label{single-sign-on}

Both the IdP and the SP can initiate the Single Sign On process, and the
SSO flow is different depending on each one. Regardless of how it's
initiated, SSO is configured for HTTPS between the SP and IdP, so all
transport-level communication is encrypted. SAML requests are signed
using certificates configured in Liferay DXP, using the SAML Web Browser
SSO profile as defined in the
\href{http://saml.xml.org/saml-specifications}{SAML 2.0 specification}.
In all cases, responses are sent using HTTP-POST or HTTP-Redirect.
HTTP-POST is preferred because it reduces the risk that the URL is too
long for a browser to handle.

Consider IdP initiated SSO first.

\section{Identity Provider Initiated
SSO}\label{identity-provider-initiated-sso}

Sometimes a user enters the SSO cycle by sending a request directly from
the browser to the IdP.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/saml-idp-initiated-sso.png}}
\caption{Identity Provider Initiated SSO}
\end{figure}

\subsection{The SSO Request to the
IdP}\label{the-sso-request-to-the-idp}

If Liferay DXP is the IdP, the IdP initiated SSO URL

\begin{itemize}
\tightlist
\item
  Must specify the path as \texttt{/c/portal/saml/sso}.
\item
  Must include the \texttt{entityId} parameter which is the identifier
  to a previously configured Service Provider Connection (SPC).
\item
  May include a \texttt{RelayState} parameter which contains a URL
  encoded value where the user is redirected upon successful
  authentication. This URL should point to a location on the desired SPC
  (according to the
  \href{https://docs.oasis-open.org/security/saml/v2.0/saml-bindings-2.0-os.pdf}{SAML
  2.0 standards section 3.4.3}, this value \emph{must not} exceed 80
  bytes in length). It is useful to specify a landing page after SSO has
  been executed.
\end{itemize}

For non-Liferay DXP IdPs (Siteminder, ADFS, etc.), consult the vendor's
documentation on constructing IdP initiated SSO URLs.

If the IdP determines that the user isn't authenticated, it prompts the
user with the appropriate login screen.

\subsection{The SSO Response from the
IdP}\label{the-sso-response-from-the-idp}

Upon successful authentication, the IdP constructs a SAML Response. It
includes attribute statements configured in the designated Service
Provider Connection (SPC; see the
\href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-liferay-as-a-saml-identity-provider}{next
article} on setting up the SPC in Liferay DXP's SAML adapter).

The IdP sends the response to the Assertion Consumer Service URL. The
request contains two parameters: \texttt{SAMLResponse} and
\texttt{RelayState}.

\noindent\hrulefill

\textbf{Note:} The method for sending the SAML response (for example,
HTTP-POST) and the Assertion Consumer Service URL are usually imported
as part of the SAML metadata XML provided by the SP. In Liferay DXP, you
import the SP's metadata in the SAML Adapter's Service Provider
Connections tab.

\noindent\hrulefill

\subsection{The SP Processes the SSO
Response}\label{the-sp-processes-the-sso-response}

The SP validates and processes the SAML Response. Liferay DXP's SAML
solution requires signed \texttt{SAMLResponse} messages. This signature
process ensures proper identification for the IdP and prevents potential
SAML Response spoofing.

\begin{itemize}
\tightlist
\item
  If one Liferay DXP instance is the IdP and another is the SP, make
  sure the SAML metadata XML file imported into the SP contains the
  IdP's certificate.
\item
  If Liferay DXP is the IdP and another application is the SP, export
  the certificate from the IdP and import it into the SP's certificate
  store.
\end{itemize}

If a \texttt{RelayState} is included in the SAML Response, the user is
redirected to it. Otherwise the home page of the SP is served.

\section{Service Provider Initiated
SSO}\label{service-provider-initiated-sso}

Most of the time, authentication requests come from the Service
Provider.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/saml-sp-initiated-sso.png}}
\caption{Service Provider Initiated SSO}
\end{figure}

\subsection{The SSO Request to the SP}\label{the-sso-request-to-the-sp}

When the user's browser requests a protected resource or login URL on
the SP, it triggers the SP initiated SSO process. When Liferay DXP is
the SAML SP, SSO is initiated either by requesting
\texttt{/c/portal/login} URL or a protected resource that requires
authentication (for example, a document not viewable by the Guest Role).
If the user requests a protected resource, its URL is recorded in the
\texttt{RelayState} parameter. If the user requested
\texttt{/c/portal/login}, the \texttt{RelayState} can be set by
providing the \texttt{redirect} parameter. Otherwise, if the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html}{portal
property} \texttt{auth.forward.by.last.path} is set to \texttt{true},
the last accessed path is set as the \texttt{RelayState}. For
non-Liferay DXP SPs, consult the vendor documentation on initiating SSO.

\subsection{The AuthnRequest to the
IdP}\label{the-authnrequest-to-the-idp}

The SP looks up the IdP's Single Sign On service URL and sends an
\texttt{AuthnRequest}. When Liferay DXP is the SP it looks up the
configured SAML Identity Provider Connection and sends a SAML
\texttt{AuthnRequest} to the IdP's Single Sign On service URL as defined
in the SAML metadata XML document. Liferay DXP supports sending and
receiving the \texttt{AuthnRequest} using HTTP-POST or HTTP-Redirect
binding. HTTP-POST is preferred.

If the user doesn't have an active session or if \texttt{ForceAuthn} was
requested by the SP, the user must authenticate by providing
credentials. When Liferay DXP is the IdP, authentication occurs in the
Login Portlet. Liferay DXP decodes and verifies the
\texttt{AuthnRequest} before requesting the user to authenticate.

\subsection{The SSO Response from the
IdP}\label{the-sso-response-from-the-idp-1}

After authentication, a SAML Response is constructed, sent to the
Assertion Consumer Service URL of the SP, and verified. The IdP
automatically makes this choice based on the SP metadata.

When Liferay DXP is configured as the IdP, any attributes configured on
the Service Provider Connection are included in the response as
attribute statements. The Assertion Consumer Service URL is looked up
from the SAML metadata XML of the SP.

When Liferay DXP is configured as the SP, response and assertion
signatures are verified. Liferay DXP requires the sender to be
authenticated. This is done via whole message signature from the issuing
IdP. Responses missing the signature are considered unauthenticated and
the response is rejected. For non-Liferay DXP SP or IdP vendors, consult
their documentation.

The user is redirected to the requested resource or to the URL contained
in the \texttt{RelayState} parameter (for example, the last page the
user accessed before initiating SSO).

\section{Single Log Off}\label{single-log-off}

The Single Log Off request is sent from the user's browser to the IdP or
an SP, and the SLO flow differs in each case. First consider IdP
initiated SLO.

\section{Identity Provider Initiated
SLO}\label{identity-provider-initiated-slo}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/saml-idp-initiated-slo.png}}
\caption{Identity Provider Initiated SLO}
\end{figure}

\subsection{The SLO Request to the
IdP}\label{the-slo-request-to-the-idp}

An IdP initiated SLO request is sent directly to the IdP by the user's
browser. When Liferay DXP is the IdP, the IdP initiated SSO URL must
specify the URL path as

\texttt{/c/portal/logout}

If the user is signed on to any configured SP, the SAML plugin takes
over the logout process, displaying all the signed on services. The
single logout screen displays the authentication status of each SP and
whether any SPs can't be logged out of (for example, if the SP is down
or doesn't support SLO). For non-Liferay DXP IdPs (Siteminder, ADFS,
etc.) consult the vendor's documentation on constructing IdP initiated
SLO URLs.

The IdP sends a SAML \texttt{LogoutRequest} to the SP.

\begin{itemize}
\tightlist
\item
  When Liferay DXP is configured as the IdP, the \texttt{LogoutRequest}
  is sent using either HTTP-POST, HTTP-Redirect, or SOAP binding.
  HTTP-Post binding is preferred but in its absence, the first available
  SLO endpoint with supported binding is selected.
\item
  When Liferay DXP is configured as the SP, supported bindings for
  \texttt{LogoutRequest} are HTTP-Post, HTTP-Redirect, or SOAP.
\item
  For other IdPs or SPs, please consult the vendor's documentation.
\end{itemize}

\subsection{The SLO Response from the
SP}\label{the-slo-response-from-the-sp}

The SP delivers a \texttt{LogoutResponse} to the IdP.

The IdP sends a SAML \texttt{LogoutRequest} to the second SP.

The second SP then delivers the \texttt{LogoutResponse} to the IdP. The
process is repeated for all SPs the user is logged into. When Liferay
DXP is the IdP, Liferay DXP logs the user out after the last SP has
delivered its \texttt{LogoutResponse} or has timed out.

\section{Service Provider Initiated
SLO}\label{service-provider-initiated-slo}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/saml-sp-initiated-slo.png}}
\caption{Service Provider Initiated SLO}
\end{figure}

\subsection{The SLO Request to the SP}\label{the-slo-request-to-the-sp}

In SP initiated SLO, the user's browser sends a logout request directly
to the SP. When Liferay DXP is configured as the SP, the SLO is
initiated by requesting this logout URL:

\begin{verbatim}
/c/portal/logout
\end{verbatim}

For other SPs, consult the vendor's documentation on initiating SLO.

A SAML \texttt{LogoutRequest} is sent to the Single Log Out service URL
of the IdP.

\begin{itemize}
\item
  If Liferay DXP serves as the SP, the \texttt{LogoutRequest} is sent to
  the IdP configured by the IdP Connections tab of the SAML provider
  (see the
  \href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-liferay-as-a-saml-identity-provider}{next
  article} to set up the IdP Connection) and the SLO service URL defined
  in the SAML metadata.
\item
  When Liferay DXP is the IdP, if the user has logged on to other SPs,
  the user is presented with a single logout screen with the status of
  each SP logout, flagging any that can't be looged out of (some SPs
  might not support SLO or are currently down). If there are no other
  SPs to log out of, the SAML session terminates and the IdP destroys
  its session.
\end{itemize}

\subsection{The SLO Response from the
SP}\label{the-slo-response-from-the-sp-1}

If the user is logged in to additional SPs (beyond just the initiating
SP), the IdP sends the SAML \texttt{LogoutRequest} to each one. When
Liferay DXP is the IdP, the \texttt{LogoutResponse} is sent using either
HTTP-Post, HTTP-Redirect, or SOAP binding.

Each SP delivers its \texttt{LogoutResponse} to the IdP. When Liferay
DXP is the SP, the \texttt{LogoutResponse} is sent using either
HTTP-Post, HTTP-Redirect or direct response to SOAP request.

After all additional SPs deliver their \texttt{LogoutResponse}s to the
IdP, the IdP destroys its SSO session. When Liferay DXP is the IdP, once
the last SP has delivered its \texttt{LogoutResponse} or has timed out,
the IdP destroys the Liferay DXP session, logging out the user.

Finally, the IdP sends a \texttt{LogoutResponse} to the SP that
initiated SLO. The initiating SP terminates its SAML session and logs
the user out.

\section{Related Topics}\label{related-topics-6}

\begin{itemize}
\tightlist
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-liferay-as-a-saml-identity-provider}{Setting
  Up SAML as an Identity Provider}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/setting-up-liferay-as-a-saml-service-provider}{Setting
  Up SAML as a Service Provider}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/token-based-single-sign-on-authentication}{Token-Based
  SSO Authentication}
\end{itemize}

\chapter{Setting up Liferay DXP as a SAML Identity
Provider}\label{setting-up-liferay-dxp-as-a-saml-identity-provider}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

An identity provider is a trusted provider that provides single sign-on
for users to access other websites. A service provider is a website that
hosts applications and grants access only to identified users with
proper credentials. Liferay Portal 6.1 EE and later versions support
SAML 2.0 integration via the
\href{https://web.liferay.com/marketplace/-/mp/application/15188711}{Liferay
Connector to SAML 2.0} application. It is provided from Liferay
Marketplace and allows Liferay DXP to act as a SAML 2.0 identity
provider or as a service provider.

\noindent\hrulefill

\textbf{Important:} You can set Liferay DXP up as an Identity Provider
or as a Service Provider. Each single Liferay DXP instance can serve as
an identity provider or as a service provider, but \textbf{not both}.
Both configurations are covered in this article.

\noindent\hrulefill

\section{Storing Your Keystore}\label{storing-your-keystore}

Your first step is to determine where to store your keystore. You have
two options:

\begin{itemize}
\tightlist
\item
  In the file system
\item
  In the Documents and Media library
\end{itemize}

The file system keystore manager is used by default and the default
location is the \texttt{{[}Liferay\ Home{]}/data} directory (you can
change the location in System Settings → SSO → SAML Configuration → Key
Store Path). To use Documents and Media library storage for your
keystore instead of file system storage, go to \emph{Control Panel} →
\emph{System Settings} → \emph{Security} → \emph{SSO} → \emph{SAML
KeyStoreManager Implementation Configuration}. Select from the two
options: \emph{Filesystem Keystore Manager} or \emph{Document Library
Keystore Manager}.

If you use Document Library storage, you can use any number of
\href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{back-end
file stores}. These are protected not only by the system where the key
is stored, but also by Liferay DXP's permissions system.

\section{Configuring Liferay DXP as a SAML Identity
Provider}\label{configuring-liferay-dxp-as-a-saml-identity-provider}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To access the SAML Admin interface, click on \emph{Control Panel} →
  \emph{Configuration} and then on \emph{SAML Admin}.
\item
  To begin configuring Liferay DXP to use SAML, select a SAML role for
  @product@ and choose an entity ID.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/saml-initial-config.png}}
  \caption{Select a SAML role for Liferay and enter an entity ID.}
  \end{figure}

  Select the \emph{Identity Provider} SAML role. Enter your own entity
  ID. Then click \emph{Save}. A new Certificate and Private Key section
  appears.
\item
  The Certificate and Private Key section lets you create a keystore for
  SAML. Click on \emph{Create Certificate} and enter the following
  information:

  \begin{itemize}
  \tightlist
  \item
    Your common name (your first and last name)
  \item
    The name of your organization
  \item
    The name of your organizational unit
  \item
    The name of your city or locality
  \item
    The name of your state or province
  \item
    The name of your country
  \item
    The length in days that your keystore will remain valid (how long
    before the keystore expires)
  \item
    The key algorithm (RSA is the default)
  \item
    The key length in bits (2048 is the default)
  \item
    The key password
  \end{itemize}

  Click \emph{Save}.

  When you create the certificate and private key, you also create a
  keystore if one doesn't already exist. As described above, this
  keystore has two storage options: file system storage (the default)
  and Documents and Media storage. By default, the certificate uses the
  \texttt{SHA256} algorithm for encryption and is fingerprinted and
  self-signed via RSA and \texttt{SHA256}.
\item
  After you click \emph{Save}, you can click \emph{Replace Certificate}
  at any time to replace the current certificate with a new one if your
  old one has expired or if you want to change the key's password.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/saml-keystore-info.png}}
  \caption{The General tab of the SAML Admin portlet displays
  information about the current certificate and private key and allows
  administrators to download the certificate or replace the
  certificate.}
  \end{figure}

  Three more tabs now appear:

  \textbf{General:} For enabling or disabling a SAML IdP and managing
  the required keystore.

  \textbf{Identity Provider:} Contains IdP options, such as whether to
  enable SSL. If SSL has been enabled, then SAML requests are not
  approved unless they are also encrypted.

  \textbf{Service Provider Connections:} This tab manages any Service
  Providers connected to this Liferay DXP instance.

  See below for more information on the Identity Provider and Service
  Provider Connections tabs.
\item
  After you save your certificate and private key information, check the
  \emph{Enabled} box at the top of the General tab and click
  \emph{Save}. You successfully set Liferay DXP up as a SAML Identity
  Provider!
\end{enumerate}

\section{Changing the Identity Provider
Settings}\label{changing-the-identity-provider-settings}

To configure Liferay DXP's SAML Identity Provider Settings, navigate to
the \emph{Identity Provider} tab of the SAML Admin Control Panel entry.

The \emph{Identity Provider} tab includes these options:

\textbf{Sign Metadata?:} Check this box to ensure the metadata XML file
that's produced is signed.

\textbf{SSL Required:} Check this box to reject any SAML messages that
are \emph{not} sent over SSL. This affects URLs in the generated
metadata.

\textbf{Require Authn Request Signature?:} When this box is checked,
each Authn Request must be signed by the sending Service Provider. In
most cases, this should be enabled.

\textbf{Session Maximum Age:} Specify the maximum duration of the SAML
SSO session in seconds. If this property is not set or is set to
\texttt{0}, the SSO session has an unlimited duration. The SSO session
maximum duration can be longer than the portal session maximum duration.
If the portal session expires before the SSO session expires, the user
is logged back in to Liferay DXP automatically. SSO session expiration
does not trigger a single logout from all service providers. You can use
the session maximum age, for example, to force users to sign in again
after a certain period of time.

\textbf{Session Timeout:} Specify the maximum idle time of the SAML SSO
session. Even if the session maximum age is unlimited, the SSO session
expires whenever the user's idle time reaches the limit set by the
session timeout property.

\section{Checkpoint}\label{checkpoint-2}

Before adding a Service Provider (SP), verify you've completed these
tasks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A SAML keystore has been generated. It can be stored in one of two
  locations: the \texttt{data} folder or in the Documents and Media
  library.
\item
  On the \emph{Identity Provider} tab, the following settings have been
  set:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    \textbf{Sign Metadata} has been checked.
  \item
    \textbf{SSL Required} - checked if SSL is active elsewhere. SSL is
    disabled by default.
  \item
    \textbf{Authn Request Signature Required:} has been checked.
  \item
    \textbf{Session Maximum Age:} has been set. If set to \texttt{0},
    then the SSO has an unlimited duration.
  \item
    \textbf{Session Timeout:} Specify the maximum idle time of the SAML
    SSO session.
  \end{enumerate}
\item
  Once the \emph{Enabled} checkbox has been checked, the IdP is live,
  and you can generate the required metadata. This URL is the default
  location of Liferay DXP's metadata XML file:

\begin{verbatim}
 [host]:[port]/c/portal/saml/metadata 
\end{verbatim}
\end{enumerate}

If this URL does not display correctly, then the SAML instance has not
been enabled. Use the URL or click \emph{Save} in the browser to
generate an actual \texttt{XML} file.

Your Identity Provider is now set up. Next, you must register a Service
Provider.

\chapter{Registering a SAML Service
Provider}\label{registering-a-saml-service-provider}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Setting up Liferay DXP as a SAML Identity Provider is only useful if you
can connect to one or more SAML Service Providers. Navigate to the
Service Provider Connections tab of the SAML Admin Control Panel entry
and click the \emph{Add Service Provider} button to add a SAML Service
Provider.

The New Service Provider page includes these options:

\textbf{Name:} The name of the Service Provider with which to connect.
The name can be anything; it's purely cosmetic.

\textbf{Entity ID:} The Service Provider's entity ID. This value must
match the entity ID declared in the Service Provider metadata.

\textbf{Enabled:} Check this box to activate the Service Provider
connection.

\textbf{Assertion Lifetime:} Defines the number of seconds after which
the SAML assertion issued by the Identity Provider should be considered
expired.

\textbf{Force Encryption:} If the SP does not provide a public key for
encrypting the assertions, abort the single sign-on.

\textbf{Metadata:} Provide a URL to the Service Provider metadata XML
file or manually upload the Service Provider metadata XML file. If you
provide a URL, the XML file is retrieved and periodically polled for
updates. The update interval can be configured in System Settings with
the Runtime Metadata Refresh Interval
(\texttt{saml.metadata.refresh.interval} if using a \texttt{config}
file) property which specifies a number of seconds. If fetching the
metadata XML file by URL fails, you can't enable the Service Provider
connection. If the Identity Provider server cannot access the metadata
via URL, you can upload the XML file manually. In this case, the
metadata XML file is not updated automatically.

\textbf{Name Identifier Format:} Choose the Name Identifier Format used
in the SAML Response. This should be set according to what the Service
Provider expects to receive. For Liferay Service Providers, any
selection other than email address indicates that the Name Identifier
refers to screen name. The formats don't have any special meaning to
Liferay Identity Providers. The \texttt{NameID} value is defined by the
Name Identifier attribute. See the next option.

\textbf{Name Identifier Attribute Name:} This specifies which attribute
of the Liferay DXP \texttt{User} object to use as the \texttt{NameID}
value. Possible values include \texttt{emailAddress},
\texttt{screenName} and \texttt{uuid}. Additionally, you can prefix the
name with \texttt{static:} or \texttt{expando:}. If you use the prefix
\texttt{static}, the value is whatever comes after \texttt{static:}. If
you use the prefix \texttt{expando}, the value is whatever custom field
is specified after \texttt{expando:}. For example, \texttt{expando:SSN}
would look up the \texttt{User} custom field with the name \texttt{SSN}.

\textbf{Attributes Enabled:} Include and resolve assertion attributes.

\textbf{Attributes Namespace Enabled:} When this box is checked, the
attribute names are namespaced like this:

\begin{verbatim}
urn:liferay:user:expando:
urn:liferay:user:
urn:liferay:groups:
urn:liferay:organizationRole:
urn:liferay:organization:
urn:liferay:roles:
urn:liferay:siteRole:
urn:liferay:userGroupRole:
urn:liferay:userGroups:
\end{verbatim}

\textbf{Attributes:} Enter a list of attributes to include in the
assertion, one per line. Each line is an expression that gets parsed.
Examples:

\begin{verbatim}
organizations
organizationRoles
roles
siteRoles
userGroups
static:[attributeName]=[attributeValue]
expando:[userCustomFieldName] 
\end{verbatim}

Note that the full namespace depends on the attribute name. Attribute
namespaces can be useful. Use them when attribute names from different
namespaces might conflict. For example, \texttt{expando:user} vs
\texttt{urn:liferay:roles:user}.

\textbf{Keep Alive URL:} If users are logged into several Liferay DXP SP
instances via a Liferay DXP IdP, their sessions can be kept alive as
long as they keep a browser window open to one of them. Configure this
only if the SP is Liferay DXP. The URL is
\texttt{https://{[}SP\ host\ name{]}/c/portal/saml/keep\_alive}.

\section{Checkpoint}\label{checkpoint-3}

Verify your settings are correct by connecting the Liferay DXP-based IdP
to its first SP. SPs connect to only one IdP, so if the first one
doesn't work, the rest won't either.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Provide a general name for the SP.
\item
  The \texttt{Entity\ ID} name must be identical to the one declared in
  the Service Provider metadata.
\item
  Check the \emph{Enabled} checkbox.
\item
  Set a value for the \emph{Assertion Lifetime}.
\item
  Choose whether encryption should be required (recommended).
\item
  Make sure the SP's metadata has been provided either as a URL or an
  XML file has been uploaded.
\item
  Make sure \emph{Name Identifier Format} and \emph{Name Identifier
  Attribute Name} have been set.
\item
  Make sure \emph{Attributes Namespace Enabled} has been set.
\end{enumerate}

If you don't have a Service Provider to add right now, that's fine. In
the next section, you'll learn how to set Liferay DXP up as a SAML
Service Provider. The same instance can't be both, but after you set up
another Liferay DXP instance as a Service Provider, come back to this
one and add the Service Provider according to the instructions above.

\chapter{Setting up Liferay DXP as a SAML Service
Provider}\label{setting-up-liferay-dxp-as-a-saml-service-provider}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Many of these steps are similar to configuring Liferay DXP as a SAML
Identity Provider. As a reminder, a single Liferay DXP installation can
be configured as a SAML Identify Provider \emph{or} as a SAML Service
Provider but not as both. If your Liferay DXP installation is already a
SAML Identity Provider, use a \emph{different} Liferay DXP installation
as a SAML Service Provider.

\noindent\hrulefill

\textbf{Note:} If you have a third party IdP with Liferay DXP as the SP,
all messages coming from the IdP must be signed. If they're not, an
error message appears and communication between the IdP and Liferay DXP
fails.

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Install the Liferay Connector to SAML 2.0 app. To confirm successful
  deployment, look for the \emph{SAML Admin} entry in the Configuration
  section of the Control Panel.
\item
  To begin configuring Liferay DXP to use SAML, you must select a SAML
  role for Liferay DXP and choose an entity ID. Select the \emph{Service
  Provider} SAML role. Choose your own entity ID. Then click \emph{Save}
  and a new section entitled Certificate and Private Key appears.
\item
  The Certificate and Private Key section is for creating a keystore for
  SAML. Click \emph{Create Certificate} and enter the following
  information:

  \begin{itemize}
  \tightlist
  \item
    Your common name (your first and last name)
  \item
    The name of your organization
  \item
    The name of your organizational unit
  \item
    The name of your city or locality
  \item
    The name of your state or province
  \item
    The name of your country
  \item
    The length in days that your keystore will remain valid (how long
    before the keystore expires)
  \item
    The key algorithm (RSA is the default)
  \item
    The key length in bits (2048 is the default)
  \item
    The key password
  \end{itemize}

  Remember that the keystore has two storage options: file system
  storage (the default) and Documents and Media storage.By default, the
  certificate uses the SHA256 algorithm for encryption and is
  fingerprinted and self-signed via MD5 and SHA1. When you enter all the
  required information, click \emph{Save}.
\item
  After you clicked \emph{Save}, check that you can view information
  about your certificate or download your certificate. If you can, you
  successfully created a keystore. After you create a keystore,
  additional options appear. There are three tabs:

  \textbf{General}: Enables or disables SAML SP and manages the required
  keystore.

  \textbf{Service Provider}: This tab manages basic and advanced
  configurations for the SP.

  \textbf{Identity Provider Connection}: This tab manages connections to
  the IdP. There can be multiple IdP connections.
\item
  You can also generate an encryption certificate. This is a separate
  key for encrypting assertions. If you want assertions encrypted, you
  must generate a key for this. The procedure is exactly the same as
  generating your certificate in step 3 above.
\item
  Next, you must configure an Identity Provider connection. Click on the
  \emph{Identity Provider Connections} tab. Enter a name for the
  Identity Provider, enter its entity ID, and enter its metadata URL. If
  you have already followed the previous instructions and configured a
  separate Liferay DXP installation as an Identify provider, you'd enter
  the following information:

  \begin{itemize}
  \tightlist
  \item
    Name: \emph{Liferay IdP}
  \item
    Entity ID: {[}ID of IdP{]}
  \item
    Clock Skew: Set the tolerance in milliseconds between SP and IdP.
  \item
    Force Authn: Whether the IdP should force reauthentication
    regardless of context.
  \item
    Metadata URL: http://localhost:8080/c/portal/saml/metadata (test
    this URL first)
  \item
    Name Identifier Format: See settings.
  \item
    Attribute Mapping: See settings.
  \item
    Keep Alive URL: See settings.
  \end{itemize}

  \textbf{Important}: The Liferay Connector to SAML 2.0 app supports
  using \emph{either} a URL to a SAML IdP metadata file \emph{or} an
  actual (uploaded) SAML metadata XML file. The value entered in the
  \emph{Metadata URL} field is persisted to the database only when there
  a metadata URL and there is no specified metadata XML file. Otherwise,
  Liferay DXP keeps the original metadata URL in the database. This
  behavior ensures that once a metadata URL has been specified, there is
  always a metadata URL saved in the database. This way, if a portal
  administrator forgets the previously entered metadata URL or its
  format, he or she can look at the displayed metadata URL and choose to
  modify the displayed metadata URL or overwrite the previously saved
  metadata URL by specifying a metadata XML file.
\item
  Finally, after you save your certificate and private key information
  and configure an Identity Provider connection, check the
  \emph{Enabled} box at the top of the General tab and click
  \emph{Save}. Liferay DXP is now a SAML Service Provider!
\end{enumerate}

Note that the SAML Service Provider session is tied to the normal
session on the application server. Session expiration on the application
server terminates the session on the Service Provider but does not
initiate single logout.

You can add multiple IdP connections. To add another Identity Provider,
click \emph{Add Identity Provider} again and enter the details for the
other provider. When users log in, they are asked to choose an identity
provider, so be sure to name the providers so users can recognize them.

\section{Checkpoint}\label{checkpoint-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A SAML keystore has been generated.
\item
  Verify the connection to the IdP.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    \emph{Name}: generic name for the IdP.
  \item
    \emph{Entity ID}: the same name of the IdP. If the IdP is another
    Liferay DXP instance, then it is the same name as the above example.
  \item
    \emph{Metadata URL}: The IdP's metadata as a URL or as an XML file.
  \item
    If the IdP is another @product instance, ensure its corresponding
    Service Provider Connection for this SP is enabled.
  \end{enumerate}
\item
  On the \emph{General} tab, the \emph{Enabled} checkbox has been
  checked.
\item
  Once \emph{Enabled} checkbox has been checked, the service provider's
  metadata becomes available:

\begin{verbatim}
 [host]:[port]/c/portal/saml/metadata
\end{verbatim}
\end{enumerate}

\section{Setting Up Liferay DXP as a SAML Service Provider in a
Clustered
Environment}\label{setting-up-liferay-dxp-as-a-saml-service-provider-in-a-clustered-environment}

You can use the Liferay Connector to SAML 2.0 app as an SSO solution for
a clustered Liferay DXP environment. If your multi-node cluster is
behind a load balancer, you must enable all the nodes as SPs, and they
must share the same keystore manager.

If using the Filesystem Keystore Manager (the default):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Configure each node of your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{Liferay
  DXP cluster} as a SAML service provider as above.
\item
  Copy the keystore file
  (\texttt{{[}Liferay\ Home{]}/data/keystore.jks}, by default) from the
  first node to the remaining nodes. This file is the Java keystore
  that's created by the SAML Provider app. The keystore contains the
  valid or self-signed certificate managed by the SAML connector app.
\item
  Verify that the service provider metadata has been generated to be
  used either as a URL or an XML file. The metadata is the same for all
  nodes because of the same database back-end. The IdP's request goes
  through the load balancer.
\item
  At this point, all nodes have the same SAML SP configuration and each
  of them can respond to web requests and handle the SAML protocol. To
  test your SSO solution, sign into Liferay DXP via your load balancer,
  navigate to a few pages of a few different sites, and then log out.
\end{enumerate}

If using the Document Library Keystore Manager, skip step 2 because the
keystore file is stored in the database shared by all the nodes.

Now you know how to configure Liferay DXP either as a SAML identity
provider or a service provider. You also know how to configure SAML in a
clustered environment.

\chapter{Changing the Settings for Service Provider and Identity
Provider
Connections}\label{changing-the-settings-for-service-provider-and-identity-provider-connections}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

To change the SAML Service Provider Settings, navigate to the Service
Provider tab.

The Service Provider tab includes these options:

\textbf{Require Assertion Signature?:} Check this box to require SAML
assertions to be individually signed in addition to the entire SAML
message.

\noindent\hrulefill

\textbf{Note:} Individual assertions need not be signed as long as the
SAML response itself is signed. The SP and IdP should always communicate
over \texttt{https} to have encryption at the transport level.

If you believe man-in-the-middle attacks are possible, the SAML response
can be signed. The only reason to sign the assertions is if the SAML
response is not signed. In this case, assertions should not only be
signed but also encrypted.

\noindent\hrulefill

\textbf{Clock Skew:} Clock skew is a tolerance in milliseconds used by
the Service Provider for mitigating time differences between the clocks
of the Identity Provider and the Service Provider. This usually only
matters when assertions have been made to expire very quickly.

\textbf{LDAP Import Enabled:} Check this box to import user information
from the configured LDAP connection based on the resolved
\texttt{NameID}. LDAP connections can be configured from Instance
Settings.

\textbf{Sign Authn Requests:} Check this box to sign the
\texttt{AuthnRequest} even if the Identity Provider metadata indicates
that it's not required.

\textbf{Sign Metadata:} Check this box to sign the metadata XML file.

\textbf{SSL Required:} Check this box to reject SAML messages that are
not sent over HTTPS. This does not affect how URLs are generated.

\section{Changing the SAML Identity Provider Connection
Settings}\label{changing-the-saml-identity-provider-connection-settings}

To configure Liferay DXP's SAML Identity Provider Settings, navigate to
the Identity Provider Connection tab of the SAML Admin portlet and click
the \emph{Edit} action button on the IdP you want to configure.

\textbf{Name:} The name of the Identity Provider with which to connect.

\textbf{Entity ID:} The Identity Provider's entity ID. This value must
match the entity ID declared in the Identity Provider metadata.

\textbf{Enabled:} Check the box to enable this IdP.

\textbf{Clock Skew:} Clock skew is a tolerance in milliseconds used by
the Service Provider for mitigating time differences between the clocks
of the Identity Provider and the Service Provider. This usually only
matters when assertions have been made to expire very quickly.

\textbf{Force Authn:} Check this box to have the Service Provider ask
the Identity Provider to re-authenticate the user before verifying the
user.

\textbf{Metadata:} You can provide a URL to the Identity Provider
metadata XML file or you can manually upload it. If you provide a URL,
the XML file is automatically retrieved and periodically polled for
updates. You can change the update interval in System Settings by
modifying the Runtime Metadata Refresh Interval property which specifies
a number of seconds. If fetching the metadata XML file by URL fails, you
can't enable the Identity Provider connection. If the metadata is
inaccessible via URL, you can upload the XML file manually. In this
case, the metadata XML file is not updated automatically.

\textbf{Name Identifier Format:} Choose the Name Identifier Format used
in the SAML Response. Set this according to what the Service Provider
expects to receive. For Liferay Service Providers, selections other than
email address indicate that the Name Identifier refers to screen name.
The formats don't have any special meaning to Liferay Identity
Providers. The Name Identifier attribute defines the \texttt{NameID}
value.

\textbf{Attribute Mapping:} Attribute mapping is done from the attribute
name or friendly name in the SAML Response to the Liferay DXP attribute
name. For example, if you want to map a response attribute named
\texttt{mail} to the Liferay DXP attribute \texttt{emailAddress}, enter
the following mapping:

\begin{verbatim}
mail=emailAddress
\end{verbatim}

Available Liferay DXP attributes are: \texttt{emailAddress},
\texttt{screenName}, \texttt{firstName}, \texttt{lastName},
\texttt{modifiedDate}, and \texttt{uuid}.

\textbf{Keep Alive URL:} If users are logged into several Liferay DXP SP
instances via a Liferay DXP IdP, their sessions can be kept alive as
long as they keep a browser window open to one of them. Configure this
only if the IdP is Liferay DXP. The URL is
\texttt{https://{[}IdP\ host\ name{]}/c/portal/saml/keep\_alive}. On the
Liferay DXP IdP, configure this URL the same way, but point back to this
SP.

Save your changes when you are finished configuring the Liferay DXP
instance as a service provider. There is no need to restart the server:
the changes are applied immediately.

Make the above configurations through the SAML Control Panel interface
and not via properties. Some features of the Liferay Connector to SAML
2.0 app are not available as properties.

\noindent\hrulefill

\textbf{Limitation:} The Liferay SAML app can only be used with a single
virtual host. Technically, this means that in the SAML metadata for
Liferay DXP, only one binding can be added in this form:

\begin{verbatim}
<md:EntityDescriptor>
...
<md:SPSSODescriptor>
...
<md:AssertionConsumerService Binding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" Location="https://portal.domain.com/c/portal/saml/acs" index="1" isDefault="true" />
...
</md:SPSSODescriptor>
</md:EntityDescriptor>

\noindent\hrulefill



# Configuring SAML


<aside class="alert alert-info">
  <span class="wysiwyg-color-blue120">This document has been updated and ported to <a href="https://learn.liferay.com/dxp/latest/en/installation-and-upgrades/securing-liferay/configuring-sso/authenticating-with-saml.html">Liferay Learn</a> and is no longer maintained here.</span>
</aside>

There are some ways of configuring the SAML plugin outside the UI. This is done
via OSGi configuration files and by uploading metadata XML to configure how
connections are negotiated. 

## OSGi Configuration Properties

As noted in the previous tutorials, anything related to configuring SP
connections must be done through the SAML Admin UI where configurations are
saved to Liferay's database. SP connections can no longer be made via properties
files as they were in versions prior to 3.1.0. 


\noindent\hrulefill

**Note:** Don't use OSGi `.config` files or Liferay DXP's System Settings Control
Panel application to configure SAML providers (IdP or SP). The System Settings
UI is auto-generated, and is for advanced administrators. It does not perform the
enhanced validation on the fields that the SAML Admin UI performs, so it could
allow administrators to create invalid configurations.

\noindent\hrulefill

This is a portal instance scoped configuration which can be managed via OSGi
Configuration Admin. The affected properties are those in the
`SAMLProviderConfiguration` metatype:

   - `keyStoreCredentialPassword()`
   - `keyStoreEncryptionCredentialPassword()`
   - `assertionSignatureRequired()`
   - `authnRequestSignatureRequired()`
   - `clockSkew()`
   - `defaultAssertionLifetime()`
   - `entityId()`
   - `enabled()`
   - `ldapImportEnabled`
   - `role()`
   - `sessionMaximumAge`
   - `sessionTimeout()`
   - `signAuthnRequest()`
   - `signMetadata()`
   - `sslRequired()`
   - `allowShowingTheLoginPortlet()`

The SAML Admin UI remains the place for creating the portal instance scoped
configuration instances.

Note that there is also a system wide configuration, represented by the
`SamlConfiguration` metatype. 

If you used Liferay 6.2, please note that the following system wide properties
were removed:

   `saml.metadata.paths` (served no purpose after removal of SP connection defaults)
   `saml.runtime.metadata.max.refresh.delay`
   `saml.runtime.metadata.min.refresh.delay`

The latter two properties were replaced with the single property
`com.liferay.saml.runtime.configuration.SamlConfiguration.getMetadataRefreshInterval()`.

Note also the introduction of the *SAML KeyStoreManager Implementation
Configuration* in *Control Panel* &rarr; *System Settings* &rarr; Security
&rarr; SSO. The options for this configuration are explained above in the
Setting up Liferay DXP as a SAML Identity Provider section.

In the latest version of the plugin, the `SHA256` algorithm is the default
encryption algorithm used in the configuration and to generate keys. The default
configuration tries `SHA256`, then `SHA384`, then `SHA512` before falling back to
`SHA1`. Because `SHA1` is potentially vulnerable, you can blacklist it using this
property: 

```properties
blacklisted.algorithms=["blacklisted_algorithm_url", "another_blacklisted_algorithm_url"]
\end{verbatim}

To blacklist \texttt{SHA1}, therefore, you'd have this configuration:

\begin{verbatim}
blacklisted.algorithms=["http://www.w3.org/2000/09/xmldsig#sha1"]
\end{verbatim}

Place these in a config file with this name:

\begin{verbatim}
com.liferay.saml.opensaml.integration.internal.bootstrap.SecurityConfigurationBootstrap.config
\end{verbatim}

There's a lot more granularity in how connections are negotiated if you
configure the metadata XML.

\section{Configuring Negotiation Via
metadata.xml}\label{configuring-negotiation-via-metadata.xml}

If the default negotiation configuration doesn't work for you, you can
craft your own configuration and upload it. Before doing this, visit
your host's metadata URL and save a copy of the configuration in case
you need it later:

\begin{verbatim}
http://[hostname]/c/portal/saml/metadata
\end{verbatim}

For example, if you're stuck connecting to a legacy IdP that only
supports \texttt{SHA1}, you can upload a configuration that disables the
other algorithms:

\begin{verbatim}
<?xml version="1.0" encoding="UTF-8"?>
<md:EntityDescriptor xmlns:md="urn:oasis:names:tc:SAML:2.0:metadata" entityID="samlidp">
  <md:IDPSSODescriptor WantAuthnRequestsSigned="true" protocolSupportEnumeration="urn:oasis:names:tc:SAML:2.0:protocol">
    <md:Extensions>
      <alg:SigningMethod xmlns:alg="urn:oasis:names:tc:SAML:metadata:algsupport" Algorithm="http://www.w3.org/2000/09/xmldsig#rsa-sha1"/>
    </md:Extensions>
    <md:KeyDescriptor use="signing">
      <ds:KeyInfo xmlns:ds="http://www.w3.org/2000/09/xmldsig#">
        <ds:X509Data>
          <ds:X509Certificate>... omitted ...</ds:X509Certificate>
        </ds:X509Data>
      </ds:KeyInfo>
    </md:KeyDescriptor>
    <md:SingleLogoutService Binding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" Location="http://localhost:8080/c/portal/saml/slo"/>
    <md:SingleLogoutService Binding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect" Location="http://localhost:8080/c/portal/saml/slo"/>
    <md:SingleSignOnService Binding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect" Location="http://localhost:8080/c/portal/saml/sso"/>
    <md:SingleSignOnService Binding="urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST" Location="http://localhost:8080/c/portal/saml/sso"/>
  </md:IDPSSODescriptor>
</md:EntityDescriptor>
\end{verbatim}

Notice that in the configuration above, the
\texttt{\textless{}md:Extensions\textgreater{}} block has only one
signing algorithm: \texttt{SHA1}.

\noindent\hrulefill

\textbf{Note:} Since the default configuration falls back to
\texttt{SHA1}, you shouldn't need to do this unless your legacy system
can't negotiate via the fallback mechanism. Also note that if you
blacklisted \texttt{SHA1}, this won't work. Due to
\href{https://en.wikipedia.org/wiki/SHA-1}{vulnerabilities in
\texttt{SHA1}}, it's best to avoid using it altogether if possible.

\noindent\hrulefill

If you've changed your metadata configuration, you can go back to the
default configuration if you saved it before making the change. If you
didn't, you can provide a URL instead of an uploaded XML file to one of
your peers' metadata configurations.

\chapter{NTLM Single Sign On
Authentication}\label{ntlm-single-sign-on-authentication}

NTLM (NT LAN Manager) is a suite of Microsoft protocols that provide
authentication, integrity, and confidentiality for users. Though
Microsoft has adopted Kerberos in modern versions of Windows server,
NTLM is still used when authenticating to a workgroup. Liferay DXP now
supports NTLM v2 authentication. NTLM v2 is more secure and has a
stronger authentication process than NTLMv1.

\noindent\hrulefill

\textbf{Note:} NTLM authentication was deprecated in 7.0 and was
removed. You can still install it from Marketplace
\href{https://web.liferay.com/marketplace/-/mp/application/125668266}{here}
or
\href{https://web.liferay.com/marketplace/-/mp/application/125668305}{here}.

\noindent\hrulefill

Note that in order to use NTLM SSO, Liferay DXP's portal instance
authentication type must be set to screen name.

\noindent\hrulefill

\textbf{Note:} To USE NTLM with Liferay DXP, you must configure your
browser. Consult your browser vendor's documentation for the details.

\noindent\hrulefill

Most importantly, all users \emph{must} be imported from an Active
Directory server. NTLM (and Kerberos) works only if the users are in the
AD; otherwise any SSO requests initiated by Liferay DXP fail.

NTLM configuration can be applied either at the system scope or at the
scope of a portal instance. To configure the NTLM SSO module at the
system scope, navigate to the Control Panel, click on
\emph{Configuration} → \emph{System Settings} → \emph{Security} →
\emph{SSO} → NTLM. The values configured there provide the default
values for all portal instances. Enter values in the same format as you
would when initializing a Java primitive type with a literal value.

Property Label \textbar{} Property Key \textbar{} Description \textbar{}
Type \textbf{Enabled} \textbar{} \texttt{enabled} \textbar{} Check this
box to enable NTLN SSO authentication. Note that NTLM will only work if
Liferay DXP's authentication type is set to screen name. \textbar{}
\texttt{boolean} \textbf{Domain Controller} \textbar{}
\texttt{domainController} \textbar{} Enter the IP address of your domain
controller. This is the server that contains the user accounts you want
to use with Liferay DXP. \textbar{} \texttt{String} \textbf{Domain
Controller Name} \textbar{} \texttt{domainControllerName} \textbar{}
Specify the domain controller NetBIOS name. \textbar{} \texttt{String}
\textbf{Domain} \textbar{} \texttt{domain} \textbar{} Enter the domain /
workgroup name \textbar{} \texttt{String} \textbf{Service Account}
\textbar{} \texttt{serviceAccount} \textbar{} You need to create a
service account for NTLM. This account will be a computer account, not a
user account. \textbar{} \texttt{String} \textbf{Service Password}
\textbar{} \texttt{serviceAccount} \textbar{} Enter the password for the
service account. \textbar{} \texttt{String} \textbf{Negotiate Flags}
\textbar{} \texttt{negotiateFlags} \textbar{} Only available at system
level. Set according to the client's requested capabilities and the
server's ServerCapabilities. See
\href{http://msdn.microsoft.com/en-us/library/cc717152\%28v=PROT.10\%29.aspx}{here}
\textbar{} \texttt{String}

Note the AD's name and IP address correspond to the
\texttt{domainControllerName} and \texttt{domainController} settings.
The \texttt{Service\ Account} is for the \emph{NTLM} account (registered
with NTLM), not the Liferay DXP user account.

To override system defaults for a particular portal instance, navigate
to the Control Panel, click on \emph{Configuration} → \emph{Instance
Settings}, click on \emph{Authentication} and then on \emph{NTLM}.

\section{Summary}\label{summary-2}

NTLM authentication is often highly desirable in Intranet scenarios
where the IT department has control over what software is running on
client devices and thus can ensure NTLM compatibility. In an Active
Directory based network / domain, it is hard to beat the user experience
that NTLM authentication can provide.

Please remember that in order to use NTLM SSO, your Liferay DXP instance
authentication type must be set to screen name \emph{and} that all users
have been imported from your active directory. If this is not acceptable
for your Liferay DXP implementation, then another SSO solution (such as
CAS) can be used as a broker between your portal and the NTLM
authentication process.

\chapter{OpenID Single Sign On
Authentication}\label{openid-single-sign-on-authentication}

OpenID is a single sign-on standard implemented by multiple vendors.
Users can register for an ID with the vendor they trust. The credential
issued by that vendor can be used by all the web sites that support
OpenID. Some high profile OpenID vendors are Google, Paypal, Amazon, and
Microsoft. Please see the \href{http://www.openid.net/}{OpenID site} for
a more complete list.

\noindent\hrulefill

\textbf{Note:} OpenID is deprecated in 7.0 and has been removed. You can
still install it from Marketplace
\href{https://web.liferay.com/marketplace/-/mp/application/125668346}{here}
or
\href{https://web.liferay.com/marketplace/-/mp/application/125668379}{here}.

\noindent\hrulefill

With OpenID, users don't have to register for a new account on every
site which requires an account. Users register on \emph{one} site (the
OpenID provider's site) and then use those credentials to authenticate
to many web sites which support OpenID. Web site owners sometimes
struggle to build communities because users are reluctant to register
for \emph{another} account. Supporting OpenID removes that barrier,
making it easier for site owners to build their communities. All the
account information is kept with the OpenID provider, making it much
easier to manage this information and keep it up to date.

Liferay DXP can act as an OpenID consumer, allowing users to
automatically register and sign in with their OpenID accounts.
Internally, the product uses
\href{https://github.com/jbufu/openid4java}{OpenID4Java} to implement
the feature.

\section{OpenID at the System Scope}\label{openid-at-the-system-scope}

OpenID is enabled by default in Liferay DXP but can be disabled or
enabled at either the system scope or portal instance scope. To
configure the OpenID SSO module at the system level, navigate to the
Control Panel and click on \emph{Configuration} → \emph{System Settings}
→ \emph{Security} → \emph{SSO}. There's only a single configuration
setting. Check the \emph{Enabled} box to enable OpenID at the system
scope (for all portal instances), uncheck it to disable it at the system
scope.

\section{OpenID at the Instance
Scope}\label{openid-at-the-instance-scope}

To configure the OpenID SSO module at the portal instance scope,
navigate to the Control Panel and click on \emph{Configuration} →
\emph{Instance Settings}, then on \emph{Authentication} → \emph{OpenID}.
There's only a single configuration setting. Check the \emph{Enabled}
box to enable OpenID for the current portal instance, or uncheck it to
disable it for the current portal instance.

Regardless of whether OpenID is enabled at the System or Instance scope,
users can see the OpenID icon when they sign into Liferay DXP. Click
\emph{Sign In}. The OpenID icon is displayed at the lower left.

\chapter{Authenticating with
Kerberos}\label{authenticating-with-kerberos}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

You can use Kerberos to authenticate Microsoft Windows ™ accounts with
Liferay DXP. This is done completely through configuration by using a
combination of Liferay DXP's LDAP support and a web server that supports
the Kerberos protocol.

Note that this configuration is preferred above
\href{/docs/7-1/deploy/-/knowledge_base/d/ntlm-single-sign-on-authentication}{NTLM}
because security vulnerabilities persist.

While it's beyond the scope of this article to explain how to set up
Kerberos and Active Directory on a Windows ™ server, we can describe the
minimum prerequisites for setting up Liferay authentication:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A Windows ™ server with Active Directory and DNS set up so the AD
  server and Liferay DXP can resolve each other on the network. In other
  words, they must be able to ping each other \emph{by name}.
\item
  An administrative user in AD Liferay DXP can use to bind to AD.
\item
  A Kerberos keytab file exported via the \texttt{ktpass} command
  containing the cryptographic information the Liferay DXP server needs
  to bind to AD.
\item
  A web server in front of Liferay DXP that supports Kerberos, such as
  Apache, NGNIX, or IIS. The web server must also support injecting a
  header to be used as a token in the Liferay DXP configuration (see
  below).
\item
  Of course, you need a Liferay DXP installation that can also resolve
  by name the other servers. It should never run on the Active Directory
  server.
\end{enumerate}

When you have all of these prerequisites in place, you're ready to
configure Kerberos authentication.

\section{How Kerberos Authentication
Works}\label{how-kerberos-authentication-works}

From the prerequisites, you may be able to guess that there are several
moving parts to how SSO works with Kerberos.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/kerberos.png}}
\caption{Kerberos authentication requires a web server in front of your
Liferay DXP server.}
\end{figure}

First, a properly configured web browser sends a negotiate request using
encrypted Windows user data. To configure this, the browser must
recognize the site as a trusted site (explained below). The web server's
Kerberos module uses the keytab file to bind over the Kerberos protocol
to AD and verify the user information. If all is okay, the AD server
confirms the connection with a valid response.

The web server you choose must support both the Kerberos protocol and
the injection of a custom header into the request that Liferay DXP can
later read. When the web server forwards the request to Liferay DXP, it
reads the header to obtain the user data and authenticate the user.

Next, you'll learn how to get all of this working.

\section{Configuring Kerberos
Authentication}\label{configuring-kerberos-authentication}

There are four components to configure: a user keytab from Active
Directory, a web server in front of your application server, Liferay
DXP, and your Windows™ clients.

\section{Creating the User Keytab}\label{creating-the-user-keytab}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a user so Liferay DXP can bind to Active Directory.
\item
  Generate a Kerberos keytab file using \texttt{ktpass}:

\begin{verbatim}
ktpass -princ HTTP/[web server host name]@[domain] -mapuser [user name]@[domain] -crypto ALL -ptype KRB5_NT_PRINCIPAL -pass [password] -out c:\kerberos.keytab
\end{verbatim}

  For example:

\begin{verbatim}
ktpass -princ HTTP/mywebserver.intdomain.local@INTDOMAIN.LOCAL -mapuser Marta@INTDOMAIN.LOCAL -crypto ALL -ptype KRB5_NT_PRINCIPAL -pass password-for-Marta -out c:\kerberos.keytab
\end{verbatim}
\item
  Ensure that the AD domain controller and the web server can see each
  other on the network via DNS configuration or \texttt{hosts} file.
\end{enumerate}

\section{Configuring Your Web Server}\label{configuring-your-web-server}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Configure Kerberos authentication. On Linux, this involves installing
  \texttt{krb5} and configuring it to match your realm that's already
  configured for Active Directory. The example domain for the user
  configured in step two above would look like this:

\begin{verbatim}
[libdefaults]
    default_realm = INTDOMAIN.LOCAL

[domain_realm]
    mywebserver.intdomain.local = INTDOMAIN.LOCAL
    intdomain.local = INTDOMAIN.LOCAL
    .intdomain.local = INTDOMAIN.LOCAL

[realms]
INTDOMAIN.LOCAL = {
    admin_server = winserver.intdomain.local
    kdc = winserver.intdomain.local
}
\end{verbatim}
\item
  Copy the keytab file you generated on your AD server to your web
  server.
\item
  Configure your web server, making sure you set the correct server
  name, Kerberos service name, Kerberos authentication realms, and the
  path to the keytab file. For example, if you're using the Apache HTTP
  server, the configuration might look like this:

\begin{verbatim}
LoadModule headers_module /usr/lib/apache2/modules/mod_headers.so
LoadModule rewrite_module /usr/lib/apache2/modules/mod_rewrite.so
LoadModule proxy_module /usr/lib/apache2/modules/mod_proxy.so
LoadModule proxy_http_module /usr/lib/apache2/modules/mod_proxy_http.so
LoadModule proxy_ajp_module /usr/lib/apache2/modules/mod_proxy_ajp.so
LoadModule auth_kerb_module /usr/lib/apache2/modules/mod_auth_kerb.so

<VirtualHost *:10080>
    <Proxy *>
        Order deny,allow
        Allow from all
    </Proxy>
    ProxyRequests     Off
    ProxyPreserveHost On
    ProxyPass / ajp://localhost:8009/
    ProxyPassReverse / ajp://localhost:8009/
    ServerName mywebserver.intdomain.local
    <Location />
                Order allow,deny
                Allow from all
                AuthType Kerberos
                KrbServiceName HTTP/mywebserver.intdomain.local@INTDOMAIN.LOCAL
                AuthName "Domain login"
                KrbAuthRealms INTDOMAIN.LOCAL
                Krb5KeyTab /etc/apache2/kerberos.keytab
                require valid-user
                KrbMethodNegotiate  On
                KrbMethodK5Passwd   Off
                #KrbLocalUserMapping On

                # Below directives put logon name of authenticated user into http header X-User-Global-ID
                RequestHeader unset X-User-Global-ID
                RewriteEngine On
                RewriteCond   %{LA-U:REMOTE_USER} (.+)
                RewriteRule   /.* - [E=RU:%1,L,NS]
                RequestHeader set X-User-Global-ID %{RU}e

                # Remove domain suffix to get the simple logon name
                # RequestHeader edit X-User-Global-ID "@INTDOMAIN.LOCAL$" ""

    </Location>
</VirtualHost>
Listen 10080
\end{verbatim}

  The last line is commented out based on user preference. If you want
  the domain removed from the user name when saved in Liferay DXP,
  uncomment it. Otherwise, leave it commented out to store the domain
  with the user name.
\end{enumerate}

\section{Connecting Liferay DXP to Active Directory over
LDAP}\label{connecting-liferay-dxp-to-active-directory-over-ldap}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Finally, configure Liferay DXP to access Active Directory via the LDAP
  protocol. Change authentication to be by Screen Name by selecting it
  in Configuration → Instance Settings → Authentication → General.
\item
  Connect Liferay DXP to AD over LDAP by going to Configuration →
  Instance Settings → Authentication → LDAP and adding an LDAP server.
  Provide the information appropriate to your installation:

  \textbf{Base Provider URL:} Your AD server on the proper port.

  \textbf{Base DN:} Your domain configuration. The example above might
  be \texttt{DC=INTDOMAIN.DC=LOCAL}.

  \textbf{Principal/Credentials:} Supply the credentials for the user
  exported to the keytab file.

  \textbf{Authentication Search Filter:} Supply the appropriate search
  filter to return user objects. For example,
  \texttt{(\&(objectCategory=person)(sAMAccountName=*))}

  \textbf{UUID:} Supply what uniquely identifies a user, such as
  \texttt{sAMAccountName}.

  \textbf{Screen Name:} Supply the field that should be mapped to
  Liferay DXP's screen name field, such as \texttt{sAMAccountName}.

  \textbf{Password:} Supply the field that contains the user's password,
  such as \texttt{userPassword}.
\item
  Be sure to test the connection, save, and enable the configuration.
\item
  Finally, configure the token for single sign-on at Configuration →
  System Settings → Security → SSO → Token Based SSO. Make sure the User
  Token Name matches \emph{exactly} the token you configured in your web
  server. Click the \emph{Enabled} and \emph{Import from LDAP} boxes and
  click \emph{Save}.
\end{enumerate}

Excellent! You've configured your servers. All that's left is to
configure your clients.

\section{Configuring your Clients}\label{configuring-your-clients}

You must do two things: make your computer log into the domain and
configure your Liferay DXP server as a trusted Internet site.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Join your computer to your domain. In keeping with the example above,
  you'd make your computer a member of the \texttt{INTDOMAIN.LOCAL}
  domain.
\item
  Log in as a user in that domain.
\item
  Internet Explorer, Edge, and Chrome use the Windows™ settings for
  trusted sites. If you use these browsers, go to Internet Options →
  Security → Local Intranet Sites and add your Liferay DXP server's URL.
  For example, add \texttt{http://mywebserver.intdomain.local:10080}.
\item
  Firefox can be configured by typing \texttt{about:config} in its
  address bar. Search for the below two preferences and add the Liferay
  DXP server's URL as the value for both:

  \begin{itemize}
  \tightlist
  \item
    \texttt{network.negotiate-auth.delegation-uris}
  \item
    \texttt{network.negotiate-auth.trusted-uris}
  \end{itemize}
\end{enumerate}

After configuring these things, test your configuration by accessing
Liferay DXP through the web server's URL. Since you are already logged
into your client machine, you should be automatically logged into
Liferay DXP without a user/password prompt.

Congratulations on configuring Kerberos with Liferay DXP!

\chapter{Configuring CORS}\label{configuring-cors}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

CORS stands for Cross-Origin Resource Sharing. An Origin is a web server
at a different domain, and a Resource is some asset stored on the
server, like an image, PDF, or HTML file. Sometimes you must request
resources stored on another origin. This is called a cross-origin
request, and web servers have policies to allow or deny such requests.

For example, browsers themselves don't allow cross-origin AJAX-style
requests from scripts to help mitigate
\href{https://en.wikipedia.org/wiki/Cross-site_scripting}{cross-site
scripting} attacks. These APIs follow a \emph{same origin} policy. But
for certain resources, it can be convenient to allow Liferay DXP to
serve them to different origins.

For example, if you manage images in Docs \& Media, you may want to
allow cross-origin requests for them. You can enable CORS for matching
URLs in Liferay DXP or for JAX-RS application resources.

\section{Enabling CORS for Liferay DXP
Services}\label{enabling-cors-for-liferay-dxp-services}

You'll find the settings in Configuration → System Settings → Security →
Security Tools → Portal Cross Resource Origin Sharing (CORS):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click \emph{Add} to create a configuration entry.
\item
  Fill out the fields on the form. When finished, click \emph{Save}.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/CORS-portal.png}}
\caption{The CORS system settings provide a way to configure CORS
headers for Liferay services.}
\end{figure}

\textbf{Enabled:} Check this box to enable the entry.

\textbf{Name:} Give the configuration entry a name.

\textbf{URL Pattern:} Use the Plus button to add as many patterns as you
need. Define patterns that match URLs to the resources you want to
share. For example, if you have many attachments in the Knowledge Base
application, you could define this pattern:

\begin{verbatim}
/knowledge_base/*
\end{verbatim}

This would define resources stored in the Knowledge Base as applicable
to the policy you set in the response header below.

\textbf{CORS Response Headers:} Use the Plus button to add as many
headers as you need. Define policies for any of the
\href{https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers\#CORS}{CORS
headers} here.

You can also use a
\href{/docs/7-2/user/-/knowledge_base/u/understanding-system-configuration-files}{configuration
file} to configure CORS.

\section{Enabling CORS for JAX-RS
Applications}\label{enabling-cors-for-jax-rs-applications}

You'll find the settings in Configuration → System Settings → Security →
Security Tools → Web Contexts Resource Origin Sharing (CORS):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click \emph{Add} to create a configuration entry.
\item
  Fill out the fields on the form. When finished, click \emph{Save}.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/CORS-jax-rs.png}}
\caption{There's a separate system settings category for CORS web
contexts.}
\end{figure}

\textbf{Dynamic Web Context OSGi Filter:} Define an LDAP-style
\href{https://osgi.org/specification/osgi.cmpn/7.0.0/service.http.whiteboard.html}{filter}
to define which JAX-RS whiteboard applications the CORS headers in this
entry apply to. This is the default filter:

\begin{verbatim}
(&(!(liferay.cors=false))(osgi.jaxrs.name=*))
\end{verbatim}

It applies CORS headers to all deployed JAX-RS whiteboard applications
without a \texttt{liferay.cors=false} property. This helps during
development, but in production you should use the narrowest
configuration possible.

\textbf{URL Pattern:} Use the Plus button to add as many patterns as you
need. Define patterns that match URLs to the web services you want to
access.

\textbf{CORS Response Headers:} Use the Plus button to add as many
headers as you need. Define policies for any of the
\href{https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers\#CORS}{CORS
headers} here.

\href{/docs/7-2/frameworks/-/knowledge_base/f/jax-rs}{JAX-RS} developers
can use the \texttt{@CORS} annotation to set policies for their deployed
applications.

\chapter{AntiSamy}\label{antisamy}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay DXP includes an
\href{https://www.owasp.org/index.php/Category:OWASP_AntiSamy_Project}{AntiSamy}
module that protects against user-entered malicious code. If your site
allows users to post content, such as in message boards, blogs, or other
applications, they could include malicious code either intentionally or
unintentionally. The AntiSamy module filters HTML/CSS fragments and
removes suspect JavaScript code from them.

The module leverages the powerful
\href{https://www.owasp.org/index.php/Category:OWASP_AntiSamy_Project}{OWASP
AntiSamy library} to enforce a content policy that's been effective for
the auction site eBay. The AntiSamy module adds an OWASP AntiSamy
implementation to your portal's list of existing sanitizer
implementations. Liferay DXP uses the AntiSamy sanitizer and any
existing configured sanitizers to scrub user input to blogs entries,
calendar events, message boards posts, wiki pages, and web content
articles.

AntiSamy is enabled by default.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/antisamy.png}}
\caption{Liferay DXP's AntiSamy configuration options allow you to
specify both a blacklist and a whitelist.}
\end{figure}

\section{Configuring AntiSamy}\label{configuring-antisamy}

AntiSamy uses both a blacklist and a whitelist, so you can define
subsets of entities that should be sanitized or not sanitized. The
whitelist prevents content of that type from being filtered, while the
blacklist filters content of that type.

By default, everything is sanitized except for \texttt{JournalArticle},
\texttt{BlogsEntry}, and \texttt{FragmentEntry}. The assumption is that
users posting these kinds of content are trusted, while users posting
message boards or wiki articles may not be trusted. If this is not the
configuration you want, you can change it:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Navigate to \emph{Control Panel} → \emph{System Settings} →
  \emph{Security Tools} → \emph{AntiSamy Sanitizer}.
\item
  Enter a package path you want to sanitize into the \emph{Blacklist}
  field.
\item
  Use the plus (+) button to add further Blacklist fields if you need
  them.
\item
  Use the plus (+) button to add further Whitelist fields if you need
  them.
\item
  Enter a package path you don't want sanitized into a \emph{Whitelist}
  field.
\item
  If you want to remove a package path from the configuration, click the
  trash can icon.
\item
  When finished, click \emph{Save}.
\end{enumerate}

\section{Using Wildcards}\label{using-wildcards}

You can use wildcards in the configuration. For example, if you only
want to sanitize message board posts and nothing else, you can

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Configure the whitelist to \texttt{*}
\item
  Configure the blacklist to \texttt{com.liferay.message.boards.*}
\end{enumerate}

The whitelist and the blacklist work together. Without the blacklist,
the above configuration's whitelist must include every content type
except \texttt{com.liferay.message.boards}, which would be a daunting
task to configure.

Use AntiSamy to ensure user-generated content stays safe for other users
to view.

\chapter{OAuth 2.0}\label{oauth-2.0}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

OAuth 2.0 is an industry-standard authorization protocol. Users can
seamlessly share select credentials from your Liferay-based website with
various clients. You've seen this before: any time you see a ``This site
wants to access:'' button (followed by a list of things like email
address, friends list, etc.) from Google or Facebook, or you authorize a
third-party Twitter client, that's OAuth 2.0 in action. It works by
authorizing password-less access to portions of user-owned resources
(such as an email address, a user profile picture, or something else
from your account) and other permissioned resources.

OAuth 2.0's design encrypts all authorization transport through HTTPS,
which prevents data passed between the systems from being intercepted.

\section{Flow of OAuth 2.0}\label{flow-of-oauth-2.0}

OAuth 2.0 takes advantage of web standards wherever possible: transport
is encrypted with HTTPS; tokens are implemented as HTTP headers; data is
passed via web services.

Here's how OAuth 2.0 works:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/oauth-flow.png}}
\caption{OAuth 2.0 takes advantage of web standards.}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A user accesses a third-party application that supports authorization
  via credentials from a Liferay-based website. In the application (web
  or mobile), the user requests authorization via OAuth, sending the
  browser or app to the Liferay-based website. When using PKCE
  (explained below), the application also generates a code verifier and
  sends a code challenge that is created by applying a transformation to
  it.
\item
  The user authenticates and is shown the resources the application
  wants permission to access. When the user gives permission by clicking
  \emph{Allow}, Liferay generates an authorization code that's sent to
  the application over HTTPS.
\item
  The application then requests a more permanent authorization token and
  sends the code with the request (along with the PKCE code verifier).
\item
  If the authorization code matches (and the transformed PKCE code
  verifier matches the previously sent code challenge), Liferay
  cryptographically generates an authorization token for this user and
  application combination. It sends the token to the application over
  HTTPS. Initial authorization is now complete!
\item
  When the application must retrieve data, it sends the token with the
  request to prove it's authorized to have that data.
\item
  Provided the token matches what Liferay has for that user and
  application, access is granted to retrieve the data.
\end{enumerate}

That description throws around a lot of terms. Definitions provided
below.

\section{OAuth 2.0 Terminology}\label{oauth-2.0-terminology}

\textbf{Authentication:} Providing credentials so a system can verify
who you are by matching those credentials with what it has stored. OAuth
is not an authentication protocol.

\textbf{Authorization:} Granting access to resources stored on another
system. OAuth is an authorization protocol.

\textbf{Application:} Any client (web, mobile, etc.) that must be
authorized to have access to resources. Applications must be registered
by administrators before users can authorize access to their resources.

\textbf{Client:} Almost synonymous with \emph{application}, except that
applications can have variants, such as web and mobile. These variants
are clients.

\textbf{Client ID:} An identifier given to a client so it can be
recognized.

\textbf{Client Secret:} A previously agreed-upon text string that
identifies a client as a legitimate client.

\textbf{Access Token:} A cryptographically generated text string that
identifies a user/client combination for access to that User's
resources.

\textbf{Response Type:} OAuth 2.0 supports several response types.
Pictured and described above is the most common: the authorization code.
Other response types are \emph{password} (logging in with a user name
and password), and \emph{client credentials} (headless predefined
application access).

\textbf{Scope:} A list of items that define what the application wants
to access. This list is sent during the initial authorization request
(or otherwise defaults to scopes selected in the application
registration) so users can grant or deny access to their resources.

\textbf{Callback URI:} Also called a Redirection Endpoint URI. After
authorization is complete, the authorization server (i.e., Liferay)
sends the client to this location.

\section{Creating an Application}\label{creating-an-application}

When you have an application that can use OAuth 2.0 for authorization,
you must register that application so Liferay DXP can recognize it. Do
this by accessing \emph{Control Panel} → \emph{Configuration} →
\emph{OAuth2 Administration}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click the \emph{Add}
  (\pandocbounded{\includegraphics[keepaspectratio]{./images/icon-add.png}})
  button.
\item
  Fill out the form (description below).
\item
  Click \emph{Save} to save the application.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/oauth-new-application.png}}
\caption{Adding an application registers it so users can authorize
access to their data.}
\end{figure}

\textbf{Name:} Give the application a recognizable title.

\textbf{Website URL:} Add a link to the application's website.

\textbf{Callback URIs:} Enter at least one (line-separated) URI where
users should be redirected after they authorize (or refuse to authorize)
access to their accounts. This should link to a handler for whichever
Allowed Authorization Types you support (see below).

\textbf{Client Profile:} Choose a template that filters the
authorization types that are appropriate (secure) for that profile. For
example, if your application is a web application, choose \emph{Web
Application}, and these authorization types are available and selected
automatically: Authorization Code, Client Credentials, Refresh Token,
and Resource Owner Password Credentials. These are OAuth 2 ``flows''
documented in the \href{https://tools.ietf.org/html/rfc6749}{OAuth2 RFC
6749 Standards Document}. If you want to select authorization types
manually, select \emph{Other}.

\textbf{Allowed Authorization Types:} Select the defined OAuth 2
\href{https://tools.ietf.org/html/rfc6749\#section-1.2}{protocol flows}
your application supports. Several common combinations are defined for
you in the various Client Profiles above.

After you save the form, it reappears with additional fields:

\textbf{Client ID:} The system generates this for you; it's an
identifier for your application, so that Liferay DXP knows what
application is being authorized to access user data.

\textbf{Client Secret:} Click the \emph{pencil} icon to generate a
client secret. The secret identifies the client during the authorization
process (see figure 1 above). Not all client profiles require a client
secret, because some are incapable of keeping it secret! This is when
the aforementioned PKCE code challenge and verifier is needed.

\textbf{Icon:} Upload an icon that your application's users identify
with your application. This is displayed on the authorization screen.

\textbf{Privacy Policy URL:} Add a link to your application's privacy
policy.

\textbf{Token Introspection:} Allow your application to retrieve
metadata from the token by requesting it from Liferay DXP. This
implements \href{https://tools.ietf.org/html/rfc7662}{RFC 7662}.

Excellent! Now you know how to add OAuth2 authorization for your
application to Liferay DXP! Next, you must define scopes of user data
the application can access.

\chapter{OAuth2 Scopes}\label{oauth2-scopes}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

In OAuth 2.0, applications are granted access to limited subsets of user
data. These are called \emph{scopes} (not to be confused with Liferay
scopes). They are created in two ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  By administrators, by creating a Service Access Policy for the scope
\item
  By developers, by creating a JAX-RS endpoint. By default, scopes are
  generated based on the HTTP verbs supported by the JAX-RS endpoint. A
  special annotation overrides this behavior and registers specific
  scopes.
\end{enumerate}

\section{Creating a Scope for a JSONWS
Service}\label{creating-a-scope-for-a-jsonws-service}

The most common way to create a scope is to create a
\href{/docs/7-2/deploy/-/knowledge_base/d/service-access-policies}{Service
Access Policy} prefixed with the name \texttt{OAUTH2\_}. This naming
convention causes the policy to appear in the OAuth application
configuration screen as a scope.

For example, say the application needs access to a user's profile
information to retrieve the email address. To grant the application
access to this, go to \emph{Control Panel} → \emph{Configuration} →
\emph{Service Access Policy}, and create the policy pictured below.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/oauth-service-access-policy.png}}
\caption{A Service Access Policy defines a scope for OAuth 2.0
applications.}
\end{figure}

Note that the policy is not a default policy, and that it grants access
only to one method in the \texttt{UserService}. This is a JSONWS web
service generated by Service Builder. You can view a list of all
available services in your installation at this URL:

\begin{verbatim}
http://[host]:[port]/api/jsonws/
\end{verbatim}

Once you create a policy and name it with the \texttt{OAUTH2\_} prefix,
it appears in the \emph{Scopes} tab in OAuth2 Administration.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/oauth-scopes-tab.png}}
\caption{Scopes named with the proper prefix appear in the Scopes tab of
your application configuration.}
\end{figure}

Now you can select it and save your application.

\section{Creating the Authorization
Page}\label{creating-the-authorization-page}

This step is optional. Users need an interface to authorize access to
their accounts, and one is provided automatically. If, however, you want
to customize the page, you can create an authorization page in your
Site.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to \emph{Control Panel} → \emph{System Settings} → \emph{Security}
  → \emph{OAuth2}. Click the bottom item on the left, labeled
  \emph{Authorize Screen}.
\item
  Two defaults appear. The first is the URL to the authorize page. By
  default, it's \texttt{/group/guest/authorize-oauth2-application}. This
  corresponds to the default site's URL and a page on that site called
  \texttt{authorize-oauth2-application}.
\item
  If you have customized the name and URL of your default site, make the
  appropriate change here so the URL matches the page you'll create in
  that site next. Click \emph{Save}.
\item
  Go to your Site's \emph{Build} → \emph{Pages} screen. Click the
  \pandocbounded{\includegraphics[keepaspectratio]{./images/icon-add.png}}
  button and choose \emph{Private Page}. This forces users to log in.
\item
  Choose the \emph{Full Page Application} type.
\item
  Give the page the same name you configured in step 2.
\item
  Uncheck the box labeled \emph{Add this Page to the following Menus:}.
  You don't want this page showing up in your Site navigation.
\item
  On the page that appears next, verify the Friendly URL matches the URL
  you configured in step 2.
\item
  Under \emph{Full Page Application}, choose \emph{OAuth2 Authorize
  Portlet}.
\item
  Click \emph{Save}.
\end{enumerate}

Excellent! Users can use the default or the UI of your design to go
through the authorization process. Now that you have the UI and you
understand scopes, it's time to make the authorization process happen in
your application.

\chapter{Authorizing Account Access with
OAuth2}\label{authorizing-account-access-with-oauth2}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Once you have an application registered, you can start authorizing
users. To do that, you must construct the URL to the authorization
server (Liferay DXP). The authorization server asks users to authorize
the requested permissions to their resources, defined as you saw in the
previous tutorial as scopes.

\section{Authorization Code Flow}\label{authorization-code-flow}

The most common OAuth flow is the Authorization Code flow, used for web
applications. The URL for this requires the following request
parameters:

\begin{itemize}
\tightlist
\item
  \texttt{response\_type}
\item
  \texttt{client\_id}
\end{itemize}

To construct a URL for this authorization, follow this pattern:

\begin{verbatim}
https://[hostname]/o/oauth2/authorize?response_type=code&client_id=[client ID]
\end{verbatim}

The client ID comes from registering the application. It's automatically
generated (you can change it if you edit the application).

IMPORTANT: Sometimes the phrase ``web application'' is used loosely,
implying applications where the above URL is requested from the web
browser directly. If this happens, you'd leak the client secret,
compromising the security of the grant flow and the application. In such
cases, select the ``User Agent Application'' client profile instead when
registering your application. This makes a secure alternative available
to your application: PKCE Extended Authorization Code flow (see below).

Once the user has authorized the requested permissions to their
resources, the authorization server returns an authorization code to
your application at its registered callback URI (A.K.A. redirect URI) as
a query string parameter.

\begin{verbatim}
[your callback URI]?code=[authorization server generated code]
\end{verbatim}

Your application must then exchange this authorization code for an
access token by sending a POST request following this pattern:

\begin{verbatim}
http://localhost:8080/o/oauth2/token
\end{verbatim}

With the following parameters in the body (encoded as
\texttt{application/x-www-form-urlencoded}):

\begin{verbatim}
client_id=[client ID]
client_secret=[client secret]
grant_type=authorization_code
code=[authorization server generated code]
redirect_uri=[registered callback URI]
\end{verbatim}

In the body of HTTP response to this request, you receive JSON like
this:

\begin{verbatim}
{
    "access_token": "[authorization server generated access token]",
    "token_type": "Bearer",
    "expires_in": 600,
    "scope": "[the scopes that were authorized by the user]",
    "refresh_token": "[authorization server generated refresh token]"
}
\end{verbatim}

From this you should extract and persist the access token. If you intend
to use the token for an indefinite amount of time (beyond 600 seconds
from the above example) you also need the refresh token. This can be
used in conjunction with the Refresh Token Flow to obtain a new access
token with the same permissions, without further user authorization. The
authorization server only issues Refresh Tokens if your application
registration is registered for this flow.

\section{PKCE Extended Authorization Code
Flow}\label{pkce-extended-authorization-code-flow}

This flow is the same as above with the addition of the Proof Key for
Code Exchange (PKCE). It requires another request parameter:
\texttt{code\_challenge}. This flow is for clients like smartphone
applications that may not have sole access to the URL (and thus the
request parameters) redirected to by the authorization server after the
user authorization. It protects against a malicious application on the
same system authorizing itself by reading the response code. To do this,
the client application sends a \emph{code challenge} with the
authorization request: a string it has generated and which it only
knows. To generate this string it must first create another secret
string known as the \emph{Code Verifier}, and then apply a
transformation to it. After authorization, the code verifier is sent
with the authorization code, validating the client.

For more detail on how to do this, please refer to the
\href{https://tools.ietf.org/html/rfc7636}{PKCE specification}.

To support this flow, you must have defined PKCE as an Allowed
Authorization Type when you created the application. This is part of the
Native Application and User Agent Application client profiles. To
request an authorization code using PKCE, use a URL containing the
\texttt{code\_challenge} request parameter:

\begin{verbatim}
https://[hostname]/o/oauth2/authorize?response_type=code&client_id=[client ID]&code_challenge=[PKCE code challenge]
\end{verbatim}

The rest of the process is identical to Authorization Code flow, except
that when making the final request to get the access token, you must
also provide the following parameter:

\begin{verbatim}
code_verifier=[Code Verifier that was transformed and sent as code_challenge previously]
\end{verbatim}

\section{Client Credentials and Resource Owner
Flows}\label{client-credentials-and-resource-owner-flows}

There are two other, less used flows. If you have a scenario where two
servers exchange agreed upon, non user-centric data, you can bypass the
Allow/Deny screen for users and authorize the client. This is called the
Client Credentials flow, and you'd use this URL pattern:

\begin{verbatim}
https://[hostname]/o/oauth2/token?grant_type=client_credentials&client_id=[client ID]&client_secret=[client secret]
\end{verbatim}

A final flow, where users trust the application with their passwords is
rare, but possible. This is called the Resource Owner Password flow, and
its URL pattern looks like this:

\begin{verbatim}
https://[hostname]/o/oauth2/token?grant_type=password&client_id=[client ID]&client_secret=[client secret]&username=[user@emailaddress.com]&password=
\end{verbatim}

Users are prompted for their passwords, and upon successful log in,
receive an authorization code.

\section{Token Use}\label{token-use}

All flows above result in an access token that's sent by the
authorization server (Liferay DXP) to the client application. This token
is sent in the response for the client application to store and send
along with any future request for data.

For example, say the authorization code
\texttt{946856e2b5ddf0928f6fc55f657bab73} was sent to the client
application. When the client requests data, this code must be sent in
each request header. Using a command line HTTP client such as Curl, you
could send a request like this:

\begin{verbatim}
curl -H 'Authorization: Bearer 946856e2b5ddf0928f6fc55f657bab73' 'https://[hostname]/o/api/sample2'
\end{verbatim}

OAuth 2.0 provides a convenient way for client applications to be
granted access to particular services (scopes) by users without sharing
credential information.

\section{Revoking Access}\label{revoking-access}

Once access is granted, users or administrators are free to revoke
access whenever they wish. If this happens to a client, the token
becomes invalid and the client must ask the user for authorization
again. This puts users in control of what has access to their data, and
they can exercise this control at any time.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/oauth-user-apps.png}}
\caption{Users have complete control over what applications have access
to their data in their account profiles.}
\end{figure}

In their account areas, users can click \emph{OAuth2 Connected
Applications} and see a list of applications they've allowed to access
their accounts. From here, they can revoke access by clicking the
\emph{Remove Access} item in the Action menu or the \emph{Remove Access}
button in the detail screen for the application.

Administrators can view the authorizations in the Authorizations tab of
any app in \emph{Control Panel} → \emph{Configuration} → \emph{OAuth2
Administration}.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/oauth-revoke-access.png}}
\caption{All authorizations for an app appear in the Authorizations tab
for the app.}
\end{figure}

Clicking the \emph{Revoke} button on any listed authorization revokes
that application's access to that user's account.

\section{Summary}\label{summary-3}

OAuth 2.0 provides a complete and secure authorization flow for users,
without their having to share any credential information. Once
applications are created in the system, secure tokens provide access to
particular scopes of information, and this access can be revoked at any
time, making OAuth 2.0 a convenient method for users and developers
alike to access the information they need.

\chapter{Upgrading to 7.0}\label{upgrading-to-7.0}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Upgrading to 7.0 involves migrating your installation and
\href{/docs/7-2/tutorials/-/knowledge_base/t/upgrading-code-to-product-ver}{code
(your theme and custom apps)} to the new version. Here you'll learn how
to upgrade your installation.

Here are the installation upgrade paths:

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3611}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Upgrade Path
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Liferay Portal 5.x and 6.0.x → Liferay Portal 6.2 → Liferay DXP 7.2 &
Support life ended for Liferay Portal 5.0, 5.1, 5.2, and 6.0 \\
Liferay Portal 6.1.x → Liferay DXP 7.1 → @product@ 7.2 & Support life
ended for Liferay Portal 6.1 \\
Liferay Portal 6.2+ → Liferay DXP 7.2 & \\
Liferay DXP 7.0+ → @product@ 7.2 & \\
\end{longtable}

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} Themes and custom apps from Liferay Portal 6.0 through
Liferay DXP 7.1 can be upgraded directly to Liferay DXP 7.2. See the
\href{/docs/7-2/tutorials/-/knowledge_base/t/upgrading-code-to-product-ver}{code
upgrade instructions} for details.

\noindent\hrulefill

Here are the upgrade steps:

\noindent\hrulefill

\textbf{Note:} You can
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database}{prepare
a new Liferay server for data upgrade} in parallel with the steps up to
and including the step to
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-product-data}{upgrading
the Liferay DXP data}.

\noindent\hrulefill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \{.root\}\href{/docs/6-2/deploy/-/knowledge_base/d/upgrading-liferay}{If
  You're Upgrading to Liferay Portal 6.2, Follow the Liferay Portal 6.2
  Upgrade Instructions First}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-a-sharded-environment}{If
  You're Upgrading a Sharded Environment, Follow the Instructions for
  Upgrading It}

  Upgrading a sharded installation to 7.0 requires migrating it to as
  many non-sharded Liferay DXP installations (servers) as you have
  shards.\{.summary\}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/updating-a-cluster}{If
  You're a Upgrading a Cluster, Read Those Instructions First}

  If you're updating a cluster, read those instructions first and apply
  them to your upgrade.\{.summary\}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/planning-for-deprecated-applications}{Plan
  for Handling the Deprecated Applications}

  Every application deprecation has different ramifications. Learn how
  the deprecations might affect your site and decide how to replace the
  functionality you use from those applications.\{.summary\}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/test-upgrading-a-product-backup-copy}{Test
  Upgrading a Liferay DXP Backup Copy}

  Here you'll prune a backup copy of your database and upgrade the data.
  You'll learn how to use the upgrade tool and resolve upgrade issues.
  The notes and scripts you assemble as you prune and upgrade the
  database copy are invaluable for correctly and efficiently upgrading
  the Liferay DXP database you'll use with 7.0.\{.summary\}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/test-upgrading-a-product-backup-copy\#copy-the-production-installation-to-a-test-server}{Copy
    the Production Installation to a Test Server}

    You'll use the installation copy to test data changes.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/test-upgrading-a-product-backup-copy\#copy-the-production-backup-to-the-test-database}{Copy
    the Production Database Backup}

    Copy the production backup to the test database and save the copy
    logs for analysis.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/pruning-the-database}{Remove
    Duplicate Web Content and Structure Field Names}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/pruning-the-database}{Find
    and Remove Unused Objects}

    You may have intermediate versions of objects (e.g.,
    \texttt{JournalArticle} objects) that you don't need. Remove them
    and objects that only reference them.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/pruning-the-database\#test-with-the-pruned-database-copy}{Test
    Liferay DXP with its Pruned Database Copy}

    Make sure Liferay DXP continues to work successfully. If it's
    broken, start over with a fresh database backup and prune it more
    carefully.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-your-test-server-and-database}{Install
    the New Liferay DXP Version on a Test Server}

    Install the Liferay DXP version you're upgrading to, to use its
    upgrade tool.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/tuning-for-the-data-upgrade}{Tune
    Your Database for the Upgrade}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-product-data}{Upgrade
    the Liferay Data, then Return Here}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/test-upgrading-a-product-backup-copy\#copy-the-production-backup-to-the-test-database}{If
    the Upgrade Took too Long, Prune a Fresh Database Backup More and
    Upgrade Its Data}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/pruning-the-database}{Test
    the Upgraded Instance}

    Make sure Liferay DXP continues to work successfully. If it's
    broken, start over with a fresh database backup and prune it more
    carefully.\{.summary\}
  \item
    Checkpoint: You've pruned and upgraded your production database
    copy. You're ready to prepare for upgrading the production database.
  \end{enumerate}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database}{Prepare
  to Upgrade the Liferay DXP Database}

  Preparing for the production database upgrade involves pruning and
  testing it, upgrading your Marketplace apps, publishing staged
  changes, and synchronizing a complete data and configuration
  backup.\{.summary\}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#remove-all-unused-objects-you-identified-earlier}{Remove
    All Noted Unused Objects}

    Remove all unused objects you noted from pruning your test
    database.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#test-using-the-pruned-database}{Test
    Liferay DXP}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#upgrade-your-marketplace-apps}{Upgrade
    Your Marketplace Apps}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#publish-all-staged-changes-to-production}{Publish
    All Staged Changes}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#synchronize-a-complete-backup}{Synchronize
    a Complete Liferay DXP Backup}

    Synchronize a complete backup of your production Liferay DXP server
    installation and pruned production database.\{.summary\}
  \item
    Checkpoint: You're ready to prepare a 7.0 server for upgrading a
    production database.
  \end{enumerate}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade}{Prepare
  a New Liferay DXP Server for Data Upgrade}

  Set up a production server with 7.0, configured to use your document
  repository and Liferay DXP database. You'll migrate your portal and
  system properties too. (Note, this step can be done in parallel with
  any of the previous steps.)\{.summary\}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#synchronize-a-complete-backup}{Request
    an Upgrade Patch From Liferay Support (Liferay DXP Only)}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#install-liferay}{Install
    the Liferay DXP Version You're Upgrading To}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#install-the-latest-upgrade-patch-or-fix-pack-liferay-dxp-only}{Install
    the Latest Upgrade Patch or Fix Pack (Liferay DXP Only)}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#migrate-your-osgi-configurations-70}{Migrate
    Your OSGi Configurations (Liferay DXP 7.0+)}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#migrate-your-portal-properties}{Migrate
    Your Portal Properties}

    Migrate your portal properties to your new 7.0 server.\{.summary\}

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#update-your-portal-properties}{Update
      Your Portal Properties}

      Some of the portal properties have new values or have been removed
      or replaced. Update your properties for 7.0.\{.summary\}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#convert-applicable-properties-to-osgi-configurations}{Convert
      Applicable Properties to OSGi Configurations}

      Many applications are configured using OSGi Configuration (Config
      Admin) instead of portal properties. Convert your existing
      properties to their OSGi Configuration replacements.\{.summary\}
    \end{enumerate}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#configure-your-documents-and-media-file-store}{Configure
    Your Documents and Media File Store}

    The upgrade tool upgrades your Documents and Media file store too.
    Update your Documents and Media file store configuration and specify
    it for the upgrade tool.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade\#disable-indexing}{Disable
    Indexing}

    Improve the data upgrade performance by disabling
    indexing.\{.summary\}
  \item
    Checkpoint: You've prepared a new Liferay DXP server for executing
    the data upgrade
  \end{enumerate}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-product-data}{Upgrade
  the Liferay DXP data}

  This section explains the data upgrade options, upgrade configuration,
  and the upgrade process.\{.summary\}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/tuning-for-the-data-upgrade}{Tune
    Your Database for the Upgrade}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-data-upgrade}{Configure
    the Data Upgrade}

    Configure the data upgrade, including the data store and whether to
    automatically upgrade the modules.\{.summary\}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-core-using-the-upgrade-tool}{Upgrade
    the Core}

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-core-using-the-upgrade-tool\#upgrade-tool-usage}{Run
      the Data Upgrade Tool}

      Run the data upgrade tool. Resolve any core upgrade
      issues.\{.summary\}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database\#synchronize-a-complete-backup}{Issues
      Upgrading to 7.0 or Lower? Restore the Database Backup}

      If the issues were with upgrades to Liferay 7.0 or lower, get a
      clean start by restoring the pruned production database
      backup.\{.summary\}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-core-using-the-upgrade-tool}{Upgrade
      Your Resolved Issues}

      If there were issues upgrading to 7.2, resolve them and restart
      the data upgrade tool; continue if there were no
      issues.\{.summary\}
    \end{enumerate}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell}{Upgrade
    the Liferay Modules}

    Learn how to use Gogo Shell to upgrade the Liferay modules, if you
    didn't upgrade them automatically with the core.\{.summary\}

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell\#command-usage}{Upgrade
      Modules that are Ready for Upgrade}

      Discover which modules are ready for upgrade and upgrade
      them.\{.summary\}
    \item
      \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell\#checking-upgrade-status}{Check
      Module Upgrade Status and Resolve Any Module Upgrade Issues}
    \item
      Checkpoint: You've completed upgrading the Liferay data. It's time
      to get your server ready for production.\{.summary\}
    \end{enumerate}
  \end{enumerate}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/executing-post-upgrade-tasks}{Execute
  the Post-Upgrade Tasks}

  Now that your database is upgraded, clean up remnants of upgrading by
  restoring your database optimizations, enabling and regenerating your
  search indexes, and more.\{.summary\}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/executing-post-upgrade-tasks\#tuning-your-database-for-production}{Remove
    the Database Tuning}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/executing-post-upgrade-tasks\#re-enabling-search-indexing-and-re-indexing-search-indexes}{Re-enable
    and Re-Index the Search Indexes}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/executing-post-upgrade-tasks\#enabling-web-content-view-permissions}{Update
    Web Content Permissions (7.0 and lower)}
  \item
    \href{/docs/7-2/deploy/-/knowledge_base/d/planning-for-deprecated-applications}{Address
    Any Deprecated Apps That Still Need Handling}
  \end{enumerate}
\item
  Checkpoint: You've completed the upgrade and post-upgrade tasks
\end{enumerate}

Follow the steps above to upgrade your Liferay DXP installation to 7.0.
They link upgrade topic details to help complete a safe, successful
upgrade.

\chapter{Planning for Deprecated
Applications}\label{planning-for-deprecated-applications}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

As Liferay DXP evolves so do Liferay applications. They may, for
example, be deprecated in favor of newer and better Liferay
applications. The deprecations might call for migrating application data
to a new application or completely removing the application and data.
Before upgrading, examine the deprecations:

\begin{itemize}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/deprecated-apps-in-7-2-what-to-do}{7.2
  deprecations}
\item
  \href{/docs/7-1/deploy/-/knowledge_base/d/deprecated-apps-in-7-1-what-to-do}{7.1
  deprecations}
\end{itemize}

Determine how and when to address the deprecations in your upgrade plan.

\chapter{Test Upgrading a Liferay DXP Backup
Copy}\label{test-upgrading-a-liferay-dxp-backup-copy}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Before upgrading your production Liferay instance, you should do a trial
run (even multiple runs) to make sure that you upgrade successfully and
efficiently. Here's the process:

\begin{itemize}
\item
  \hyperref[preparing-a-test-server-and-database]{Preparing a test
  server and database}: This involves copying your current production
  installation to a test server and copying your production data backup
  to a test database. After you prune data from the test database (next
  step) you'll test against it.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/pruning-the-database}{Pruning
  the database}: Free your database of duplicate and unused objects. By
  removing them you can reduce upgrade time and improve your server's
  performance.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-your-test-server-and-database}{Upgrading
  your test server and database}: First you'll optimize your database
  for the data upgrade. Taking time to do this can save upgrade time.
  Then you'll do an upgrade test run (or several test runs) on a the
  pruned database copy. After going through the upgrade process,
  resolving any issues, and testing the upgraded server successfully,
  you can confidently upgrade your production database.
\end{itemize}

\noindent\hrulefill

\textbf{Tip:} These steps and
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade}{preparing
a new Liferay DXP server} can be done in parallel to save time.

\noindent\hrulefill

Now prepare your test environment.

\section{Preparing a Test Server and
Database}\label{preparing-a-test-server-and-database}

Using a new separate server and database let's you safely test
upgrading.

\section{Copy the Production Installation to a Test
Server}\label{copy-the-production-installation-to-a-test-server}

Prepare a test server to use a copy of your production installation.
Your test server must use the same Liferay version you're using on
production. Configure your server to use a new empty database for
testing data upgrades.

\section{Copy the Production Backup to the Test
Database}\label{copy-the-production-backup-to-the-test-database}

Import data from your
\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-a-liferay-installation}{production
database backup} to the new empty database.

\noindent\hrulefill

\textbf{Important:} Make sure to save the data import log---you'll
examine it in the next steps.

\noindent\hrulefill

Next you'll prune your database of unneeded data.

\chapter{Pruning the Database}\label{pruning-the-database}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Accumulating unneeded site data is common. For example, you may have
many unused versions of Web Content articles or Documents and Media
files. If you're done revising them and don't need the intermediate
revisions, you can remove them. This saves you space and upgrade time.
Here you'll remove unneeded data and then test your server.

\section{Remove Duplicate Web Content Structure Field
Names}\label{remove-duplicate-web-content-structure-field-names}

If you've used Web Content Management extensively, you might have
structures without unique field names. Find and remove duplicate field
names before upgrading. If you upgraded to Liferay Portal 6.2 previously
and skipped doing this, you'll encounter this error:

\begin{verbatim}
19:29:35,298 ERROR [main][VerifyProcessTrackerOSGiCommands:221] com.liferay.portal.verify.VerifyException: com.liferay.dynamic.data.mapping.validator.DDMFormValidationException$MustNotDuplicateFieldName: The field name page cannot be defined more than once
com.liferay.portal.verify.VerifyException: com.liferay.dynamic.data.mapping.validator.DDMFormValidationException$MustNotDuplicateFieldName: The field name page cannot be defined more than once
\end{verbatim}

If this is the case, roll back to your previous backup of Liferay Portal
6.2 and find and remove duplicate field names.

\section{Find and Remove Unused
Objects}\label{find-and-remove-unused-objects}

In the UI or using database queries, identify unused objects. Then
remove them via Liferay's UI or using Liferay's API through the
\href{/docs/7-2/user/-/knowledge_base/u/running-scripts-from-the-script-console}{script
console} or a portlet you create.

\noindent\hrulefill

\textbf{Important}: You should only use Liferay's UI or API because they
account for relationships between Liferay DXP objects.

Never use SQL directly on your database to remove records. Your SQL
might miss object relationships, orphaning objects and causing
performance problems.

\noindent\hrulefill

Here are some common places to check for unused objects.

\section{Objects From the Large/Populated
Tables}\label{objects-from-the-largepopulated-tables}

Table rows are mapped to Liferay DXP objects. Large tables with many
records might contain lots of unused objects. The greater the table size
and the records per table, the longer upgrading takes.

Finding and removing unused objects associated with such tables reduces
upgrade times. Your data import log (from the previous step) can provide
valuable table information. Database engines show this information in
different ways. Your database import log might look like this:

\begin{verbatim}
Processing object type SCHEMA\_EXPORT/TABLE/TABLE\_DATA

imported "LIFERAY"."JOURNALARTICLE" 13.33 GB 126687 rows

imported "LIFERAY"."RESOURCEPERMISSION" 160.9 MB 1907698 rows

imported "LIFERAY"."PORTLETPREFERENCES" 78.13 MB 432285 rows

imported "LIFERAY"."LAYOUT" 52.05 MB 124507 rows

imported "LIFERAY"."ASSETENTRY" 29.11 MB 198809 rows

imported "LIFERAY"."MBMESSAGE" 24.80 MB 126185 rows

imported "LIFERAY"."PORTALPREFERENCES" 4.091 MB 62202 rows

imported "LIFERAY"."USER\_" 17.32 MB 62214 rows

...
\end{verbatim}

Several items stand out in the example database import:

\begin{itemize}
\tightlist
\item
  The \texttt{JOURNALARTICLE} table makes up 98\% of the database size.
\item
  There are many \texttt{RESOURCEPERMISSION} records.
\item
  There are many \texttt{PORTLETPREFERENCES} records.
\end{itemize}

Search for unused objects associated with the tables that stand out and
use Liferay's API (e.g., the UI or
\href{/docs/7-2/user/-/knowledge_base/u/running-scripts-from-the-script-console}{script
console}) to delete the objects.

\section{Common Object Types Worth
Checking}\label{common-object-types-worth-checking}

Some object types should be checked for unused objects. Here are some
reasons for checking them:

\begin{itemize}
\tightlist
\item
  Removing them frees related unused objects for removal
\item
  They're version objects that aren't worth keeping
\end{itemize}

Check these object types:

\begin{itemize}
\item
  \textbf{Sites}: Remove sites you don't need. When you remove a site,
  remove its related objects:

  \begin{itemize}
  \item
    Layouts
  \item
    Portlet preferences
  \item
    File entries (document library objects)
  \item
    Asset Entries
  \item
    Tags
  \item
    Vocabularies and categories
  \item
    Expando fields and their values
  \item
    \texttt{ResourcePermission} objects
  \item
    (and everything else)
  \end{itemize}
\item
  \textbf{Instances}: Unused instances are rare, but since they are the
  highest object in the hierarchy, removing their objects can optimize
  upgrades considerably:

  \begin{itemize}
  \item
    Sites (and all their related content)
  \item
    Users
  \item
    Roles
  \item
    Organizations
  \item
    Global \texttt{ResourcePermission} objects
  \end{itemize}
\item
  \textbf{Intermediate web content versions:} Liferay DXP generates a
  new web content version after any modification (including
  translations). Consider removing versions you don't need. Removing a
  Journal Article, for example, also removes related objects such as
  image files (\texttt{JournalArticleImage}) that are part of the
  content. Removing unneeded image files frees space in your database
  and file system. For more details, see
  \href{/docs/7-2/deploy/-/knowledge_base/d/example-removing-intermediate-journal-article-versions}{Example:
  Removing Intermediate Journal Article Versions}.
\item
  \textbf{Document versions}: As with Journal Articles, if you don't
  need intermediate document versions, delete them. This saves space
  both in the database and on the file system, space that no longer
  needs to be upgraded.
\item
  \textbf{Layouts:} Layouts are site pages, and they affect upgrade
  performance because they relate to other entities such as portlet
  preferences, permissions, assets, ratings, and more. Remove unneeded
  layouts.
\item
  \textbf{Roles}: Remove any Roles you don't need. Deleting them also
  deletes related \texttt{ResourceBlockPermission} and
  \texttt{ResourcePermission} objects.
\item
  \textbf{Users:} If you have Users that aren't active anymore, remove
  them.
\item
  \textbf{Vocabularies}: Remove any unused vocabularies. Note that
  removing a vocabulary also removes its categories.
\item
  \textbf{Orphaned data}: Check for unused objects that are not
  connected to anything. Here are some examples:

  \begin{itemize}
  \item
    \texttt{DLFileEntries} with no file system data.
  \item
    \texttt{ResourcePermission} objects associated to a Role, Layout,
    User, portlet instance, etc. that no longer exists.
  \item
    \texttt{PortletPreference} objects associated with a portlet or
    layout that no longer exists. This is common in environments with
    many embedded portlets. These portlet instances have a different
    lifecycle and aren't deleted when the portlet is removed from a
    template.
  \end{itemize}
\end{itemize}

If you want to see an example of removing intermediate object versions,
read
\href{/docs/7-2/deploy/-/knowledge_base/d/example-removing-intermediate-journal-article-versions}{Example:
Removing Intermediate Journal Article Versions} and then return here.

Next, you'll test Liferay DXP with its pruned database.

\section{Test with the Pruned Database
Copy}\label{test-with-the-pruned-database-copy}

Find and resolve any issues related to the objects you removed. You can
always restart pruning a new copy of your production database if you
can't resolve an issue.

\noindent\hrulefill

\textbf{Warning:} the upgrade to Liferay DXP 7.2 moves Web Content
images to the Document Library and then deletes their former table
\texttt{JournalArticleImage}. Make sure the images show in the upgraded
Web Content articles.

\noindent\hrulefill

Once you've successfully tested Liferay DXP with its pruned database
copy, you can upgrade the database to 7.0.

\chapter{Example: Removing Intermediate Journal Article
Versions}\label{example-removing-intermediate-journal-article-versions}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

These instructions and code samples demonstrate removing intermediate
Journal Article versions. In the
\href{/docs/7-2/user/-/knowledge_base/u/running-scripts-from-the-script-console}{script
console}, you can remove unneeded object versions by executing Java or
Groovy code.

Here are example steps for removing intermediate Journal Article
versions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Decide how many of the latest versions to keep. You must keep the
  original version and the most recent version, but you may keep older
  recent versions too. For example, you may want to keep the two latest
  versions or just the latest.
\item
  Find a method for deleting the entity versions. Liferay DXP
  \href{@app-ref@/apps/}{app APIs} and
  \href{@platform-ref@/7.2-latest/javadocs/portal-kernel/}{com.lifieray.portal.kernel
  API} are available at \href{@platform-ref@}{@platform-ref@}.

  If it's a
  \href{/docs/7-2/appdev/-/knowledge_base/a/service-builder}{Service
  Builder} entity, examine the \texttt{delete*} methods in the entity's
  \texttt{*LocalServiceUtil} class. For example, this
  \texttt{deleteArticle} in
  \href{@app-ref@/web-experience/latest/javadocs/com/liferay/journal/service/JournalArticleLocalServiceUtil.html\#deleteArticle-long-java.lang.String-double-java.lang.String-com.liferay.portal.kernel.service.ServiceContext-}{\texttt{JournalArticleLocalServiceUtil}}
  deletes a Journal Article version:

\begin{verbatim}
deleteArticle(long groupId, java.lang.String articleId, double version, 
    java.lang.String articleURL, 
    com.liferay.portal.kernel.service.ServiceContext serviceContext)
\end{verbatim}
\item
  Aggregate the entity versions to delete and the information required
  to delete them. For example, get all the Journal Article versions in
  range that match your removal criteria and associate their entity IDs
  and group IDs with them---the \texttt{deleteArticle} method requires
  the entity ID and group ID.

  The entity object (e.g., \texttt{JournalArticle}) typically has a
  version field. \texttt{JournalArticleResource} has each Journal
  Article's article ID (the entity's ID) and group ID.
  \texttt{JournalArticleResource} is our key to getting each
  \texttt{JournalArticle}, which can have multiple versions. Here are
  steps for identifying the Journal Article versions to delete:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Get all the \texttt{JournalArticleResource} objects.
  \end{enumerate}

\begin{verbatim}
List<JournalArticleResource> journalArticleResources = 
    JournalArticleLocalServiceUtil.getJournalArticleResources(start, end);
\end{verbatim}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \setcounter{enumii}{1}
  \item
    Get each Journal Article version's workflow status via the
    \texttt{JournalArticle} object associated with each
    \texttt{JournalArticleResource}. Dynamic Query is an efficient way
    to get exactly the data you want (and nothing more) from each
    object.
  \end{enumerate}

\begin{verbatim}
for (JournalArticleResource
    journalArticeResource : journalArticleResources) {

    List<Double> journalArticlesVersionsToDelete =
        new ArrayList<Double>();

    DynamicQuery dq =
        DynamicQueryFactoryUtil.forClass(JournalArticle.class)
            .setProjection(ProjectionFactoryUtil.projectionList()
                .add(ProjectionFactoryUtil.property("id"))
                .add(ProjectionFactoryUtil.property("version"))
                .add(ProjectionFactoryUtil.property("status")))
            .add(PropertyFactoryUtil.forName("groupId")
                .eq(journalArticeResource.getGroupId()))
            .add(PropertyFactoryUtil.forName("articleId")
                .eq(journalArticeResource.getArticleId()))
            .addOrder(OrderFactoryUtil.asc("version"));

    List<Object[]> result =
        JournalArticleLocalServiceUtil.dynamicQuery(dq);

    // See the next step for the sample code that goes here
}
\end{verbatim}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \setcounter{enumii}{2}
  \tightlist
  \item
    For each \texttt{JournalArticleResource} (there's one for each
    Journal Article entity), build a list of intermediate versions in
    range of the first or latest versions you want to keep and whose
    status qualifies them for deletion. For example, you may want to
    delete intermediate article versions that are approved or expired
    (i.e.,
    \href{@platform-ref@/7.2-latest/javadocs/portal-kernel/com/liferay/portal/kernel/workflow/WorkflowConstants.html}{WorkflowConstants.STATUS\_APPROVED
    or WorkflowConstants.STATUS\_EXPIRED}). The
    \texttt{MIN\_NUMBER\_FIRST\_VERSIONS\_KEPT} and
    \texttt{MIN\_NUMBER\_LATEST\_VERSIONS\_KEPT} variables here mark the
    minimum and maximum number of first (oldest) and latest (newest)
    versions to keep.
  \end{enumerate}

\begin{verbatim}
List<Double> journalArticlesVersionsToDelete =
    new ArrayList<Double>();

for (int i=0; i < result.size(); i++) {
    long id = (long) result.get(i)[0];
    double version = (double) result.get(i)[1];
    int status = (int) result.get(i)[2];

    if ((status == WorkflowConstants.STATUS_APPROVED) || (status == WorkflowConstants.STATUS_EXPIRED) {

        if (i < MIN_NUMBER_FIRST_VERSIONS_KEPT) {
            continue;
        }

        if (i >= (result.size() -
            MIN_NUMBER_LATEST_VERSIONS_KEPT)) {
            continue;
        }

        journalArticlesVersionsToDelete.add(version);
    }
}

// See the next step for the sample code that goes here
\end{verbatim}
\item
  Lastly, delete each Journal Article matching the versions you
  aggregated.

\begin{verbatim}
for (double version : journalArticlesVersionsToDelete) {
{
    JournalArticleLocalServiceUtil.deleteArticle(journalArticeResource.getGroupId(),
        journalArticeResource.getArticleId(), 
        journalArticlesVersionsToDelete(i), null, null);
}
\end{verbatim}
\end{enumerate}

You can write similar code to remove intermediate versions of other
entities.

\noindent\hrulefill

\textbf{Tip:} Print the version (and any other information of interest)
of each object you're removing. You can also comment out the object
deletion call and read the printout of versions to be removed as a test
before committing to deleting them.

\noindent\hrulefill

After you've pruned your database, test it with Liferay DXP.

\chapter{Upgrading Your Test Server and
Database}\label{upgrading-your-test-server-and-database}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

After you've
\href{/docs/7-2/deploy/-/knowledge_base/d/pruning-the-database}{pruned
your database and tested it successfully}, it's ready for upgrade. Here
you'll install 7.0 and migrate your current installation files to it and
upgrade them. Then you'll optimize your database for the upgrade and
upgrade your data. Lastly, you'll test this upgraded test environment.
You may run into issues that require you to start again with backup of
your pruned database. After you're satisfied with the test upgrade, you
can prepare for upgrading production. Start with preparing 7.0 on a test
server.

\section{Install Liferay on a Test Server and Configure It to Use the
Pruned
Database}\label{install-liferay-on-a-test-server-and-configure-it-to-use-the-pruned-database}

\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade}{Prepare
a new test server with 7.0}. Configure it to use the pruned database
copy---keep the original backup in case you want to restart test
upgrades on a copy of it. You'll use the new test server's Liferay
upgrade tool next.

\section{Tune Your Database for the
Upgrade}\label{tune-your-database-for-the-upgrade}

\href{/docs/7-2/deploy/-/knowledge_base/d/tuning-for-the-data-upgrade}{Tune
your database for the upgrade}.

\section{Upgrade the Database}\label{upgrade-the-database}

Upgrade the database to 7.0 (see
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-product-data}{Upgrade
the Database}); then return here.

If the upgrade took too long, search the upgrade log to identify more
unused objects. Then retry these steps with a fresh copy of the
production database.

\section{Test the Upgraded Portal and Resolve Any
Issues}\label{test-the-upgraded-portal-and-resolve-any-issues}

Test this upgraded 7.0 instance and resolve any issues. If you can't
resolve an issue, retry these steps with a fresh copy of the production
database.

\section{Checkpoint: You've Pruned and Upgraded a Production Database
Copy}\label{checkpoint-youve-pruned-and-upgraded-a-production-database-copy}

By removing unused objects from Liferay DXP in your test environment,
you've made upgrading feasible to do in production. You identified
unused objects, documented/scripted removing them, and successfully
upgraded the Liferay DXP database copy.

It's time to prepare your production environment for upgrading.

\chapter{Preparing to Upgrade the Liferay DXP
Database}\label{preparing-to-upgrade-the-liferay-dxp-database}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

After testing the upgrade on a copy of your production database, you can
apply what you learned to your production database.

\noindent\hrulefill

\textbf{Tip:} This step and
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade}{preparing
a new Liferay DXP server} can be done in parallel to save time.

\noindent\hrulefill

\section{Remove All Unused Objects You Identified
Earlier}\label{remove-all-unused-objects-you-identified-earlier}

Previously you identified and removed unused objects from a copy of your
Liferay DXP production database backup. In the same way (in the script
console or UI) you removed the unused objects from the backup, remove
them from your pre-upgrade production database.

\section{Test Using the Pruned
Database}\label{test-using-the-pruned-database}

Find and resolve any issues related to the objects you removed. By
removing the objects from production and testing your changes before
upgrading, you can more easily troubleshoot issues, knowing that they're
not related to upgrade processes.

\section{Upgrade Your Marketplace
Apps}\label{upgrade-your-marketplace-apps}

Upgrade each Marketplace app (Kaleo, Calendar, Notifications, etc.) that
you're using to its latest version for your Liferay DXP installation.
Before proceeding with the upgrade, troubleshoot any issues regarding
these apps.

\section{Publish all Staged Changes to
Production}\label{publish-all-staged-changes-to-production}

If you have
\href{/docs/7-2/user/-/knowledge_base/u/enabling-staging}{local/remote
staging enabled} and have content or data saved on the staged site,
\href{/docs/7-2/user/-/knowledge_base/u/publishing-staged-content-efficiently}{publish}
it to the live site. If you skip this step, you must run a full publish
(or manually publish changes) after the upgrade, since the system won't
know what content changed since the last publishing date.

\section{Synchronize a Complete
Backup}\label{synchronize-a-complete-backup}

\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-a-liferay-installation}{Completely
back up your Liferay DXP installation, pruned production database, and
document repository}.

It's time to prepare a new Liferay DXP server.

\chapter{Preparing a New Liferay DXP Server for Data
Upgrade}\label{preparing-a-new-liferay-dxp-server-for-data-upgrade}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

To upgrade your Liferay DXP database, prepare a new server for hosting
7.0. You'll use this server to run the database upgrade and run 7.0.
Then you can run your production server while you're configuring a new
server to host 7.0 exactly the way you want.

\noindent\hrulefill

\textbf{Note:} these steps can be done in parallel with any of the
upgrade preparation steps: planning for deprecated apps, testing
upgrades on a Liferay DXP backup copy, or preparing to upgrade the
@product@ database.

\noindent\hrulefill

Get the latest fixes for 7.0 by requesting an upgrade patch.

\section{Request an Upgrade Patch from Liferay Support (Liferay DXP
only)}\label{request-an-upgrade-patch-from-liferay-support-liferay-dxp-only}

An \emph{upgrade patch} contains the latest fix pack and hot fixes
planned for the next service pack. Upgrade patches provide the latest
fixes available for your data upgrade.

\section{Install Liferay}\label{install-liferay}

\href{/docs/7-2/deploy/-/knowledge_base/d/deploying-product}{Install
Liferay DXP on your application server} or
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-product}{use
Liferay DXP bundled with your application server of choice}.

\noindent\hrulefill

\textbf{Important:} Do not start your application server. It's not ready
to start until after the Liferay DXP database upgrade.

\noindent\hrulefill

\section{Install the Latest Upgrade Patch or Fix Pack (Liferay DXP
only)}\label{install-the-latest-upgrade-patch-or-fix-pack-liferay-dxp-only}

Install the upgrade patch (if you requested it from Liferay Support) or
the
\href{https://help.liferay.com/hc/en-us/articles/360028810452-Patching-Liferay-DXP}{latest
Fix Pack}.

\section{Migrate Your OSGi Configurations
(7.0+)}\label{migrate-your-osgi-configurations-7.0}

Copy your
\href{/docs/7-2/user/-/knowledge_base/u/understanding-system-configuration-files}{OSGi
configuration files} (i.e., \texttt{.config} files) to your new server's
\texttt{{[}Liferay\ Home{]}/osgi/configs} folder.

\section{Migrate Your Portal
Properties}\label{migrate-your-portal-properties}

It is likely that you have overridden portal properties to customize
your installation. If so, you must update the properties files (e.g.,
\texttt{portal-setup-wizard.properties} and
\texttt{portal-ext.properties}) to 7.0. For features that use OSGi
Config Admin, you must convert your properties to OSGi configurations.
As you do this, you must account for property changes in all versions of
Liferay DXP since your current version up to and including 7.0. Start
with updating your portal properties.

\section{Update Your Portal
Properties}\label{update-your-portal-properties}

If you're coming from a version prior to Liferay Portal 6.2, start with
these property-related updates:

\begin{itemize}
\item
  If you're on Liferay Portal 6.1,
  \href{/docs/6-2/deploy/-/knowledge_base/d/upgrading-liferay\#review-the-liferay-6}{adapt
  your properties to the new defaults that Liferay Portal 6.2
  introduced}.
\item
  If you're on Liferay 6.0.12,
  \href{/docs/6-2/deploy/-/knowledge_base/d/upgrading-liferay\#migrate-your-image-gallery-images}{migrate
  the Image Gallery}.
\item
  If you have a sharded environment,
  \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-a-sharded-environment}{configure
  your upgrade to generate a non-sharded environment}.
\item
  Liferay's image sprite framework is deprecated as of 7.2 and is
  disabled by default. The framework requires scanning plugins for image
  sprites. If you don't use the framework, there's no need for it to
  scan for images sprites. If you use the framework, enable it by
  overriding the default \texttt{sprite.enabled} portal property (new in
  7.2) value with the following setting in a
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{\texttt{portal-ext.properties}}
  file:

\begin{verbatim}
sprite.enabled=true
\end{verbatim}
\end{itemize}

\noindent\hrulefill

\textbf{Note:} You can build image sprites using any framework you like
and deploy them in your plugins.

\noindent\hrulefill

When a new version of Liferay DXP is released, there are often changes
to default settings, and this release is no different. If you rely on
the defaults from your old version, you should review the changes and
decide to keep the defaults from your old version or accept the defaults
of the new.

Because no existing properties changed from 7.1 to 7.2, here's a list of
the 6.2 properties that have changed in 7.2:

\begin{verbatim}
users.image.check.token=false
organizations.types=regular-organization,location
organizations.rootable[regular-organization]=true
organizations.children.types[regular-organization]=regular-organization,location
organizations.country.enabled[regular-organization]=false
organizations.country.required[regular-organization]=false
organizations.rootable[location]=false
organizations.country.enabled[location]=true
organizations.country.required[location]=true
layout.set.prototype.propagate.logo=true
editor.wysiwyg.portal-web.docroot.html.taglib.ui.discussion.jsp=simple
web.server.servlet.check.image.gallery=true
blogs.trackback.enabled=true
discussion.comments.format=bbcode
discussion.max.comments=0
dl.file.entry.thumbnail.max.height=128
dl.file.entry.thumbnail.max.width=128
\end{verbatim}

This property was removed:

\begin{verbatim}
organizations.children.types[location]
\end{verbatim}

The latest
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html}{portal
properties reference} provides property details and examples. Some
properties are replaced by OSGi configurations.

\section{Convert Applicable Properties to OSGi
Configurations}\label{convert-applicable-properties-to-osgi-configurations}

Properties in modularized features have changed and must now be deployed
separately in
\href{/docs/7-2/user/-/knowledge_base/u/system-settings\#exporting-and-importing-configurations}{OSGi
configuration files} (OSGi Config Admin).

Use the
\href{/docs/7-2/reference/-/knowledge_base/r/blade-cli}{\texttt{blade\ upgradeProps}}
command to scan your \texttt{portal-ext.properties} file to discover
which properties are now set via OSGi Config Admin. You can also check
the upgrade log from previous attempts for traces like these:

\begin{verbatim}
2019-03-09 17:05:17.678 ERROR [main][VerifyProperties:161] Portal property "layout.first.pageable[link_to_layout]" is obsolete
2019-03-09 17:05:17.679 ERROR [main][VerifyProperties:136] Portal property "journal.article.check.interval" was modularized to com.liferay.journal.web as "check.interval"
\end{verbatim}

\noindent\hrulefill

\textbf{Tip:} The Control Panel's \emph{Configuration → System Settings}
screens are the most accurate way to create \texttt{.config} files. Use
them to
\href{/docs/7-2/user/-/knowledge_base/u/system-settings\#exporting-and-importing-configurations}{export
a screen's configuration} to a \texttt{.config} file.

\noindent\hrulefill

\section{Update Your Database Driver}\label{update-your-database-driver}

Install the recommended database driver and update your database
connection driver specified in your \texttt{portal-ext.properties}. See
the
\href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
Templates}.

\section{Configure Your Documents and Media File
Store}\label{configure-your-documents-and-media-file-store}

General document store configuration (e.g.,
\texttt{dl.store.impl={[}File\ Store\ Impl\ Class{]}}) continues to be
done using \texttt{portal-ext.properties}. But here's what's changed for
document storage:

\begin{itemize}
\item
  Store implementation class package names changed from
  \texttt{com.liferay.portlet.documentlibrary.store.*} in Liferay Portal
  6.2 to \texttt{com.liferay.portal.store.*} in Liferay DXP 7.0+. Make
  sure your \texttt{portal-ext.properties} file sets
  \texttt{dl.store.impl} in one of these ways:

\begin{verbatim}
dl.store.impl=com.liferay.portal.store.file.system.FileSystemStore
dl.store.impl=com.liferay.portal.store.db.DBStore
dl.store.impl=com.liferay.portal.store.file.system.AdvancedFileSystemStore
dl.store.impl=com.liferay.portal.store.s3.S3Store
\end{verbatim}
\item
  JCR Store was deprecated in Liferay DXP 7.0. The
  \href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{Document
  Repository Configuration} documentation describes other store options.
  \href{/docs/7-2/user/-/knowledge_base/u/server-administration}{Migrate
  to a supported document store} before upgrading your data.
\item
  CMIS Store was deprecated since 7.0.10 Fix Pack 14 and was removed in
  Liferay DXP 7.2. The
  \href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{Document
  Repository Configuration} documentation describes other store options.
  \href{/docs/7-2/user/-/knowledge_base/u/server-administration}{Migrate
  to a supported document store} before upgrading your data.
\item
  Since Liferay DXP 7.0, document store type-specific configuration
  (e.g., specific to Simple File Store, Advanced File Store, S3, etc.)
  is done in the Control Panel at \emph{Configuration → System Settings
  → File Storage} or using OSGi configuration files (\texttt{.config}
  files). Type specific configuration is no longer done using
  \texttt{portal-ext.properties}.
\end{itemize}

For example, these steps to create a \texttt{.config} file specifying a
root file location for a Simple File Store or Advanced File Store:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a \texttt{.config} file named after your store implementation
  class.

  Simple File Store:
  \texttt{com.liferay.portal.store.file.system.configuration.FileSystemStoreConfiguration.config}

  Advanced File Store:
  \texttt{com.liferay.portal.store.file.system.configuration.AdvancedFileSystemStoreConfiguration.config}
\item
  Set the following \texttt{rootDir} property and replace
  \texttt{\{document\_library\_path\}} with your file store's path.

\begin{verbatim}
rootDir="{document_library_path}"
\end{verbatim}
\item
  Copy the \texttt{.config} file to your
  \texttt{{[}Liferay\ Home{]}/osgi/configs} folder.
\end{enumerate}

The
\href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{Document
Repository Configuration} provides more document store configuration
details.

\section{Configure Kerberos in place of
NTLM}\label{configure-kerberos-in-place-of-ntlm}

If you're using NTLM to authenticate Microsoft Windows ™ accounts with
Liferay DXP, switch to using
\href{/docs/7-2/deploy/-/knowledge_base/d/authenticating-with-kerberos}{Kerberos}.
Security vulnerabilities persist with NTLM. NTLM has been deprecated and
removed from the bundle, but you can still
\href{https://github.com/liferay/liferay-portal/tree/7.2.x/modules/apps/portal-security-sso-ntlm}{build
and deploy the module}.

\section{Disable Indexing}\label{disable-indexing}

Before starting the upgrade process in your new installation, you must
disable indexing to prevent upgrade process performance issues that
arise when the indexer attempts to re-index content.

To disable indexing, create a file called
\texttt{com.liferay.portal.search.configuration.IndexStatusManagerConfiguration.config}
in your \texttt{{[}Liferay\ Home{]}/osgi/configs} folder and add the
following content:

\begin{verbatim}
indexReadOnly="true"
\end{verbatim}

After you complete the upgrade, re-enable indexing by removing the
\texttt{.config} file or setting \texttt{indexReadOnly="false"}.

Your new 7.0 server is ready for upgrading your database.

\chapter{Upgrading the Liferay DXP
Data}\label{upgrading-the-liferay-dxp-data}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Now you're ready to upgrade the Liferay DXP data. The upgrade processes
update the database schema for the core and your installed modules.
Verification processes test the upgrade. Configured verifications for
the core and modules run afterwards, but can be run manually too.

Here are the ways to upgrade:

\begin{itemize}
\item
  \textbf{Upgrade everything in one shot}: Use the upgrade tool to
  upgrade the core and all the modules.
\item
  \textbf{Upgrade the core and the modules separately}: Use the upgrade
  tool (recommended) or
  \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell}{Gogo
  shell} to upgrade the core. Then use Gogo shell to upgrade each
  module.
\end{itemize}

If you are upgrading from Liferay Portal 6.2 or earlier, use the upgrade
tool to upgrade everything. It's the easiest, most comprehensive way to
upgrade from those versions. Since version 7.0, however, Liferay DXP's
modular framework lets you upgrade modules---even the
core---individually. A helpful practice for large databases is to focus
first on upgrading the core and your most important modules; then back
up your database before continuing upgrades. Upgrading is a flexible
process that adjusts to your preferences.

\noindent\hrulefill

\textbf{Note:} Liferay enterprise subscribers can use the upgrade tool
to execute upgrades for fix packs. Since Liferay DXP 7.1, a fix pack's
micro upgrade processes in the core (database schema micro version
changes) are not mandatory. This means you can install a fix pack (i.e.,
core code) without having to execute the database schema micro version
changes. You can execute micro version changes when you want, even
outside of major or minor version upgrades. Before using the upgrade
tool to execute a fix pack's micro upgrade process, however, you must
shut down the server, install the fix pack, and
\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-a-liferay-installation}{back
up the Liferay DXP database, installation, and Document Library store}.

Module micro database schema version changes in fix packs execute
automatically on server startup unless the
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-data-upgrade}{\texttt{autoUpgrade}
setting} is \texttt{false} (the default is \texttt{true}).

\chapter{Tuning for the Data Upgrade}\label{tuning-for-the-data-upgrade}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Upgrading impacts the database differently from daily running in
production. Because of this, you should tune your database for the
upgrade process before you run it, and then re-apply your production
settings after the upgrade completes.

\begin{itemize}
\item
  Data upgrades execute many more update statements (\texttt{INSERT},
  \texttt{UPDATE}, and \texttt{DELETE}) and less \texttt{SELECT}
  statements than production instances. When upgrading, tune your
  database for executing updates.
\item
  Data upgrades should be done in safe environments completely separate
  from production servers and should use database backup copies. If
  upgrade errors occur or you make mistakes, they don't impact
  production, and you can always restart using your database backup
  copy.
\end{itemize}

The data upgrade tuning instructions given here are a starting point for
tuning your Liferay DXP data upgrade. They account for data upgrade
activities and a safe data upgrade environment:

\begin{itemize}
\item
  Deactivate data integrity measures that impact performance. Restore
  the backup if failures occur.
\item
  Make commit-related transaction I/O operations asynchronous.
\item
  Increase the interval to flush commits to disk.
\item
  Minimize transaction logging.
\end{itemize}

\noindent\hrulefill

\textbf{Note:} These options worked well for us on specific versions of
each database. Please consult your database vendor's documentation for
information on how to optimize executing updates on your specific
database version.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Important:} Test your database configuration to determine tuning
that's best for your system, and consult your DBA as appropriate.
\textbf{Never} use database upgrade configurations in production. Always
restore your production database settings before starting your Liferay
DXP server for production use with the database.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Warning:} Some database properties and configurations are global
and affect schemas in the same database.

\noindent\hrulefill

These configurations were optimal for upgrading data in a Liferay 6.2 EE
installation that had these characteristics:

\begin{itemize}
\item
  3.2 GB database
\item
  15 GB Document Library
\item
  Content translated in 3 languages
\item
  Record count for most populated entities:

  \begin{itemize}
  \tightlist
  \item
    1,694,000 rating entries
  \item
    1,605,000 permissions (\texttt{ResourcePermission} objects)
  \item
    871,000 assets (\texttt{AssetEntry} objects)
  \item
    400,000 users
  \item
    400,000 sites (\texttt{Group} objects)
  \item
    402,000 images
  \item
    259,000 message forum threads and posts
  \item
    200,000 documents
  \item
    193,000 portlet preferences
  \item
    103,000 web content pieces (\texttt{JournalArticle} objects)
  \item
    50,600 pages
  \item
    3,276 journal article images
  \item
    3,100 document folders
  \end{itemize}
\end{itemize}

Start with configuring the database upgrade tool's Java process.

\section{Tuning the Database Upgrade Java
Process}\label{tuning-the-database-upgrade-java-process}

Make sure to provide adequate memory for the database upgrade tool's
Java process. 15GB was appropriate for the test scenario. Also make sure
to set the file encoding to UTF-8 and the time zone to GMT. Here are the
Java process settings:

\begin{itemize}
\tightlist
\item
  Xmx 15 GB RAM
\item
  File encoding UTF-8
\item
  User time zone GMT
\end{itemize}

Here is the \texttt{db\_upgrade.sh} command:

\begin{verbatim}
db_upgrade.sh -j "-Xmx15000m -Dfile.encoding=UTF-8 -Duser.timezone=GMT"
\end{verbatim}

It's time to tune your database transaction engine.

\section{Tuning the Database Transaction Engine for Executing
Updates}\label{tuning-the-database-transaction-engine-for-executing-updates}

Many more update statements are executed during data upgrade than in
production. Here's how to optimize each database's transaction engine
for the updates.

\section{IBM DB2}\label{ibm-db2}

Please consult IBM's official DB2 documentation.

\section{MariaDB}\label{mariadb}

In addition to the default database configuration, turn off InnoDB
double-write.

\section{Microsoft SQL Server}\label{microsoft-sql-server}

In addition to the default database configuration, set
\href{https://docs.microsoft.com/en-us/sql/relational-databases/logs/control-transaction-durability}{transaction
durability} to \texttt{FORCED}.

\section{MySQL}\label{mysql}

In addition to the default database configuration, turn off
\href{https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html\#sysvar_innodb_doublewrite}{InnoDB
double-write}.

\section{Oracle Database}\label{oracle-database}

The default configuration works well. It configures
\href{https://docs.oracle.com/database/121/REFRN/GUID-FD8D1BD2-0F85-4844-ABE7-57B4F77D1608.htm\#REFRN10048}{asynchronous
I/O to disk} automatically.

\section{PostgreSQL}\label{postgresql}

In addition to the default database configuration, turn off
\href{https://www.postgresql.org/docs/10/wal-async-commit.html}{synchronous
commits}.

\section{Tuning the Database Transaction
Log}\label{tuning-the-database-transaction-log}

In production, transaction logs mark safe states to roll back to. In
data upgrades, however, the safe state is the original data backup.
Since transaction logging is insignificant for data upgrades, it should
be disabled or minimized. Here are log tuning instructions for each
database.

\section{IBM DB2}\label{ibm-db2-1}

Please consult IBM's official DB2 documentation.

\section{MariaDB}\label{mariadb-1}

In addition to the default database configuration, set the InnoDB flush
log at transaction commit to \texttt{0}.

\section{Microsoft SQL Server}\label{microsoft-sql-server-1}

Use the default database configuration.

\section{MySQL}\label{mysql-1}

In addition to the default database configuration, set the
\href{https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html\#sysvar_innodb_flush_log_at_trx_commit}{InnoDB
flush log at transaction commit} to \texttt{0}.

\section{Oracle Database}\label{oracle-database-1}

Use the default database configuration.

\section{PostgreSQL}\label{postgresql-1}

In addition to the default database configuration, Set the
\href{https://www.postgresql.org/docs/10/wal-async-commit.html}{write
ahead log writer delay} to \texttt{1000} milliseconds.

Congratulations! You have a starting point to plan your own Liferay DXP
data upgrade project. Remember, optimal tuning depends on your data,
infrastructure conditions, and database vendor. Analyze your data, tune
for upgrade, and time your test upgrades. Use this information to
determine the best database and Java process configuration for your
Liferay DXP data upgrade.

\chapter{Configuring the Data
Upgrade}\label{configuring-the-data-upgrade}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The upgrade tool provides the easiest way to upgrade the core and
installed modules. You can use text files or the tool's command line
interface to configure your upgrade. The upgrade tool can upgrade
everything---the core and all the modules---together or separately.

7.0 bundles include the upgrade tool. If you installed @product-ver@
manually, you can download the upgrade tool separately.

\begin{itemize}
\item
  \emph{Liferay DXP 7.2}: Go to the
  \href{https://customer.liferay.com/group/customer/downloads}{\emph{Downloads}
  page} and select the \emph{DXP 7.2} product and the
  \emph{Product/Service Packs} file type. In the listing that appears,
  click \emph{Download} for the \emph{Liferay DXP Upgrade Client}.
\item
  \emph{Liferay Portal CE 7.2}: Go to the
  \href{https://www.liferay.com/downloads-community}{\emph{Downloads}
  page} and select \emph{Download} for \emph{Liferay Portal Tools for
  7.2}.
\end{itemize}

Before starting the data upgrade process, configure the upgrade tool for
the core upgrade and specify whether the upgrade tool should upgrade
non-core module data automatically.

\section{Configuring the Core
Upgrade}\label{configuring-the-core-upgrade}

The core upgrade requires configuration. You can configure it at runtime
via the command line interface or pre-configure it in these files in
\texttt{{[}Liferay\ Home{]}/tools/portal-tools-db-upgrade-client/}:

\begin{itemize}
\tightlist
\item
  \texttt{app-server.properties}: Specifies the server's location and
  libraries.
\item
  \texttt{portal-upgrade-database.properties}: Configures the database
  connection.
\item
  \texttt{portal-upgrade-ext.properties}: Sets the rest of the portal
  properties that the upgrade requires. You might want to copy your
  current portal properties (except your database properties) into this
  file. Before copying your current properties, make sure you've
  \href{/docs/7-2/deploy/-/knowledge_base/d/preparing-to-upgrade-the-product-database}{updated
  the portal properties for 7.0}.
\end{itemize}

Each file's properties are described next.

\section{Configuring
app-server.properties}\label{configuring-app-server.properties}

Specify the following information to configure 7.0's app server:

\texttt{dir:} the absolute path of the application server folder.
\emph{(required)}

\texttt{extra.lib.dirs:} a comma delimited list of extra directories
containing any binaries or resources to add to the class path. Use all
absolute paths OR all paths relative to \texttt{dir}. \emph{(required)}

\texttt{global.lib.dir:} the application server's global library
directory. Use the absolute path or a path relative to \texttt{dir}.
\emph{(required)}

\texttt{portal.dir:} the directory where portal is installed in your app
server. Use the absolute path or a path relative to \texttt{dir}.
\emph{(required)}

\texttt{server.detector.server.id:} ID of a supported application
server. (\emph{required}) Here are the IDs:

\begin{itemize}
\tightlist
\item
  \texttt{jboss}
\item
  \texttt{jonas}
\item
  \texttt{resin}
\item
  \texttt{tomcat}
\item
  \texttt{weblogic}
\item
  \texttt{websphere}
\item
  \texttt{wildfly}
\end{itemize}

Relative paths must use Unix style format. The following properties, for
example, are for Windows and use relative paths:

\begin{verbatim}
dir=D:\
extra.lib.dirs=Liferay/liferay-portal-master/tomcat-9.0.10/bin
global.lib.dir=Liferay/liferay-portal-master/tomcat-9.0.10/lib
portal.dir=Liferay/liferay-portal-master/tomcat-9.0.10/webapps/ROOT
server.detector.server.id=tomcat
\end{verbatim}

These properties, for example, are for Linux and use all absolute paths:

\begin{verbatim}
dir=/
extra.lib.dirs=/home/user/liferay/liferay-portal-master/tomcat-9.0.10/bin
global.lib.dir=/home/user/liferay/liferay-portal-master/tomcat-9.0.10/lib
portal.dir=/home/user/liferay/liferay-portal-master/tomcat-9.0.10/webapps/ROOT
server.detector.server.id=tomcat
\end{verbatim}

\section{Configuring
portal-upgrade-database.properties}\label{configuring-portal-upgrade-database.properties}

Specify the following information to configure the database you're
upgrading. Note that these properties correspond exactly to the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#JDBC}{JDBC
portal properties} you'd use in a \texttt{portal-ext.properties} file.

\texttt{jdbc.default.driverClassName} \emph{(required)}

\texttt{jdbc.default.url} \emph{(required)}

\texttt{jdbc.default.username} \emph{(required)}

\texttt{jdbc.default.password} \emph{(required)}

\section{Configuring
portal-upgrade-ext.properties}\label{configuring-portal-upgrade-ext.properties}

Specify the following information to configure the upgrade:

\texttt{liferay.home:} The
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay home
folder} \emph{(required)}

\texttt{dl.store.impl:} The implementation for persisting documents to
the document library store. This property is mandatory if you're using a
\texttt{*FileSystemStore} implementation. If you
\href{/docs/7-2/deploy/-/knowledge_base/d/preparing-a-new-product-server-for-data-upgrade}{updated
this property in your \texttt{portal-ext.properties}}, copy it here.
Otherwise, set the property one of these ways:

\begin{verbatim}
dl.store.impl=com.liferay.portal.store.file.system.FileSystemStore
dl.store.impl=com.liferay.portal.store.db.DBStore
dl.store.impl=com.liferay.portal.store.file.system.AdvancedFileSystemStore
dl.store.impl=com.liferay.portal.store.s3.S3Store
\end{verbatim}

\texttt{hibernate.jdbc.batch\_size:} The JDBC batch size used to improve
performance; set to \emph{250} by default \emph{(optional)}

\section{Example Upgrade
Configuration}\label{example-upgrade-configuration}

Here's an example interaction with the upgrade tool's command line
interface:

\begin{verbatim}
Please enter your application server (tomcat):
tomcat
Please enter your application server directory (../../tomcat-8.0.32):

Please enter your extra library directories (../../tomcat-8.0.32/bin):

Please enter your global library directory (../../tomcat-8.0.32/lib):

Please enter your portal directory (../../tomcat-8.0.32/webapps/ROOT):

[ db2 mariadb mysql oracle postgresql sqlserver sybase ]
Please enter your database (mysql):
mariadb
Please enter your database host (localhost):

(etc.)
\end{verbatim}

The command line interface creates the configuration files based on your
input. You can put this information into configuration files to
configure the tool manually.

Here are example upgrade configuration files that you can customize and
copy into
\texttt{{[}Liferay\ Home{]}/tools/portal-tools-db-upgrade-client/}:

\begin{itemize}
\item
  \texttt{app-server.properties}:

\begin{verbatim}
dir=../../tomcat-8.0.32
global.lib.dir=/lib
portal.dir=/webapps/ROOT
server.detector.server.id=tomcat
extra.lib.dirs=/bin
\end{verbatim}
\item
  \texttt{portal-upgrade-database.properties}:

\begin{verbatim}
jdbc.default.url=jdbc:mysql://lportal62?characterEncoding=UTF-8&dontTrackOpenResources=true&holdResultsOpenOverStatementClose=true&serverTimezone=GMT&useFastDateParsing=false&useUnicode=true
jdbc.default.driverClassName=com.mysql.cj.jdbc.Driver
jdbc.default.username=root
jdbc.default.password=
\end{verbatim}
\item
  \texttt{portal-upgrade-ext.properties}:

\begin{verbatim}
liferay.home=/home/user/servers/liferay7
module.framework.base.dir=/home/user/servers/liferay7/osgi
dl.store.impl=com.liferay.portal.store.file.system.FileSystemStore
\end{verbatim}
\end{itemize}

Next, decide if the upgrade tool should upgrade non-core modules
automatically.

\section{Configuring Non-Core Module Data
Upgrades}\label{configuring-non-core-module-data-upgrades}

You can configure the upgrade tool to upgrade all installed modules
automatically or to open a Gogo shell (after core upgrade completes) for
you to execute module upgrades manually.

If the upgrade tool's \texttt{autoUpgrade} property is set to
\texttt{true} (the default setting), upgrade processes for all installed
modules are run too.

If you set \texttt{autoUpgrade="false"} in a file called
\texttt{com.liferay.portal.upgrade.internal.configuration.ReleaseManagerConfiguration.config}
and copy the file into the \texttt{{[}Liferay\ Home{]}/osgi/configs}
folder, the upgrade tool opens Gogo shell after the core upgrade. In the
Gogo shell, you can
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell}{administer
module upgrades}.

It's time to run the upgrade tool.

\chapter{Upgrading the Core Using the Upgrade
Tool}\label{upgrading-the-core-using-the-upgrade-tool}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The upgrade tool provides the easiest way to upgrade the core and
installed modules. Here's how to use it.

\section{Upgrade Tool Usage}\label{upgrade-tool-usage}

The \texttt{db\_upgrade.sh} script in the
\texttt{{[}Liferay\ Home{]}/tools/portal-tools-db-upgrade-client} folder
(\texttt{db\_upgrade.bat} on Windows) invokes the upgrade tool.

This command prints the upgrade tool usage:

\begin{verbatim}
db_upgrade.sh --help
\end{verbatim}

This configuration prevents automatic module upgrade, but causes the
upgrade tool to open a Gogo shell for
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell}{upgrading
modules} after finishing the core upgrade.

Here are the tool's default Java parameters:

\begin{verbatim}
-Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.timezone=GMT -Xmx2048m 
\end{verbatim}

The \texttt{-j} option overrides the JVM parameters. For example, these
options set the JVM memory to 10GB, which is a good starting point for
this process type:

\begin{verbatim}
db_upgrade.sh -j "-Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.timezone=GMT -Xmx10240m"
\end{verbatim}

The \texttt{-l} option specifies the tool's log file name:

\begin{verbatim}
db_upgrade.sh -l "output.log"
\end{verbatim}

Here are all the upgrade tool command line options:

\textbf{--help} or \textbf{-h}: Prints the tool's help message.

\textbf{--jvm-opts} or \textbf{-j} + \textbf{{[}arg{]}}: Sets any JVM
options for the upgrade process.

\textbf{--log-file} or \textbf{-l} + \textbf{{[}arg{]}}: Specifies the
tool's log file name---the default name is \texttt{upgrade.log}.

\textbf{--shell} or \textbf{-s}: Automatically connects you to the Gogo
shell after finishing the upgrade process.

\noindent\hrulefill

\textbf{Note:} Only execute the upgrade process on a server with ideal
memory, CPU, and database connection configurations. If executing an
upgrade remotely using \texttt{ssh}, make sure to guard against
interruptions:

\begin{itemize}
\tightlist
\item
  If you're executing the upgrade using \texttt{ssh}, ignore hangups
  (connection loss) by using \texttt{nohup} or something similar.
\item
  On the machine you're connecting from, disable settings that shutdown
  or sleep that machine.
\end{itemize}

The upgrade process continues on the server even if you lose connection
to it. If you lose connection, reconnect and monitor upgrade status via
the log (default log file is \texttt{upgrade.log}). If you're using an
earlier version of 7.0 and upgrade execution is interrupted, check your
log file for where execution stopped.

\begin{itemize}
\tightlist
\item
  If execution stopped during an upgrade process for Core 7.1 or higher,
  or any module upgrade process, restart the upgrade tool to continue
  the upgrade from that point. You can also use Gogo shell to
  \href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-modules-using-gogo-shell\#checking-upgrade-status}{check
  module upgrade status} and continue upgrading modules.
\item
  If execution stopped during an upgrade process for Core 7.0 or lower,
  you must
  \href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-a-liferay-installation}{restore
  the data from a backup} and start the upgrade again.
\end{itemize}

\noindent\hrulefill

\noindent\hrulefill

\textbf{Warning:} To prevent the tool's expanded command from growing
too large for Windows, execute the upgrade tool script from the
\texttt{{[}Liferay\ \ Home{]}/tools/portal-tools-db-upgrade-client}
folder.

\noindent\hrulefill

It's time to upgrade your core data using the upgrade tool.

\section{Running and Managing the Core
Upgrade}\label{running-and-managing-the-core-upgrade}

Start the upgrade tool, as the previous section explains. Here are the
core upgrade stages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show the upgrade patch level
\item
  Execute the core upgrade processes
\item
  Execute the core verifiers
\end{enumerate}

Monitor the upgrade via the upgrade tool log file (default file is
\texttt{upgrade.log}). If a core upgrade process fails, analyze the
failure and resolve it. If a core upgrade step for Liferay DXP 7.1 (or
newer) fails, executing the upgrade tool again starts it from that step.

If you configured the upgrade tool to upgrade non-core modules, the tool
opens a Gogo shell and starts upgrading them. The Gogo shell lets you
upgrade modules, check module upgrade status, verify upgrades, and
restart module upgrades. Read on to learn how to use Gogo shell commands
to complete Liferay DXP upgrades.

\chapter{Upgrading Modules Using Gogo
Shell}\label{upgrading-modules-using-gogo-shell}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay's Gogo shell can upgrade and verify individual modules. It's a
fine-grained approach to upgrading the core and non-core modules. If you
haven't already upgraded your non-core modules using the upgrade tool or
if there are modules you need to revisit upgrading, you can upgrade them
using Gogo Shell.

\noindent\hrulefill

\textbf{Note}: You must
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-data-upgrade}{Configure
the core upgrade} before using Gogo shell commands to upgrade the core.

\noindent\hrulefill

Below is a list of commands.

\section{Command Usage}\label{command-usage}

If you ran the upgrade tool and it opened Gogo shell, you're already
connected. Otherwise, you can execute commands using the
\href{/docs/7-2/customization/-/knowledge_base/c/using-the-felix-gogo-shell}{Gogo
Shell portlet}.

Here are the commands:

\texttt{exit} or \texttt{quit:} Exits the Gogo shell

\texttt{upgrade:help:} Displays upgrade commands

\texttt{upgrade:check:} Lists upgrades pending execution because they
failed in the past or the module hasn't reached its final version

\texttt{upgrade:execute\ \{module\_name\}:} Executes upgrades for that
module

\texttt{upgrade:executeAll:} Executes all pending module upgrade
processes

\texttt{upgrade:list:} Lists all registered upgrades

\texttt{upgrade:list\ \{module\_name\}:} Lists the module's required
upgrade steps

\texttt{upgrade:list\ \textbar{}\ grep\ Registered:} Lists registered
upgrades and their versions

\texttt{verify:help:} Displays verify commands

\texttt{verify:check\ \{module\_name\}:} Lists the latest execution
result for the module's verify process

\texttt{verify:checkAll:} Lists the latest execution results for all
verify processes

\texttt{verify:execute\ \{module\_name\}:} Executes the module's
verifier

\texttt{verify:executeAll:} Executes all verifiers

\texttt{verify:list:} Lists all registered verifiers

There are many useful
\href{/docs/7-2/customization/-/knowledge_base/c/using-the-felix-gogo-shell}{Liferay
commands and standard commands available in Gogo shell}. The following
sections describe Liferay upgrade commands.

\section{Listing module upgrade
processes}\label{listing-module-upgrade-processes}

Before upgrading modules, you should find which have unresolved
dependencies, which are resolved and available to upgrade, and examine
the module upgrade processes.

Executing \texttt{upgrade:list} in the Gogo shell lists the modules
whose upgrade dependencies are satisfied. These modules can be upgraded.

If a module is active but not listed, its dependencies must be upgraded.
The Gogo shell command
\texttt{scr:info\ {[}upgrade\_step\_class\_qualified\_name{]}} shows the
upgrade step class's unsatisfied dependencies. Here's an example
\texttt{scr:info} command:

\begin{verbatim}
scr:info com.liferay.journal.upgrade.JournalServiceUpgrade
\end{verbatim}

Invoking \texttt{upgrade:list\ {[}module\_name{]}} lists the module's
upgrade processes, in no particular order. For example, executing
\texttt{upgrade:list\ com.liferay.bookmarks.service} (for the Bookmarks
Service module), lists this:

\begin{verbatim}
Registered upgrade processes for com.liferay.bookmarks.service 1.0.0
        {fromSchemaVersionString=0.0.0, toSchemaVersionString=1.0.0, upgradeStep=com.liferay.portal.spring.extender.internal.context.ModuleApplicationContextExtender$ModuleApplicationContextExtension$1@6e9691da}
        {fromSchemaVersionString=0.0.1, toSchemaVersionString=1.0.0-step-3, upgradeStep=com.liferay.bookmarks.upgrade.v1_0_0.UpgradePortletId@5f41b7ee}
        {fromSchemaVersionString=1.0.0-step-1, toSchemaVersionString=1.0.0, upgradeStep=com.liferay.bookmarks.upgrade.v1_0_0.UpgradePortletSettings@53929b1d}
        {fromSchemaVersionString=1.0.0-step-2, toSchemaVersionString=1.0.0-step-1, upgradeStep=com.liferay.bookmarks.upgrade.v1_0_0.UpgradeLastPublishDate@3e05b7c8}
        {fromSchemaVersionString=1.0.0-step-3, toSchemaVersionString=1.0.0-step-2, upgradeStep=com.liferay.bookmarks.upgrade.v1_0_0.UpgradeClassNames@6964cb47}
\end{verbatim}

An application's upgrade step class names typically reveal their
intention. For example, the example's
\texttt{com.liferay.bookmarks.upgrade.v1\_0\_0.UpgradePortletId} upgrade
step class updates the app's portlet ID. The other example upgrade step
classes update class names, the \texttt{LastPublishDate}, and
\texttt{PortletSettings}. The example's step from \texttt{0.0.0} to
\texttt{1.0.0} upgrades the module from an empty database.

To examine a module's upgrade process better, you can sort the listed
upgrade steps mentally or in a text editor. Here's the upgrade step
order for a Bookmarks Service module to be upgraded from Liferay Portal
6.2 (the module's database exists) to schema version \texttt{1.0.0}:

\begin{itemize}
\tightlist
\item
  \texttt{0.0.1} to \texttt{1.0.0-step-3}
\item
  \texttt{0.0.1-step-3} to \texttt{1.0.0-step-2}
\item
  \texttt{0.0.1-step-2} to \texttt{1.0.0-step-1}
\item
  \texttt{0.0.1-step-1} to \texttt{1.0.0}
\end{itemize}

The overall module upgrade process starts at version \texttt{0.0.1} and
finishes at version \texttt{1.0.0}. The first step starts on the initial
version (\texttt{0.0.1}) and finishes on the target version's highest
step (\texttt{step-3}). The last step starts on the target version's
lowest step (\texttt{step-1}) and finishes on the target version
(\texttt{1.0.0}).

Once you understand the module's upgrade process, you can execute it
with confidence.

\section{Executing module upgrades}\label{executing-module-upgrades}

Executing \texttt{upgrade:execute\ {[}module\_name{]}} upgrades the
module. You might run into upgrade errors that you must resolve.
Executing the command again starts the upgrade from the last successful
step.

You can check upgrade status by executing
\texttt{upgrade:list\ {[}module\_name{]}}. For example, entering
\texttt{upgrade:list\ com.liferay.iframe.web} outputs this:

\begin{verbatim}
Registered upgrade processes for com.liferay.iframe.web 0.0.1
   {fromSchemaVersionString=0.0.1, toSchemaVersionString=1.0.0, upgradeStep=com.liferay.iframe.web.upgrade.IFrameWebUpgrade$1@1537752d}
\end{verbatim}

The first line lists the module's name and current version. The example
module's current version is \texttt{0.0.1}. The
\texttt{toSchemaVersionString} value is the target version.

Executing \texttt{upgrade:list\ {[}module\_name{]}} on the module after
successfully upgrading it shows the module's name followed by the
version you targeted.

For example, if you successfully upgraded
\texttt{com.liferay.iframe.web} to version \texttt{1.0.0}, executing
\texttt{upgrade:list\ com.liferay.iframe.web} shows the module's version
is \texttt{1.0.0}:

\begin{verbatim}
Registered upgrade processes for com.liferay.iframe.web 1.0.0
   {fromSchemaVersionString=0.0.1, toSchemaVersionString=1.0.0, upgradeStep=com.liferay.iframe.web.upgrade.IFrameWebUpgrade$1@1537752d}
\end{verbatim}

For module upgrades that don't complete, you can check their status and
resolve their issues.

\section{Checking upgrade status}\label{checking-upgrade-status}

The command \texttt{upgrade:check} lists modules that have impending
upgrades.

For example, if module \texttt{com.liferay.dynamic.data.mapping.service}
failed in a step labeled \texttt{1.0.0-step-2}, executing
\texttt{upgrade:check} shows this:

\begin{verbatim}
Would upgrade com.liferay.dynamic.data.mapping.service from 1.0.0-step-2 to
1.0.0 and its dependent modules
\end{verbatim}

Modules often depend on other modules to complete upgrading. Executing
\texttt{scr:info\ {[}upgrade\_step\_class\_qualified\_name{]}} shows the
upgrade step class's dependencies. You must upgrade modules on which
your module depends.

To resolve and activate a module, its upgrade must complete. The
\href{http://felix.apache.org/documentation/subprojects/apache-felix-dependency-manager/tutorials/leveraging-the-shell.html}{Apache
Felix Dependency Manager} Gogo shell command \texttt{dm\ wtf} reveals
unresolved dependencies. If your module requires a certain data schema
version (e.g., its \texttt{bnd.bnd} specifies
\texttt{Liferay-Require-SchemaVersion:\ 1.0.2}) but the module hasn't
completed upgrade to that version, \texttt{dm\ wtf} shows that the
schema version is not registered.

\begin{verbatim}
1 missing dependencies found.
-------------------------------------
The following service(s) are missing:
 * com.liferay.portal.kernel.model.Release (&(release.bundle.symbolic.name=com.liferay.journal.service)(release.schema.version=1.0.2)) is not found in the service registry
\end{verbatim}

The \texttt{dm\ wtf} command can also help detect errors in portlet
definitions and custom portlet \texttt{schemaVersion} fields.

Browsing the Liferay DXP database \texttt{Release\_} table can help you
determine a module's upgrade status too. The core's
\texttt{servletContextName} field value is \texttt{portal}. If the
core's \texttt{schemaVersion} field matches your new Liferay DXP version
(e.g., \texttt{7.2.1} for Liferay Portal CE GA2) and the
\texttt{verified} field is \texttt{1} (true), the core upgrade completed
successfully.

Each module has one \texttt{Release\_} table record, and the value for
its \texttt{schemaVersion} field must be \texttt{1.0.0} or greater
(\texttt{1.0.0} is the initial version for 7.0 modules, except for those
that were previously traditional plugins intended for Liferay Portal
version 6.2 or earlier).

\section{Executing verify processes}\label{executing-verify-processes}

Some modules have verify processes. These make sure the upgrade executed
successfully. Verify processes in the core are automatically executed
after upgrading Liferay DXP. You can also execute them by configuring
the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Verify}{\texttt{verify.*}
portal properties} and restarting your server.

To check for available verify processes, enter the Gogo shell command
\texttt{verify:list}. To run a verify process, enter
\texttt{verify:execute\ {[}verify\_qualified\_name{]}}.

\chapter{Executing Post-Upgrade
Tasks}\label{executing-post-upgrade-tasks}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Since you optimized your system for upgrading, after the upgrade is
complete you must re-optimize it for production.

\section{Tuning Your Database for
Production}\label{tuning-your-database-for-production}

Prior to upgrading your Liferay DXP database, you tuned it for upgrade.
Now that upgrade is complete, restore the production database tuning you
used previously.

\section{Re-enabling Search Indexing and Re-indexing Search
Indexes}\label{re-enabling-search-indexing-and-re-indexing-search-indexes}

Make sure to re-enable search indexing by removing the
\texttt{com.liferay.portal.search.configuration.IndexStatusManagerConfiguration.config}
file from your \texttt{{[}Liferay\ Home{]}/osgi/configs} folder or
setting this property in it:

\begin{verbatim}
indexReadOnly="false"
\end{verbatim}

Then re-index Liferay DXP's search indexes. Don't just do this blindly,
however. By default, Liferay DXP ships with an embedded configuration
for Elasticsearch. This configuration works great for demo purposes, but
is not supported in production. Make sure to
\href{/docs/7-2/deploy/-/knowledge_base/d/installing-elasticsearch}{install
and configure a standalone Elasticsearch instance to run in production}.

\section{Enabling Web Content View
Permissions}\label{enabling-web-content-view-permissions}

Prior to Liferay DXP 7.1, all users could view web content articles by
default. Now view permissions are checked by default. Here are options
for opening view permissions:

Option 1: Edit view permissions per web content article per role.

Option 2: Open view permissions for all web content articles by going to
\emph{System Settings → Web Experience → Web Content} and deselecting
\emph{Article view permissions check enabled}.

Once you've configured search, re-indexed your search index, and set web
content view permissions, your upgraded system is ready for action!
Congratulations!

\chapter{Upgrading a Sharded
Environment}\label{upgrading-a-sharded-environment}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Since Liferay DXP 7.0, Liferay removed its own physical partitioning
implementation (also known as sharding) in favor of the capabilities
provided natively by database vendors. Upgrading a sharded installation
to DXP 7.0 or higher requires migrating it to as many non-sharded
Liferay DXP installations (servers) as you have shards. These steps
guide you through configuring the new Liferay DXP servers to use your
formerly sharded data.

\noindent\hrulefill

\textbf{Note:} Liferay continues to support its logical partitioning
capabilities (also known as
\href{/docs/7-2/user/-/knowledge_base/u/setting-up-a-virtual-instance}{virtual
instances}) for the foreseeable future.

\noindent\hrulefill

\noindent\hrulefill

For any further assistance with sharding contact your Liferay account
manager or Liferay Support.

\noindent\hrulefill

\section{Add Configurations Before the Data
Upgrade}\label{add-configurations-before-the-data-upgrade}

In addition to other configurations, you will need to set more
properties to migrate your shards to virtual instances for your data
upgrade.

Here is how to configure the upgrade to migrate from sharding:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Copy all of the shard JDBC connection properties from
  \texttt{portal-ext.properties}
  to\texttt{portal-upgrade-database.properties}. For example, JDBC
  connections for a default shard and two non-default shards might look
  like this:

\begin{verbatim}
jdbc.default.driverClassName=[the database driver class name]
jdbc.default.url=[the URL to the default database shard]
jdbc.default.username=[the user name]
jdbc.default.password=[the password]

jdbc.one.driverClassName=[the database driver class name]
jdbc.one.url=[the URL to database shard one]
jdbc.one.username=[the user name]
jdbc.one.password=[the password]

jdbc.two.driverClassName=[the database driver class name]
jdbc.two.url=[the URL to database shard two]
jdbc.two.username=[the user name]
jdbc.two.password=[the password]
\end{verbatim}
\item
  Set the JDBC \emph{default} connection properties in each server's
  \texttt{portal-upgrade-database.properties} to specify the associated
  shard.

  \begin{itemize}
  \tightlist
  \item
    Add the original JDBC properties for the respective non-default
    shard database. For example, shard \texttt{one}'s original
    properties might start with \texttt{jdbc.one}:
  \end{itemize}

\begin{verbatim}
jdbc.one.driverClassName=[the database driver class name]
jdbc.one.url=[the URL to database shard one]
jdbc.one.username=[the user name]
jdbc.one.password=[the password]
\end{verbatim}

  \begin{itemize}
  \tightlist
  \item
    Rename the properties to start with \texttt{jdbc.default}. For
    example:
  \end{itemize}

\begin{verbatim}
jdbc.default.driverClassName=[the database driver class name]
jdbc.default.url=[the URL to database shard one]
jdbc.default.username=[the user name]
jdbc.default.password=[the password]
\end{verbatim}
\end{enumerate}

\section{Upgrade and Update
Properties}\label{upgrade-and-update-properties}

When you perform the database upgrade, upgrade the default shard first,
and then each of the non-default shards. See
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-product-data}{Using
the Database Upgrade Tool} for more information on running the database
upgrade.

After the database upgrade has been completed, make the following
configuration changes to your application servers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In each server's \texttt{portal-ext.properties}, use the JDBC
  \emph{default} properties you specified in the
  \texttt{portal-upgrade-database.properties} (see the \emph{default}
  properties above).
\item
  Remove the non-default shard JDBC properties from the default shard
  server's \texttt{portal-ext.properties} file, leaving only the default
  shard database \texttt{jdbc.default} properties. For example:

  Old JDBC properties:

\begin{verbatim}
jdbc.default.driverClassName=[the database driver class name]
jdbc.default.url=[the URL to the default database shard]
jdbc.default.username=[the user name]
jdbc.default.password=[the password]

jdbc.one.driverClassName=[the database driver class name]
jdbc.one.url=[the URL to database shard one]
jdbc.one.username=[the user name]
jdbc.one.password=[the password]

jdbc.two.driverClassName=[the database driver class name]
jdbc.two.url=[the URL to database shard two]
jdbc.two.username=[the user name]
jdbc.two.password=v[the password]
\end{verbatim}

  New JDBC properties:

\begin{verbatim}
jdbc.default.driverClassName=[the database driver class name]
jdbc.default.url=[the URL to your database]
jdbc.default.username=[the user name]
jdbc.default.password=[the password]
\end{verbatim}
\end{enumerate}

Once you have completed all of these steps, you have migrated off of a
sharded environment to virtual instances on separate Liferay DXP servers
together with your DXP upgrade.

Congratulations! You have migrated off of a sharded environment to
virtual instances on separate Liferay DXP servers. You have also
upgraded to 7.0. Your virtual instances are ready for action.

\chapter{Migrating From Audience Targeting to Segmentation and
Personalization}\label{migrating-from-audience-targeting-to-segmentation-and-personalization}

7.0 integrates all the Audience Targeting app's features into Liferay's
core as Segmentation and Personalization. This enables better
integration with other applications and provides developers with easier
access to Segmentation and Personalization features. Audience Targeting
users must migrate their user segments into the new Segments
application. There are three steps to the migration process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Upgrade to 7.0.
\item
  Migrate custom rules.
\item
  Migrate behavior-based features.
\end{enumerate}

First, to upgrade to the latest version of Liferay DXP, follow the
\href{/docs/7-2/tutorials/-/knowledge_base/t/upgrading-code-to-product-ver}{upgrade
guide}. Most of your Audience Targeting configuration is automatically
transferred into the new engine.

Next, any custom rules that were created in Audience Targeting must be
re-evaluated. Some custom rules may have an out-of-the-box equivalent
now, while others must be migrated. If a rule must be re-implemented,
follow the
\href{/docs/7-2/frameworks/-/knowledge_base/f/segmentation-personalization}{Segmentation
and Personalization development guide}. You can check
\href{/docs/7-2/deploy/-/knowledge_base/d/migrating-user-segments}{the
list of rules that are automatically migrated} to see how much
additional work you have in store. You must also
\href{/docs/7-2/deploy/-/knowledge_base/d/manually-migrating-from-audience-targeting}{migrate
display widgets} since the new Personalization features use different
tools.

Finally, you must migrate behavior-based features, but since Audience
Targeting's analytics features are now part of Analytics Cloud, there
isn't a direct path to upgrade. See the
\href{https://help.liferay.com/hc/en-us/articles/360006947671-Creating-Segments}{Analytics
Cloud documentation}.

\chapter{Migrating User Segments}\label{migrating-user-segments}

In Audience Targeting, a user segment represents a subset of users. A
user segment is defined by one or more rules that users must match to
belong to that user segment. In 7.0, segments work in a similar way, but
they are defined by criteria instead of rules. Segment criteria are sets
of fields defined by different user actions or properties (profile
information, organization information, session information) that can be
combined through operations (like equals, not equals, contains, not
contains, greater than, and less than) and conjunctions (AND, OR) to
define complex filters.

Due to the similarities between Audience Targeting user segments and 7.0
Segments, certain data can be migrated automatically as part of the
upgrade process.

\section{Upgrade Process}\label{upgrade-process}

As a result of the upgrade process,

\begin{itemize}
\tightlist
\item
  All Audience Targeting User Segments appear under the new Segments
  administration in 7.2, with the same name.
\item
  For every segment, those Audience Targeting rules with an equivalent
  in Liferay DXP 7.2 have been migrated into the corresponding criteria
  fields (see Table below).
\item
  Audience Targeting tables have been removed from your Liferay DXP
  Database.
\end{itemize}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Audience Targeting Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Liferay DXP 7.2. Segment Criteria Field
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Upgrade Path
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Browser & Browser & Automated. Use user agent field with
\texttt{contains} operation as an alternative \\
Custom Field & Custom Field & Automated \\
Language & Language & Automated \\
Last Login Date & Last Sign In Date & Automated \\
Organization Member & Organization & Automated \\
OS & User Agent & Automated \\
Previous Visited Site & Not Available & Automated \\
Regular Role & Role & Automated \\
Site Member & Site & Automated \\
User Group Member & User Group & Automated \\
Age & Not Available & Suggested: custom field \\
Facebook (various) & Not Available & Suggested: custom field \\
Gender & Not Available & Suggested: custom field \\
Score Points & Not Available & Suggested: cookie \\
Visited Page/Content & Not Available & Suggested: cookie \\
\end{longtable}

\noindent\hrulefill

Here's an example user segment as it would appear in Audience Targeting
for Liferay DXP 7.1:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/migrating-audience-targeting-segment.png}}
\caption{A Liferay DXP 7.1 Audience Targeting Segment.}
\end{figure}

And here is the same segment migrated to Liferay 7.2:

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/migrating-new-segment.png}}
\caption{A Liferay DXP 7.2 Segment}
\end{figure}

For those Audience Targeting rules without a direct equivalent, a manual
migration is required. If you have any these rules, you can learn about
your next steps in
\href{/docs/7-2/deploy/-/knowledge_base/d/manually-migrating-from-audience-targeting}{Manual
Migration}.

\chapter{Manually Migrating from Audience
Targeting}\label{manually-migrating-from-audience-targeting}

As explained in the previous article, some Audience Targeting rules do
not have a direct equivalent in Liferay DXP 7.2 and, therefore, they
cannot be migrated automatically. Here are the recommended solutions for
each rule type.

\section{User Attribute Rules}\label{user-attribute-rules}

Some User Attributes, like Gender or Age, do not have a direct
equivalent in 7.0. User Attributes retrieved from external sources like
Facebook also do not have a replacement. To replace these, you must
create a
\href{/docs/7-2/user/-/knowledge_base/u/creating-segments-with-custom-fields-and-session-data}{custom
user field} and use that to define your new Segment.

\section{Session Rules}\label{session-rules}

For Session attributes that do not have a direct equivalent, the
recommended solution is to use a URL field for the current URL or a
previously visited URL on your site as criteria, or to use a Cookie for
more advanced session tracking needs.

\section{Behavior Rules}\label{behavior-rules}

In 7.0 analytics is now managed through Analytics Cloud. You can learn
more about creating behavior based rules in the
\href{https://help.liferay.com/hc/en-us/articles/360006947671-Creating-Segments}{Analytics
Cloud documentation}.

\section{Migrating Custom Rules}\label{migrating-custom-rules}

Audience Targeting segmentation features could be extended using custom
rules. As part of the upgrade planning process, the function of any such
rules should be re-evaluated with the new Segmentation features of 7.0
in mind.

First, check the
\href{/docs/7-2/reference/-/knowledge_base/r/defining-segmentation-criteria}{Segmentation
reference} if any new criteria fields can replace their function. In
particular, custom fields, URL fields, and cookies might help you
migrate your custom rules with little to no additional development.

If none of them cover your requirements, follow the development guide
for instructions on
\href{/docs/7-2/frameworks/-/knowledge_base/f/segmentation-personalization}{how
to add new criteria fields and contributors}.

\section{Migrating Display Portlets}\label{migrating-display-portlets}

With Audience Targeting, you could display personalized content with the
User Segment Display Content portlet or by using Asset Publisher with
the
\href{https://help.liferay.com/hc/en-us/articles/360018174271-Using-the-Audience-Targeting-Widgets-}{Segments
filter enabled}. In 7.0, you must choose the most appropriate
personalization option for your use cases.

\section{User Segment Content
Display}\label{user-segment-content-display}

The User Segment Content Display portlet was used to display existing
content based on segment membership rules. In 7.0, you can cover the
same use case by defining manual content sets with variations for your
different audiences and applying it to an asset publisher. See the
documentation for
\href{/docs/7-2/user/-/knowledge_base/u/content-set-personalization}{creating
personalized Content Sets}. With this feature, you can assign any number
of assets to the Content List for the given audience, and then use the
Asset Publisher to define how content is displayed on the page.

\section{Asset Publisher
Personalization}\label{asset-publisher-personalization}

Finally, if you want to display a dynamic list of content for your
different audiences based on a filter in the same way you did with in
Audience Targeting with the Segments filter in the Asset Publisher, you
can create a dynamic content set with variations for your audiences and
apply it to an asset publisher.

In addition, the new
\href{/docs/7-2/user/-/knowledge_base/u/content-page-personalization}{Experience-based
Content Page personalization} feature may fulfill a use case that you
were previously solving with one of the methods previously available.

\chapter{Deprecated Apps in 7.2: What to
Do}\label{deprecated-apps-in-7.2-what-to-do}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

During the development of any software product, it's sometimes necessary
to stop development on or remove outdated or unpopular features. 7.0 is
no different. In 7.0, Liferay has deprecated several apps and features.

There are three types of deprecated apps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Deprecated apps that remain in Liferay DXP, but will be removed in a
  future release. (Availability: \emph{Bundled})
\item
  Deprecated apps that have been removed from Liferay DXP, yet are still
  available for download via
  \href{https://web.liferay.com/marketplace}{Liferay Marketplace}
  (Availability: \emph{Marketplace})
\item
  Deprecated apps that have been removed from Liferay DXP and aren't
  available for download. (Availability: \emph{Removed})
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} All apps deprecated by Liferay are no longer in active
development. You should therefore plan to stop using these apps. Such
apps, however, may still be available for download.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} For information on apps deprecated in Liferay DXP 7.1,
please see
\href{/docs/7-1/deploy/-/knowledge_base/d/deprecated-apps-in-7-1-what-to-do}{Deprecated
Apps in 7.1: What to Do}

\noindent\hrulefill

Here are the apps deprecated in 7.0.

\section{Foundation}\label{foundation}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1364}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2727}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
App
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Availability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
AlloyUI & Bundled & Replaced by \href{https://metaljs.com/}{MetalJS}
(temporary) exposed as
\href{/docs/7-2/reference/-/knowledge_base/r/front-end-taglibs}{ClayUI
tag} equivalents. \\
CMIS Store & Removed & Migrate to another
\href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{Document
Repository Store option}. Before
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-product-ver}{upgrading
to 7.0}, migrate your document store data using
\href{/docs/7-2/user/-/knowledge_base/u/server-administration}{Data
Migration in Server Administration}. \\
JCRStore & Removed & Migrate to another
\href{/docs/7-2/deploy/-/knowledge_base/d/document-repository-configuration}{Document
Repository Store option}. Before
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-product-ver}{upgrading
to 7.0}, migrate your document store data using
\href{/docs/7-2/user/-/knowledge_base/u/server-administration}{Data
Migration in Server Administration}. \\
Legacy Search Portlet & Bundled & Will be removed in a future release.
Replaced by the \href{/docs/7-2/user/-/knowledge_base/u/search}{Search
widgets}. \\
Liferay Mobile Device Detection Enterprise & Removed & Contact 51Degrees
for up-to-date definitions. \\
Sprite framework & Bundled & Liferay's image sprite framework is
deprecated and is disabled by default via the \texttt{sprite.enabled}
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{portal
property}. You can still build image sprites using any framework you
like and deploy them in your plugins. \\
\end{longtable}

\noindent\hrulefill

\section{Personalization}\label{personalization}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1364}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2727}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
App
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Availability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Audience Targeting & Removed & Replaced by
\href{/docs/7-2/user/-/knowledge_base/u/segmentation-and-personalization}{Personalization}. \\
\end{longtable}

\noindent\hrulefill

\section{Web Experience}\label{web-experience}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1364}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2727}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
App
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Availability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
RSS Publisher & Bundled & See
\href{/docs/7-1/user/-/knowledge_base/u/the-rss-publisher-widget}{the
article} on enabling and using this widget. \\
User Group Pages (Copy Mode) & Bundled & See the
\href{/docs/7-1/user/-/knowledge_base/u/user-group-sites\#legacy-user-group-sites-behavior}{Legacy
User Group Sites Beahavior} instructions on how to enable it. \\
Resources Importer & Bundled & Deprecated as of 7.1 with no direct
replacement \\
\end{longtable}

\noindent\hrulefill

\section{Forms}\label{forms}

\noindent\hrulefill

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
App & Availability & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Web Form & Removed & Final version released for 7.0. \\
\end{longtable}

\noindent\hrulefill

\section{Security}\label{security-1}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0938}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3438}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
App
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Availability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Central Authentication Service (CAS) & Bundled & Migrate to
\href{https://help.liferay.com/hc/en-us/articles/360028711032-Introduction-to-Authenticating-Using-SAML}{SAML
based authentication}. \\
Google Login & Marketplace & Replaced by
\href{/docs/7-2/deploy/-/knowledge_base/d/authenticating-with-openid-connect}{OpenID
Connect}. \\
NTLM & Marketplace & Replaced by
\href{/docs/7-2/deploy/-/knowledge_base/d/authenticating-with-kerberos}{Kerberos}. \\
OpenAM / OpenSSO & Bundled & Migrate to
\href{https://help.liferay.com/hc/en-us/articles/360028711032-Introduction-to-Authenticating-Using-SAML}{SAML
based authentication}. \\
OpenID & Marketplace & Replaced by
\href{/docs/7-2/deploy/-/knowledge_base/d/authenticating-with-openid-connect}{OpenID
Connect}. \\
\end{longtable}

\noindent\hrulefill

\section{User and System Management}\label{user-and-system-management}

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.8571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
App
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Availability
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Live Users & Enabled through the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html}{\texttt{live.users.enabled}}
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{portal
property}. \\
\end{longtable}

\noindent\hrulefill

\section{Related Topics}\label{related-topics-7}

\href{/docs/7-2/deploy/-/knowledge_base/d/apps-in-maintenance-mode}{Apps
in Maintenance Mode}

\chapter{Apps in Maintenance Mode}\label{apps-in-maintenance-mode}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

At a designated time, Liferay may cease enhancing a product or
capability. This is called \emph{maintenance mode}. During this mode,
Liferay actively supports and provides bug fixes for the product or
capability in accordance with the subscribers' subscription level and
the end of service life policies of the compatible Liferay DXP version.
Maintenance mode does not necessarily mean that deprecation in a future
Liferay DXP version is planned for the product or capability; it only
means that enhancements aren't being made for the current Liferay DXP
development cycle.

As of Liferay DXP 7.2, these products and capabilities have transitioned
into maintenance mode:

\begin{itemize}
\tightlist
\item
  Liferay Connected Services
\item
  Liferay Connector to OAuth 1.0a
\item
  Liferay Drools
\item
  Liferay Mobile Experience (Liferay Screens, Liferay Mobile SDK,
  Liferay Push)
\item
  Liferay Reports
\item
  Liferay Sync
\item
  Staging
\end{itemize}

\section{Related Topics}\label{related-topics-8}

\href{/docs/7-2/deploy/-/knowledge_base/d/deprecated-apps-in-7-2-what-to-do}{Deprecated
Apps in 7.2: What to do?}

\chapter{Maintaining Liferay DXP}\label{maintaining-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Once you have a Liferay DXP installation, there are some things you must
do to keep it running smoothly. Backing up your installation in case of
a hardware failure protects your data and helps you get your system back
in working order quickly. And if you're a DXP customer, patching your
system regularly brings the latest bug fixes to your running instance.

\noindent\hrulefill

Upgrading 7.0 to a new GA version can require
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-product-ver}{data
upgrade}. Until you perform all required data upgrades (if any), Liferay
DXP startup fails with messages like these:

\begin{verbatim}
2019-03-06 17:22:35.025 INFO  [main][StartupHelper:72] There are no patches installed
You must first upgrade to Liferay DXP 7210
2019-03-06 17:22:35.098 ERROR [main][MainServlet:277] java.lang.RuntimeException: You must first upgrade to Liferay DXP 7201
\end{verbatim}

\noindent\hrulefill

Read on to learn about how to keep your system running well.

\chapter{Patching Liferay DXP}\label{patching-liferay-dxp}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

While we strive for perfection with every Liferay DXP release, the
reality of the human condition dictates that releases may not be as
perfect as originally intended. But we've planned for that. Included
with every Liferay DXP bundle is a Patching Tool that handles installing
two types of patches: fix packs and hotfixes.

\noindent\hrulefill

\textbf{Important:} Make sure to
\href{/docs/7-2/deploy/-/knowledge_base/d/backing-up-a-liferay-installation}{back
up your Liferay DXP installation and database} regularly, especially
before patching. The patching tool installs code changes and some of
these make data changes (if necessary) automatically on startup.

Certain fix packs (service packs) can include data/schema micro
changes---they're optional and revertible. Module upgrades and any micro
changes they include are applied at server startup by default, or can be
applied manually by
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-data-upgrade\#configuring-non-core-module-data-upgrades}{disabling
the \texttt{autoUpgrade} property}. Server startup skips all Core micro
changes. Instead, you can apply them using the
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-product-ver}{upgrade
tool} before server startup.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Important:} Installing the latest service pack on top of Liferay
DXP 7.2 GA1/FP1 requires running the
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-the-product-data}{data
upgrade tool}. Examine the
\href{/docs/7-2/deploy/-/knowledge_base/d/upgrading-to-product-ver}{Liferay
DXP upgrade instructions} to determine preparations, testing, and post
upgrade steps that are appropriate for you. To eliminate system down
time during upgrade, consider using the
\href{/docs/7-2/deploy/-/knowledge_base/d/other-cluster-update-techniques}{Blue-green
deployment technique}.

Liferay DXP 7.2 FP2/SP1's data schema change adds version columns to
several tables.
\href{https://docs.jboss.org/hibernate/orm/4.0/devguide/en-US/html/ch05.html\#d0e2225}{Hibernate's
optimistic locking system} uses the columns to preserve data integrity
during concurrent data modifications.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:}
\href{/docs/7-2/deploy/-/knowledge_base/d/updating-a-cluster}{Patching a
cluster} requires additional considerations.

\chapter{Patching Basics}\label{patching-basics}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Liferay ships 7.0 fixes through three different channels:

\begin{itemize}
\tightlist
\item
  Fix packs
\item
  Hotfixes
\item
  Service Packs
\end{itemize}

\section{Fix Packs}\label{fix-packs}

The latest fixes that patch the core are bundled together weekly into
fix packs that are provided to all of Liferay's customers. Fix packs
include fixes for both the core and the applications and modules that
ship with Liferay DXP. The fixes address regressions or obvious bugs and
don't require you to make additional changes. Each fix pack contains all
previous fix packs since the last service pack.

\href{https://help.liferay.com/hc/en-us/articles/360035038331}{Security
Fix Packs} are a special fix pack type for deploying critical security
fixes quickly without changing fix pack levels.

Fixes that don't fit these requirements are considered for service packs
or hot fixes.

\section{Hotfixes}\label{hotfixes}

A hotfix is provided to customers when they contact Liferay about an
emergency situation, and Liferay's support team---working with the
customer---determines that the problem is a product issue that must be
fixed very quickly. Support fixes the bug and provides a hotfix to the
customer immediately. This is a short-term fix. Hotfixes can patch the
core, the applications, and modules.

\section{Service Packs}\label{service-packs}

Service packs are built on top of the original Liferay DXP release and
repackaged with the latest fix pack, Patching Tool, and modules. Since a
service pack is a fix pack, it contains all previous fix packs since the
last service pack. Each one includes the most recent patches and
updates.

Service packs can also include changes that have these characteristics:

\begin{itemize}
\tightlist
\item
  Require more extensive testing.
\item
  Require some of your attention, such as updating your documentation.
\item
  Improve the product.
\end{itemize}

Rather than updating existing Liferay DXP systems with service packs,
you should

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Keep systems up-to-date with fix packs (according to your own
  deployment schedule).
\item
  Install the latest Marketplace updates frequently.
\item
  Update the Patching Tool when necessary.
\end{enumerate}

This method updates the installation to the service pack levels, while
allowing scheduled deployments and avoiding full environment rebuilds.

\section{How Patches are Tested}\label{how-patches-are-tested}

Liferay extensively tests service packs, fix packs, and hotfixes to
ensure high quality. Fixes in fix packs go through both automated
regression testing and manual testing. Hotfixes receive similar
automated testing, and the support engineer who fixes a reported issue
tests it.

Before releasing a service pack, Liferay runs test suites on the
packaged service pack.

\chapter{Using the Patching Tool}\label{using-the-patching-tool}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The Patching Tool installs, removes, compares, and prepares Liferay DXP
patches. It is pre-installed in Liferay DXP bundles, easy to install
into @product@ manual installations, and easy to update. The Patching
Tool's executable scripts facilitate patching.

Here are the essentials to get started using the Patching Tool:

\begin{itemize}
\tightlist
\item
  \hyperref[installing-the-patching-tool]{Installing the Patching Tool}
  (for manual installations only)
\item
  \hyperref[executables]{Executables}
\end{itemize}

\section{Installing the Patching
Tool}\label{installing-the-patching-tool}

Liferay DXP bundles come with the Patching Tool pre-installed (in
\texttt{{[}Liferay\ Home{]}/patching-tool}) and pre-configured with the
default settings. Skip this section if you're using a bundle.

If you installed Liferay DXP manually, however, you must also install
the Patching Tool manually.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Download the Patching Tool from the
  \href{https://customer.liferay.com/downloads?p_p_id=com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_productAssetCategoryId=118191019&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_fileTypeAssetCategoryId=118191066}{Customer
  Portal}.
\item
  Unzip the Patching Tool to your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder (recommended) or to another folder.
\end{enumerate}

After installing the Patching Tool, you must
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-patching-tool}{configure
it to use your Liferay DXP installation}. The \texttt{patching-tool}
folder you extracted from the Patching Tool ZIP file contains the
Patching Tool, including its executable scripts.

\section{Executables}\label{executables}

The Unix shell and Windows batch scripts distributed with the Patching
Tool make it easier to use. On Unix systems, run

\begin{verbatim}
./patching-tool.sh parameters
\end{verbatim}

On Windows, run

\begin{verbatim}
patching-tool parameters
\end{verbatim}

The Windows command \texttt{patching-tool} is used in the examples that
follow. On Unix, replace the name of the executable before running the
commands.

Installing patches is next!

\chapter{Installing Patches}\label{installing-patches}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Before installing any patches, you must shut down your server. On
Windows operating systems, files in use are locked by the OS, and can't
be patched. On Unix-style systems, you can usually replace files that
are running, but the old ones reside in memory. For these reasons, it is
best to shut down Liferay DXP before installing patches.

Liferay distributes all patches (fix packs and hotfixes) as ZIP files.
When you download a patch, either from a
\href{https://help.liferay.com/hc}{Help Center} ticket (hotfix) or from
the \href{https://customer.liferay.com/downloads}{Customer Portal} (fix
pack), place it in the Patching Tool's \texttt{patches} folder (e.g.,
\texttt{{[}Liferay\ Home{]}/patching-tool/patches}) without unzipping
it. To list your installed patches and available local patches, execute
this command:

\begin{verbatim}
patching-tool info
\end{verbatim}

This displays a list of patches you've already installed, along with a
list of patches that \emph{can} be installed from what's in the
\texttt{patches} folder.

To install the available patches, use the following steps. First, issue
the following command:

\begin{verbatim}
patching-tool install
\end{verbatim}

To make sure the all changed OSGi bundles replace the existing ones,
delete the \texttt{osgi/state} folder from the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home
folder}.

\noindent\hrulefill

\textbf{Note}: The \texttt{osgi/state} folder contains OSGi bundle state
information. If an OSGi bundle's changes in a hot fix or fix pack are
internal only, they are invisible to the OSGi framework, that OSGi
bundle stays installed, and its state information stays unchanged. Hot
fixes, for example, may contain in-place changes that do not use the
API. The framework cannot detect such changes. A fix pack's changes may
also be transparent to the framework. For these reasons, deleting the
\texttt{osgi/state} folder after applying fix packs and hot fixes is
recommended.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Important}: The \texttt{osgi/state} folder should ONLY be
deleted when working in a development environment or when applying a fix
pack or hot fix.

\noindent\hrulefill

If there are new database indexes created by the patch, the Patching
Tool tells you to update them. To get the list, run this command:

\begin{verbatim}
patching-tool index-info
\end{verbatim}

Since there's no database connection at patching time, the indexes must
be created at portal startup. If the server has permissions to modify
the database indexes, instruct Liferay DXP to create the indexes
automatically at startup by adding this setting to your
\texttt{portal-ext.properties} file:

\begin{verbatim}
database.indexes.update.on.startup=true
\end{verbatim}

Otherwise, you must create the indexes manually. Check the
\texttt{patching-tool\ index-info} command output for more details.

After installing patches, you can execute the
\texttt{patching-tool\ info} command to verify them.

\noindent\hrulefill

\textbf{Note:} If there are any issues with the installed patches,
verify that there aren't any remaining files from the previous patch
installation of a fix pack or hotfix within the application server
cache.

\noindent\hrulefill

During the installation, \texttt{patching-backup-deps.zip} and
\texttt{patching-backup.zip} files are created and stored in the web
application's \texttt{WEB-INF} folder. These files are required to
restore the Liferay DXP's original state; removing them disables
patching.

\noindent\hrulefill

\textbf{Note:} When installing patches, Liferay DXP's \texttt{web.xml}
is always overwritten by the one contained in the patch. If you've
customized \texttt{web.xml}, you must re-implement your customizations
after installing a patch.

\noindent\hrulefill

The \texttt{patching-backup.zip} file is necessary for installing future
patches, because the Patching Tool reverts the installed fix pack before
installing a new one. To revert the installed fix pack, it examines the
contents of the \texttt{patching-backup.zip} to determine the changes
that it needs to revert.

\section{Handling Hotfixes and
Patches}\label{handling-hotfixes-and-patches}

As stated previously, hotfixes are short term fixes provided as quickly
as possible, and fix packs are larger bundles of hotfixes provided to
all customers at regular intervals. If you already have a hotfix
installed and the fix pack that contains that hotfix is released, the
Patching Tool can manage this for you. Fix packs always supersede
hotfixes; so when you install your fix pack, the hotfix it contains is
uninstalled and the fix pack version is installed in its place.

The Patching Tool applies fixes to fix packs automatically. If a new
(fixed) version of a fix pack is released, install it with the Patching
Tool. The Patching Tool uninstalls the old fix pack and installs the new
version in its place.

\section{Fix Pack Dependencies}\label{fix-pack-dependencies}

Some hotfixes depend on fix packs. If you attempt to install a hotfix
that depends on a fix pack, the Patching Tool notifies you. Go to the
\href{hhttps://customer.liferay.com/downloads}{Customer Portal} and
obtain the hotfix dependency. Once all the necessary patches are
available in the \texttt{patches} folder, the Patching Tool installs
them.

\section{Updating the Patching Tool}\label{updating-the-patching-tool}

When a patch you're trying to install requires a Patching Tool update,
the Patching Tool tells you. To update the Patching Tool, download the
latest one from the
\href{https://customer.liferay.com/downloads?p_p_id=com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_productAssetCategoryId=118191019&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_fileTypeAssetCategoryId=118191066}{Customer
Portal}. Overwrite the existing Patching Tool by unzipping the new one
to the \texttt{patching-tool} folder's parent folder.

\section{Cleaning Up}\label{cleaning-up}

After you've performed your patching procedure (whether you've installed
or
\href{/docs/7-2/deploy/-/knowledge_base/d/working-with-patches\#uninstalling-patches}{removed
patches}), it's important to clean up Liferay DXP's cache of deployed
code. This ensures that you're using the revision you've just installed
the patches for when you start the server. This is really easy to do.

To clear out the cached code, remove the contents of the
\texttt{{[}Liferay\ Home{]}/work} folder. Now you're ready to start your
server.

\chapter{Working with Patches}\label{working-with-patches}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Here are some things you might need to do with patches:

\begin{itemize}
\tightlist
\item
  Report Patch Levels to Liferay Support
\item
  Uninstall Patches
\item
  Show collisions between patches and deployed plugins
\item
  Separate Patches from your Installation
\end{itemize}

Start with reporting patch levels to Liferay Support.

\section{Including support-info in Support
Tickets}\label{including-support-info-in-support-tickets}

Providing your environment's information (e.g., hardware architecture)
and patch level to Liferay Support is critical for reproducing your
issues. Write your support information (including your patch level) to a
file by executing this command:

\begin{verbatim}
patching-tool support-info
\end{verbatim}

The support information is written to file
\texttt{patching-tool-support-info-actual-timestamp.txt} in your
\texttt{patching-tool} folder. Please upload this file to the
\href{https://help.liferay.com/hc}{Help Center} ticket.

\section{Uninstalling Patches}\label{uninstalling-patches}

Have you noticed that the Patching Tool only seems to have an
\texttt{install} command? This is because patches are managed not by the
command, but by what appears in the \texttt{patches} folder. You manage
the patches you have installed by adding or removing patches from this
folder.

Here's how to uninstall (remove) a patch:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Remove the patch from your \texttt{patches} folder.
\item
  Run the \texttt{patching-tool\ install} command.
\end{enumerate}

To revert ALL patches, run this command:

\begin{verbatim}
patching-tool revert
\end{verbatim}

Now you know how to remove and revert patches. You can also compare
patch levels. See the
\href{/docs/7-2/deploy/-/knowledge_base/d/comparing-patch-levels}{reference
guide} for a list of the available commands.

\section{Showing collisions between patches and deployed
plugins}\label{showing-collisions-between-patches-and-deployed-plugins}

Some patches update files you might have customized via a plugin. The
\texttt{patching-tool\ list-collisions} command lists differences
(collisions) between installed patch files and your plugin's version of
them. Here's the command:

\begin{verbatim}
patching-tool list-collisions
\end{verbatim}

It is an alias for the following diff command:

\begin{verbatim}
patching-tool diff collisions files _base
\end{verbatim}

\texttt{\_base} is the literal patch level name. Collisions are only
listed for installed patches that contain source code files.

\noindent\hrulefill

\textbf{Note:} As of Patching Tool 2.0.9,
\texttt{patching-tool\ list-collisions} lists only JSP file collisions
in fragment bundles.

\noindent\hrulefill

\section{Separating Patches from the
Installation}\label{separating-patches-from-the-installation}

The Patching Tool's \texttt{separate} command helps reduce the patched
Liferay DXP installation size. If the installation has been patched, you
can make it smaller by moving the restore files out of it.

Patched installations are large because the restore files are stored
inside the web application's \texttt{WEB-INF} folder by default. These
files are required for patching the installation again.

If these files are removed, subsequent patching processes fail. Because
of this, Liferay added an option to separate the patching files from the
installation while still preserving and restoring them safely when new
patches arrive. To do this, use this command:

\begin{verbatim}
patching-tool separate [separation_name] 
\end{verbatim}

This command produces a
\texttt{liferay-patching-files-{[}separation-name{]}.zip} file in the
Patching Tool's \texttt{patches} folder. It contains the necessary files
and metadata for patching, verification, and validation. Once you create
this file, the patch files are removed from their default location and
are now only available in this file. You can store this file elsewhere
to reduce your installation's size.

\textbf{WARNING:} If the product is separated from its patches in this
way, you cannot run most of the Patching Tool commands until the patches
are restored.

After the separation process only the following commands can be used:

\begin{itemize}
\tightlist
\item
  \texttt{auto-discovery}
\item
  \texttt{info}
\item
  \texttt{setup}
\end{itemize}

Any other command returns this:

\begin{verbatim}
This installation does not include data for patching. Please copy the
liferay-patching-files-[separation-name].zip file into the 'patches' directory
and run patching-tool setup. 
\end{verbatim}

This is how you restore the patch files to your system. Details below.

\section{Restoring the Separated Patch
Files}\label{restoring-the-separated-patch-files}

When you need to patch Liferay DXP again, you must restore the separated
patch artifact. To do this, copy the
\texttt{liferay-patching-files-{[}separation-name{]}.zip} back to the
Patching Tool's \texttt{patches} folder and run
\texttt{patching-tool\ setup} command.

The command finds the necessary patching artifact and restores the patch
files to the installation. After that, the Patching Tool works like it
did prior to separating the patches.

\chapter{Configuring the Patching
Tool}\label{configuring-the-patching-tool}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The Patching Tool installs Liferay DXP patches. It ships with
prepackaged Liferay DXP bundles. If any of the following scenarios
describes your @product@ installation, however, you must configure the
Patching Tool manually:

\begin{itemize}
\tightlist
\item
  Installed Liferay DXP manually on an existing application server
\item
  Customized your Liferay DXP folder structure
\item
  Running in a cluster
\end{itemize}

If none of the above scenarios describe your installation, you can skip
this section.

If you installed Liferay DXP manually, you must also install the
Patching Tool manually. Download it from the
\href{https://customer.liferay.com/downloads?p_p_id=com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_productAssetCategoryId=118191019&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_fileTypeAssetCategoryId=118191066}{Customer
Portal}. Unzipping it to your
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
folder is the easiest way to use it.

Read on to configure the Patching Tool for your environment.

\chapter{Patching Tool Basic
configuration}\label{patching-tool-basic-configuration}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

There are two ways to configure the Patching Tool:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Automatically by executing the \texttt{auto-discovery} command
\item
  Manually by editing the configuration file (see
  \href{/docs/7-2/deploy/-/knowledge_base/d/patching-tool-advanced-configuration}{Patching
  Tool Advanced Configuration})
\end{enumerate}

Automatic configuration generates the configuration files by looking for
Liferay DXP files in the local file system. By default the Patching Tool
looks for them in its parent folder. To start the process, run this
command in your Patching Tool folder (\texttt{patching-tool}):

\begin{verbatim}
patching-tool auto-discovery
\end{verbatim}

If Liferay DXP is not installed in the parent folder, specify its
location:

\begin{verbatim}
patching-tool auto-discovery /opt/liferay-dxp
\end{verbatim}

If you specified the wrong location of Liferay DXP or it is not in the
parent folder, the Patching Tool can't find the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
and reports an error like this:

\begin{verbatim}
The .liferay-home has not been detected in the given directory tree.

Configuration:
patching.mode=binary
war.path=../tomcat-9.0.17/webapps/ROOT/
global.lib.path=../tomcat-9.0.17/lib/ext/
liferay.home=**[please enter manually]**

The configuration hasn't been saved. Please save this to the default.properties file.
\end{verbatim}

Here are ways to resolve the Liferay Home issue:

\begin{itemize}
\tightlist
\item
  Specify the Liferay Home path in the \texttt{default.properties} file.
\item
  If the Liferay Home is in the Patching Tool's tree, create a
  \texttt{.liferay-home} file in the Liferay Home folder and re-run the
  auto-discovery process.
\end{itemize}

When the Patching Tool is configured, running
\texttt{patching-tool\ info} reports product version information.

That's it! Now that you've installed and configured the Patching Tool,
you're ready to download and install patches.

\chapter{Patching Tool Advanced
Configuration}\label{patching-tool-advanced-configuration}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

By default, the Patching Tool's configuration file called
\texttt{default.properties} is in the tool's folder.

A Patching Tool configuration file typically looks like this:

\begin{verbatim}
patching.mode=binary
war.path=../tomcat-9.0.17/webapps/ROOT/
global.lib.path=../tomcat-9.0.17/lib/ext/
liferay.home=../
\end{verbatim}

The properties above (described fully in
\href{/docs/7-2/deploy/-/knowledge_base/d/patching-tool-configuration-properties}{Patching
Tool Configuration Properties}) define the location of
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home},
the patching mode (binary or source), the path to where WAR files are
deployed in the app server, and the global library path. The tool's
auto-discovery bases the OSGi module framework paths on the Liferay
Home. If, however, you changed the OSGi module framework paths to
something different than those under the default folder
\texttt{{[}Liferay\ Home{]}/osgi}, you must manually specify the
following properties:

\begin{verbatim}
module.framework.core.path=path_to_modules_core_dir
module.framework.marketplace.path=path_to_modules_marketplace_dir
module.framework.modules.path=path_to_modules_modules_dir
module.framework.portal.path=path_to_modules_portal_dir
module.framework.static.path=path_to_modules_static_dir
\end{verbatim}

Using auto-discovery and working with the default profile
\texttt{default.properties} is the easiest way to use the Patching Tool,
and is great for smaller, single server installations. But many Liferay
DXP installations serve millions of pages per day, and the Patching Tool
has been designed for this as well. So if you're running a small,
medium, or large cluster of Liferay DXP machines, you can use the
Patching Tool profiles to manage patching for all of them.

\section{Using Profiles with the Patching
Tool}\label{using-profiles-with-the-patching-tool}

You can create profiles for multiple runtimes by running auto-discovery
or creating them manually. To auto-discover other runtimes, run the
Patching Tool with parameters like this:

\begin{verbatim}
./patching-tool.sh [name of profile] auto-discovery [path/to/Liferay Home]
\end{verbatim}

This runs the same discovery process, but on the path you specify. It
writes the profile information to a file called
\texttt{{[}name\ of\ profile{]}.properties}. Alternatively, you can
manually create profile property files in your \texttt{patching-tool}
folder.

See
\href{/docs/7-2/deploy/-/knowledge_base/d/patching-tool-configuration-properties}{Patching
Tool configuration properties} (profile properties) for a complete list
of the available configuration properties.

You can have as many profiles as you want and use the same Patching Tool
to patch all of them. This helps to keep all your installations in sync.

\chapter{Installing patches on the 7.0
WAR}\label{installing-patches-on-the-7.0-war}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

If you
\href{/docs/7-1/deploy/-/knowledge_base/d/installing-product-on-tomcat}{installed
Liferay DXP manually} as a WAR file on a supported application server,
you must apply patches to the WAR file and supporting files and
re-deploy them. This article shows you how to do that.

\section{Prerequisites}\label{prerequisites-1}

Download the necessary artifacts from the
\href{https://customer.liferay.com/downloads}{Customer Portal:}

\begin{itemize}
\tightlist
\item
  Liferay DXP WAR file (\texttt{liferay-dxp-{[}version{]}.war})
\item
  Dependencies ZIP file
  (\texttt{liferay-dxp-dependencies-{[}version{]}.zip})
\item
  OSGi JARs ZIP file (\texttt{liferay-dxp-osgi-{[}version{]}.zip})
\item
  \href{https://customer.liferay.com/downloads?p_p_id=com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_productAssetCategoryId=118191019&_com_liferay_osb_customer_downloads_display_web_DownloadsDisplayPortlet_fileTypeAssetCategoryId=118191066}{Latest
  Patching Tool}
\end{itemize}

\section{Install the patch on the Liferay DXP WAR and
artifacts}\label{install-the-patch-on-the-liferay-dxp-war-and-artifacts}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create an arbitrary folder. Unzip the dependency artifacts and the
  Patching Tool into it. The folder contents should look like this:

  \begin{itemize}
  \tightlist
  \item
    \texttt{{[}patching-home{]}/}

    \begin{itemize}
    \tightlist
    \item
      \texttt{liferay-dxp-dependencies-{[}version{]}/} ← Unzipped
      Dependencies
    \item
      \texttt{osgi/} ← Unzipped OSGi JARs
    \item
      \texttt{patching-tool/} ← Unzipped Patching Tool
    \item
      \texttt{liferay-dxp-{[}version{]}.war/} ← Liferay DXP WAR File
    \end{itemize}
  \end{itemize}
\item
  Create the default profile configuration file in the Patching Tool
  folder: \texttt{patching-home/patching-tool/default.properties}. The
  contents should look like this:
\end{enumerate}

\begin{verbatim}
patching.mode=binary
war.path=../../patching-home/liferay-dxp-[version].war
global.lib.path=../../patching-home/liferay-dxp-dependencies-[version]
liferay.home=../../patching-home
\end{verbatim}

\begin{verbatim}
If you're using a different OSGi folder structure, you can specify it as
the [Patching Tool Advanced Configuration](/docs/7-2/deploy/-/knowledge_base/d/patching-tool-advanced-configuration)
documentation describes: 
\end{verbatim}

\begin{verbatim}
module.framework.core.path=/osgi-home/osgi/core
module.framework.marketplace.path=/osgi-home/osgi/marketplace
module.framework.modules.path=/osgi-home/osgi/modules
module.framework.portal.path=/osgi-home/osgi/portal
module.framework.static.path=/osgi-home/osgi/static 
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  Download the patch (fix pack or hotfix) to install and put it in a
  folder called \texttt{patches} in your Patching Tool folder
  (i.e.~\texttt{{[}patching-home{]}/patching-tool/patches}).
\item
  Execute the Patching Tool's \texttt{info} command:
\end{enumerate}

\begin{verbatim}
/patching-home/patching-tool> patching-tool info
Loading product and patch information...
Product information:
  * installation type: binary
  * build number: 7210
  * service pack version:
    - available SP version: Not available
    - installable SP version: Not available
  * patching-tool version: 2.0.12
  * time: 2019-06-03 18:30Z
  * host: 91WRQ72 (8 cores)
  * plugins: no plugins detected

Currently installed patches: -
...
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Install the patch.
\end{enumerate}

\begin{verbatim}
/patching-home/patching-tool> patching-tool.sh  install
One patch is ready to be installed. Applying dxp...
Cleaning up: [1%..10%..20%..30%..40%..50%..60%..70%..80%..90%..100%]
Installing patches: [1%..10%..20%..30%..40%..50%..60%..70%..80%..90%...100%]
The installation was successful. One patch is installed on the system.
\end{verbatim}

Great! You have successfully patched the artifacts, and they are ready
to be deployed on any supported Application Server.

\section{Related Topics}\label{related-topics-9}

\href{/docs/7-2/deploy/-/knowledge_base/d/patching-tool-advanced-configuration}{Patching
Tool Advanced Configuration}

\href{/docs/7-2/deploy/-/knowledge_base/d/deploying-product}{Deploying
Liferay DXP}

\chapter{Keeping up with Fix packs and Service
Packs}\label{keeping-up-with-fix-packs-and-service-packs}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

The \emph{Announcements} section on
\href{https://help.liferay.com/hc}{Liferay's Help Center page} lists all
fix pack updates, security alerts, product releases, and system updates.
The approximate frequency of fix pack and service pack releases is
explained
\href{/docs/7-2/deploy/-/knowledge_base/d/patching-basics}{here}. The
\emph{Receive Notifications} sidebar lets you subscribe to the latest
updates on products, patches, and system improvements.

Click \emph{Downloads} on the Liferay Digital Experience Platform page
to access:

\begin{itemize}
\tightlist
\item
  Latest Release
\item
  Fix Packs
\item
  Service Packs Archive
\item
  Security Advisories
\item
  Patching Tool
\end{itemize}

Click \emph{Support Information} to access the compatibility matrix,
support FAQs, and more.

\chapter{Backing up a Liferay DXP
Installation}\label{backing-up-a-liferay-dxp-installation}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Once you have an installation of Liferay DXP running, you should
implement a comprehensive backup plan. In case some kind of catastrophic
hardware failure occurs, you'll be thankful to have backups and
procedures for restoring Liferay DXP from one of them. @product@ isn't
very different from other Java web applications that might be running on
your application server. Nevertheless, there are some specific
components you should include in your backup plan.

The recommended backup plan includes backing up these things:

\begin{itemize}
\tightlist
\item
  Source code
\item
  Liferay DXP's file System
\item
  Liferay DXP's database
\end{itemize}

\section{Backing up Source Code}\label{backing-up-source-code}

If you have extended Liferay DXP or have written any plugins, they
should be stored in a source code repository such as Git, Subversion, or
CVS, unless you're Linus Torvalds, and then tarballs are okay too
(that's a joke). You should back up your source code repository on a
regular basis to preserve your ongoing work. This probably goes without
saying in your organization since nobody wants to lose source code
that's taken months to produce. Thus you should include source code in
your Liferay DXP backup plan.

Next, let's examine the Liferay DXP installation items you should back
up.

\section{Backing up Liferay DXP's File
System}\label{backing-up-liferay-dxps-file-system}

The \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home
folder} stores Liferay DXP's properties configuration files, such as
\texttt{portal-setup-\ wizard.properties} and
\texttt{portal-ext.properties}. You should absolutely back them up. In
fact, it's best to back up your entire application server and Liferay
Home folder contents.

Liferay DXP stores configuration files, search indexes, and cache
information in Liferay Home's \texttt{/data} folder. If you're using the
File System store or the Advanced File System store, the documents and
media repository is also stored here by default. It's always important
to back up your \texttt{/data} folder.

The files that comprise Liferay DXP's OSGi runtime are stored in Liferay
Home's \texttt{/osgi} folder. It contains all of the app and module JAR
files deployed to Liferay DXP. The \texttt{/osgi} folder also contains
other required JAR files, configuration files, and log files. It's also
important to back up your \texttt{/osgi} folder.

Liferay Home's \texttt{/logs} folder contains Liferay DXP's log files.
If a problem occurs on Liferay DXP, the @product@ log files often
provide valuable information for determining what went wrong. The
\texttt{/data}, \texttt{/osgi}, and \texttt{/logs} folders are all
contained in the Liferay Home folder. Thus, if you're backing up both
your application server folder and your Liferay Home folder, you're in
good shape.

Remember that if you've configured the document library to store files
to a location other than the default location, you should also back up
that location.

That covers the Liferay DXP file system locations you should back up.
Next, let's discuss how to back up Liferay DXP's database.

\section{Backing up Liferay DXP's
Database}\label{backing-up-liferay-dxps-database}

Liferay DXP's database is the central repository for all of the portal's
information. It's the most important component to back up. You can back
up the database live (if your database allows this) or by exporting
(dumping) the database into a file and then backing up the exported
file. For example, MySQL ships with a \texttt{mysqldump} utility which
lets you export the entire database and data into a large SQL file. This
file can then be backed up. On restoring the database you can import
this file into the database to recreate the database state to that of
the time you exported the database.

If you're storing Liferay DXP's Documents and Media Library files to a
Jackrabbit JSR-170 repository database, you should back it up. If you've
placed your search index into a database (not recommended; see the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-clustering}{Liferay
DXP Clustering} article for information on using Cluster Link or Solr),
you should back up that database too.

If you wish to avoid re-indexing your content after restoring your
database, back up your search indexes. This is easiest to do if you have
a separate Elastic or Solr environment on which your index is stored. If
you're in a clustered configuration and you're replicating indexes,
you'll need to back up each index replica.

Restoring your application server, your Liferay Home folder, the
locations of any file system-based media repositories, and your database
from a backup system should give you a functioning portal. Restoring
search indexes should avoid the need to re-index when you bring your
site back up after a catastrophic failure. Good, consistent backup
procedures are key to recovering successfully from a hardware failure.

\chapter{Monitoring Liferay DXP}\label{monitoring-liferay-dxp}

These articles show you how to monitor Liferay DXP. Monitoring vital
statistics such as Java memory heaps, garbage collection, database
connection pools, and the application server helps you optimize
performance. Better monitoring means better tuning and thus avoids
dangerous runtime scenarios like out of memory errors and wasted heap
space.

You'll learn basic monitoring techniques, such as

\begin{itemize}
\tightlist
\item
  Using the Visual VM tool and the JMX Console
\item
  Garbage Collection
\end{itemize}

Read on to learn more about monitoring Liferay DXP!

\chapter{Monitoring Garbage Collection and the
JVM}\label{monitoring-garbage-collection-and-the-jvm}

Although the
\href{/docs/7-2/deploy/-/knowledge_base/d/tuning-guidelines}{tuning
parameters} give you a good start to JVM tuning, you must monitor GC
performance to ensure you have the best settings to meet your needs.
There are several tools to help you monitor Oracle JVM performance.

\section{VisualVM}\label{visualvm}

\href{https://visualvm.github.io/}{VisualVM} provides a centralized
console for viewing Oracle JVM performance information and its Visual GC
plugin shows garbage collector activities.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/visual-vm-gc.png}}
\caption{VisualVM's Visual GC plugin shows the garbage collector in
real-time.}
\end{figure}

\noindent\hrulefill

\textbf{Note:} Oracle's JDK has VisualVM bundled
(\texttt{\$JAVA\_HOME/bin/jvisualvm}). However, always download and use
the latest version from VisualVM's
\href{https://visualvm.github.io/}{official website}.

\noindent\hrulefill

\section{JMX Console}\label{jmx-console}

This tool helps display various statistics like Liferay DXP's
distributed cache performance, application server thread performance,
JDBC connection pool usage, and more.

\noindent\hrulefill

\textbf{Note:} The JMX Console is the preferred tool for monitoring
application server performance.

\noindent\hrulefill

To enable JMX connections, add these JVM arguments:

\begin{verbatim}
-Dcom.sun.management.jmxremote=true
-Dcom.sun.management.jmxremote.port=5000
-Dcom.sun.management.jmxremote.authenticate=false
-Dcom.sun.management.jmxremote.ssl=false
\end{verbatim}

If you're running JMX Console from a another machine, add these JVM
arguments too:

\begin{verbatim}
-Dcom.sun.management.jmxremote.local.only=false
-Dcom.sun.management.jmxremote.rmi.port=5000
-Djava.rmi.server.hostname=[place IP address here]
\end{verbatim}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/visual-vm-jmx.png}}
\caption{VisualVM monitors the JVM using Java Management Extensions.}
\end{figure}

\section{Garbage Collector Verbose
Logging}\label{garbage-collector-verbose-logging}

Add these JVM arguments to activate verbose logging for the JVM garbage
collector.

\begin{verbatim}
-verbose:gc -Xloggc:/tmp/liferaygc1.log -XX:+PrintGCDetails 
-XX:+PrintGCCause -XX:+PrintGCApplicationConcurrentTime 
-XX:+PrintGCApplicationStoppedTime
\end{verbatim}

Examining these logs helps you tune the JVM properly.

\noindent\hrulefill

\textbf{Note:} Adding these JVM arguments generates a heap dump if an
\texttt{OutOfMemoryError} occurs. The dump is written to the heap dump
path specified. Specify the path to use:

\texttt{-XX:+HeapDumpOnOutOfMemoryError\ -XX:HeapDumpPath=/heap/dump/path/}

\noindent\hrulefill

Garbage collector log files can grow huge. You can use additional
arguments like the following ones to rotate the log to a new log file
when the current log file reaches a maximum size:

\begin{verbatim}
-XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 
-XX:GCLogFileSize=50M
\end{verbatim}

These arguments rotate the logs to up to \texttt{10} log files with a
maximum size of \texttt{50M} each.

Now you can monitor garbage collection in the JVM and tune it for top
performance.

\chapter{Managing Liferay DXP with Liferay Connected
Services}\label{managing-liferay-dxp-with-liferay-connected-services}

Liferay Connected Services (LCS) is a set of tools and services for
managing and monitoring your Liferay DXP instances. LCS can help you
install fix packs, monitor your instances' performance, activate your
instances, and help you manage your subscriptions. In other words, LCS
is like a butler for the mansion that is Liferay DXP. It's like having a
single butler that can serve several mansions at once!

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

Before going any further, you should take note of a few key terms used
throughout this guide:

\textbf{Project:} Represents a group of users belonging to a company or
organization. For example, a project can consist of all the users from a
project team or business unit, or it can include the entire company.

\textbf{Environment}: Represents a physical cluster of servers or a
virtual or logical aggregation of servers.

\textbf{Server}: Describes a concrete Liferay DXP instance. It can be a
standalone server or a cluster node.

As you go through this guide, you'll cover the following topics:

\begin{itemize}
\tightlist
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/getting-started-with-lcs}{Getting
  Started}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/lcs-preconfiguration}{LCS
  Preconfiguration}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/activating-your-liferay-dxp-server-with-lcs}{Registering
  Your Liferay DXP Server with LCS}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/using-lcs}{Using LCS}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/troubleshooting-your-lcs-connection}{Troubleshooting
  Your LCS Connection}
\end{itemize}

You'll get started with the configuration steps required to use LCS with
Liferay DXP.

\chapter{Getting Started with LCS}\label{getting-started-with-lcs}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

To use LCS, you must register a server in an LCS environment. An LCS
environment represents a physical cluster of servers or a virtual or
logical aggregation of servers. Each environment is part of an LCS
project. An LCS project represents a group of users belonging to a
company or organization. For example, a project can consist of all the
users from a project team or business unit, or it can include the entire
company.

LCS projects don't initially contain any environments. You must
therefore create one before you can register any servers in LCS. The
first time you log in to
\href{https://lcs.liferay.com}{lcs.liferay.com}, LCS presents you with a
wizard that walks you through the environment creation process. Click
\emph{Get Started} to begin.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-00.png}}
\caption{Click \emph{Get Started} to begin the wizard.}
\end{figure}

Each of these steps corresponds to a step in the wizard:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Select the LCS project for your new environment. You can select any of
  your available LCS projects. Note that each project lists its
  available subscriptions and whether it supports elastic subscriptions.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-01.png}}
  \caption{Select the LCS project you want to create the environment in,
  and click \emph{Next}.}
  \end{figure}
\item
  Name and describe the environment. The name is mandatory, but the
  description is optional. Although you can enter anything you wish in
  these fields, it's best to choose a name and description that
  accurately identify the environment (e.g., Development, Production,
  Test, etc.). Note that you can change these values after creating the
  environment.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-02.png}}
  \caption{Name and describe the environment, then click \emph{Next}.}
  \end{figure}
\item
  Select the environment's subscription type from the project's
  available subscriptions. Even if you won't use LCS to activate the
  servers defined for this environment, you must still select a
  subscription type. Also note that you can't change this selection
  after creating the environment.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-03.png}}
  \caption{Select the environment's subscription type, then click
  \emph{Next}.}
  \end{figure}
\item
  Select whether servers that connect to this environment are part of a
  cluster. LCS provides additional tools in clustered environments that
  help you manage the cluster. For example, clustered environments show
  cluster-specific metrics, and fix packs apply to all cluster nodes.
  There are a few things to keep in mind if you set the environment as
  clustered:

  \begin{itemize}
  \tightlist
  \item
    You can't change this setting after creating the environment.
  \item
    Each clustered environment can only support nodes that belong to a
    single cluster. To connect a different cluster's nodes, you must
    create a separate clustered environment exclusively for those nodes.
  \item
    You must set the portal property \texttt{cluster.link.enabled} to
    \texttt{true} in any servers that connect to a clustered
    environment.
  \end{itemize}

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-04.png}}
  \caption{Select whether this is a clustered environment, then click
  \emph{Next}.}
  \end{figure}
\item
  Select whether the environment allows elastic subscriptions. Elastic
  subscriptions let you register an unlimited amount of servers. This is
  critical for auto-scaling situations in which servers are created and
  destroyed automatically in response to demand. Elastic environments
  are also useful for bringing additional servers online on a temporary
  basis for any other purpose, such as business continuity planning. For
  more information, see
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-liferay-dxp-subscriptions\#elastic-subscriptions}{the
  documentation on elastic subscriptions}. Also note that you can't
  change this selection after creating the environment.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-05.png}}
  \caption{Select whether this is an elastic environment, then click
  \emph{Next}.}
  \end{figure}
\item
  Enable the LCS service you want to use with servers that connect to
  this environment. The following service is available:

  \textbf{Liferay Instance Activation:} Enabling this lets LCS activate
  any Liferay DXP instances that connect to the environment. If you
  disable this service, you must activate via an XML file from Liferay
  support, and such instances must run version 5.0.0 or newer of the LCS
  client app.

  Note that you \textbf{must} use LCS for activation of Elastic
  subscriptions. Otherwise, you don't have to use LCS for activation.

  Portal Analytics, Fix Pack Management and Portal Properties Analysis
  have been removed from the list of available services. For more
  information about this change, please read
  \href{https://help.liferay.com/hc/en-us/articles/360037317691-Liferay-Connected-Services-Feature-Deprecation-Update-March-2020}{this
  article}

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-06.png}}
  \caption{Enable or disable the LCS services you want to use for
  servers that connect to the environment, then click \emph{Next}.}
  \end{figure}
\item
  A completed form presents your selections. Review them and make any
  changes that you want. When you're finished, click \emph{Create
  Environment}.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-onboarding-07.png}}
  \caption{This form contains each of your selections from the previous
  steps. Make any changes you want, then click \emph{Create
  Environment}.}
  \end{figure}
\end{enumerate}

After creating your environment, the wizard shows a screen that lets you
download the LCS client app, download the environment's token file, and
go to your project's dashboard in LCS. Before registering a server in
your new environment, however, you must complete the
\href{/docs/7-2/deploy/-/knowledge_base/d/lcs-preconfiguration}{preconfiguration
steps} for that server.

\chapter{LCS Preconfiguration}\label{lcs-preconfiguration}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

Before registering your server with LCS, there are a few things you must
configure. The sections in this guide walk you through these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \hyperref[downloading-the-lcs-client-app]{Downloading the LCS Client
  App}
\item
  \hyperref[preconfiguring-lcs-to-connect-through-a-proxy]{Preconfiguring
  LCS to Connect Through a Proxy}
\item
  \hyperref[ensuring-access-to-lcs]{Ensuring Access to LCS}
\item
  \hyperref[ntp-server-synchronization]{NTP Server Synchronization}
\item
  \hyperref[configuring-websphere]{Configuring WebSphere}: This is only
  necessary if you're running Liferay DXP on the WebSphere application
  server.
\item
  \hyperref[installing-the-lcs-client-app]{Installing the LCS Client
  App}
\end{enumerate}

\hyperref[upgrading-the-lcs-client-app]{The last section} in this guide
shows you how to upgrade the LCS client app once your server is
registered with LCS. We highly recommend that you upgrade the app
whenever Liferay releases a new version of it.

\noindent\hrulefill

\textbf{Note:} You must use LCS for activation of Elastic subscriptions.
Otherwise, you don't have to use LCS for activation. You can instead
request an XML activation key from Liferay Support.

\noindent\hrulefill

\section{Downloading the LCS Client
App}\label{downloading-the-lcs-client-app}

The LCS client app is included in each Liferay DXP bundle and
autodeploys when the bundle starts. The included version of the app,
however, may be outdated. To get the latest version of the LCS client
app, you must first download it via Liferay Marketplace.

\noindent\hrulefill

\textbf{Note:} Even though Liferay Marketplace and this guide use the
term \emph{purchase}, the LCS client app is free of charge. The purchase
process for a free app in Liferay Marketplace adds the app to your
Liferay project, much like downloading a free app in a mobile app store
adds the app to your account.

\noindent\hrulefill

Use these steps to purchase and download the app (if you've already
purchased the app, you can skip to step 3 to download it):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Navigate to
  \href{https://web.liferay.com/marketplace/-/mp/application/71774947}{the
  LCS client app in Liferay Marketplace}. Sign in to Marketplace, then
  click the LCS client app's \emph{Free} button.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-client-app-marketplace.png}}
  \caption{Click the app's \emph{Free} button to begin the purchase
  process.}
  \end{figure}
\item
  Select your project, accept the license agreement, and then click the
  \emph{Purchase} button. Marketplace then displays your receipt.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-client-app-receipt.png}}
  \caption{Liferay Marketplace displays your receipt for the LCS client
  app.}
  \end{figure}
\item
  On the receipt, click \emph{See Purchased}. This shows where you can
  download the LCS client app. To download the app, click the \emph{App}
  button next to the latest version of the app.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** If you must download the LCS client app later, such as when
 [upgrading it](#upgrading-the-lcs-client-app), 
 select *Purchased Apps* from the User menu at the top-right of Liferay 
 Marketplace. On the Purchased Apps screen, select the project you 
 associated with the LCS client app and then select the app. This takes you 
 to the same downloads page shown in the screenshot. 
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
![ Click the *App* button next to the version of the app you want to download.](./images/lcs-client-download-page.png){./images/lcs-client-download-page.png)
\end{verbatim}

Great! You've successfully downloaded the LCS client app. Before
installing it, however, there are a few additional pre-configuration
steps you should complete. These appear next; then you'll learn how to
install the app.

\noindent\hrulefill

\textbf{Note:} If your server connects to the Internet through a proxy,
you must configure your server or the LCS client app \textbf{before}
deploying the app. The following section contains instructions on this.
If your server doesn't connect through a proxy, skip this section.

\noindent\hrulefill

\section{Preconfiguring LCS to Connect Through a
Proxy}\label{preconfiguring-lcs-to-connect-through-a-proxy}

If your server connects to the Internet through a proxy, you must set
some properties \textbf{before} deploying the LCS client app. There are
two ways to do so---chose only one:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \hyperref[jvm-app-server-arguments]{As JVM app server arguments}.
\item
  \hyperref[lcs-client-app-properties]{As LCS client app properties}.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} Use only one of these methods to configure your server to
connect through a proxy.

\noindent\hrulefill

\section{JVM App Server Arguments}\label{jvm-app-server-arguments}

To set the proxy properties in your server, set them as JVM app server
arguments. Set these properties to the appropriate values for your
proxy:

\begin{verbatim}
-Dhttp.proxyHost=
-Dhttp.proxyPort=
-Dhttp.proxyUser=
-Dhttp.proxyPassword=
-Dhttps.proxyHost=
-Dhttps.proxyPort=
\end{verbatim}

Note that the \texttt{user}, \texttt{password}, and \texttt{https}
properties are only needed if your proxy requires authentication.

\section{LCS Client App Properties}\label{lcs-client-app-properties}

To set the proxy properties via the LCS client app, you must create and
deploy a config file containing the properties. Follow these steps to do
so:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create the config file
  \texttt{com.liferay.lcs.client.configuration.LCSConfiguration.config}.
  In the steps that follow, you'll set the proxy properties in this
  file.
\item
  Set these \texttt{proxy*} properties to the appropriate values for
  your proxy:

\begin{verbatim}
proxyHostName=""
proxyHostPort=""
\end{verbatim}
\item
  If your proxy requires authentication, pass the credentials via these
  properties:

\begin{verbatim}
proxyHostLogin=""
proxyHostPassword=""
\end{verbatim}
\item
  If your proxy requires NTLM authentication, you must also populate
  these properties:

\begin{verbatim}
proxyAuthType="ntlm"
proxyDomain=""
proxyWorkstation=""
\end{verbatim}

  Be sure to set \texttt{proxyDomain} and \texttt{proxyWorkstation} to
  the appropriate values for your proxy. Note that you can leave
  \texttt{proxyWorkstation} blank if you don't need it.
\item
  Deploy the config file to \texttt{osgi/configs}.
\end{enumerate}

\section{Ensuring Access to LCS}\label{ensuring-access-to-lcs}

For the LCS client app to work, it must be able to access the following
DNS names. If your server is behind a proxy and/or a firewall, then you
must open access to these:

\begin{itemize}
\tightlist
\item
  \texttt{lcs.liferay.com}
\item
  \texttt{lcs-gateway.liferay.com}
\end{itemize}

As an added security measure, you can also restrict traffic to HTTPS.

The next section discusses NTP server synchronization.

\section{NTP Server Synchronization}\label{ntp-server-synchronization}

For LCS to work properly, the application server running Liferay DXP
should be synchronized with a time server. If it's not, you may get log
errors similar to these:

\begin{verbatim}
ERROR [pool-6-thread-3][HandshakeTask:68] java.lang.RuntimeException: Handshake expired. 
Check that the server is synchronized with an NTP server. 

WARN [liferay/hot_deploy-1][LCSHotDeployMessageListener:186] LCS portlet is not connected 
java.lang.RuntimeException: com.liferay.jsonwebserviceclient.JSONWebServiceInvocationException: 
com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'oauth_problem': was expecting 
('true', 'false' or 'null')_ at [Source: oauth_problem=timestamp_refused&oauth_acceptable_timestamps=1477311475-1477312075; 
line: 1, column: 14] [Sanitized]
\end{verbatim}

For information on how to synchronize your application server with a
time server, see your application server's documentation.

\section{Configuring WebSphere}\label{configuring-websphere}

IBM ® WebSphere ® is a trademark of International Business Machines
Corporation, registered in many jurisdictions worldwide.

If you're running the WebSphere application server, then there are some
additional configuration steps you must take before deploying the LCS
client app:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Shut down the application server.
\item
  Add these properties in a \texttt{portal-ext.properties} file:

\begin{verbatim}
module.framework.properties.org.osgi.framework.bootdelegation=\
    __redirected,\
    com.sun.ccpp,\
    com.sun.ccpp.*,\
    com.liferay.aspectj,\
    com.liferay.aspectj.*,\
    com.liferay.portal.servlet.delegate,\
    com.liferay.portal.servlet.delegate*,\
    com.sun.crypto.*,\
    com.sun.image.*,\
    com.sun.jmx.*,\
    com.sun.jna,\
    com.sun.jndi.*,\
    com.sun.mail.*,\
    com.sun.management.*,\
    com.sun.media.*,\
    com.sun.msv.*,\
    com.sun.org.*,\
    com.sun.syndication,\
    com.sun.tools.*,\
    com.sun.xml.*,\
    com.yourkit.*,\
    com.ibm.crypto.*,\
    sun.*,\
    javax.validation,\
    javax.validation.*,\
    jdk.*,\
    weblogic.jndi,\
    weblogic.jndi.*\
\end{verbatim}
\item
  In your Liferay DXP installation, delete the \texttt{osgi/state}
  folder.
\item
  Start the application server.
\item
  Navigate to the WebSphere console in a browser.
\item
  Select your server and navigate to \emph{Java and Process Management}
  → \emph{Process Definition} → \emph{Additional Properties}.
\item
  Select \emph{Java Virtual Machine} → \emph{Custom Properties}.
\item
  Click \emph{New}, and enter the following:

  \begin{itemize}
  \tightlist
  \item
    Name: \texttt{com.ibm.crypto.provider.DoRSATypeChecking}
  \item
    Value: \texttt{false}
  \end{itemize}
\item
  Click \emph{Save}, then \emph{OK} to apply changes to the master
  configuration.
\end{enumerate}

Note that for LCS client app versions prior to 5.0.0, you must also
change the value of the \texttt{digital.signature.algorithm.provider}
property in the app's \texttt{portlet.properties} file to
\texttt{IBMJCE}:

\begin{verbatim}
digital.signature.algorithm.provider=IBMJCE
\end{verbatim}

\section{Installing the LCS Client
App}\label{installing-the-lcs-client-app}

Once you've addressed the above pre-configuration steps, you're ready to
install the LCS client app. Follow these steps to install the app:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In your
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder (usually the parent folder of the application server's folder),
  delete this file:

\begin{verbatim}
osgi/marketplace/Liferay Connected Services Client.lpkg
\end{verbatim}
\item
  Place the new \texttt{Liferay\ Connected\ Services\ Client.lpkg} in
  \texttt{osgi/marketplace}.
\end{enumerate}

Great! Now you're all set to
\href{/docs/7-2/deploy/-/knowledge_base/d/activating-your-liferay-dxp-server-with-lcs}{register
your server with LCS}.

The next section shows you how to upgrade the LCS client app. We highly
recommend that you do this whenever Liferay releases a new version of
the app.

\section{Upgrading the LCS Client
App}\label{upgrading-the-lcs-client-app}

Your server should always be running the latest version of the LCS
client app. There are two ways to upgrade the app, depending on the
exact LCS pre-configuration steps you followed:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Via Liferay Marketplace \emph{inside} Liferay DXP. Use this method if
  you don't need to configure the LCS client app (e.g., to connect
  through a proxy) before it deploys.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** If you choose this method and have a clustered environment, you 
 must perform the upgrade separately on each node in your cluster. 
 Therefore, you may prefer to upgrade manually as detailed in the next step 
 to ensure that all your nodes are running the exact same version of the 
 LCS client app. 
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
To perform the upgrade, first navigate to *Control Panel* &rarr; *Apps* 
&rarr; *Purchased*. Apps needing an update are listed first. Click *Update* 
next to the LCS client app. Note that you may need to restart your server 
for the upgrade to complete. 
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Manually, after downloading the LCS client app's LPKG file to your
  machine. Use this method if you must pre-configure the LCS client app
  to connect through a proxy.
\end{enumerate}

\noindent\hrulefill

\begin{verbatim}
 **Note:** If you used JVM app server arguments to configure your server to 
 connect through a proxy, then you don't need to pre-configure the LCS 
 client app to connect through the same proxy. 
\end{verbatim}

\noindent\hrulefill

\begin{verbatim}
To update the LCS client app manually, follow the previous sections in this
guide for downloading and pre-configuring the app. Then deploy it to
`[Liferay Home]/deploy` as you would any other app. 
\end{verbatim}

Contact Liferay Support if you need additional assistance with the
upgrade process.

\chapter{Registering Your Liferay DXP Server with
LCS}\label{registering-your-liferay-dxp-server-with-lcs}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

Follow these steps to register your Liferay DXP server with LCS:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Ensure that you've completed the
  \href{/docs/7-2/deploy/-/knowledge_base/d/lcs-preconfiguration}{LCS
  preconfiguration steps}.
\item
  Log in to \href{https://lcs.liferay.com}{lcs.liferay.com}. This takes
  you to your company's LCS project. If your company has multiple
  projects, from the menu to the right of the Dashboard tab select the
  project that's getting a new server.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-select-project.png}}
  \caption{Select your LCS project from the menu highlighted by the red
  box in this screenshot.}
  \end{figure}
\item
  Select or create the environment in which to register this server. If
  you're using LCS for activation, upon connection to LCS your server
  consumes an activation key from the subscription type assigned to the
  environment. Note that a subscription type can only be assigned to an
  environment when creating the environment. If you have sufficient
  permissions in your company's project, you can
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-environments\#creating-environments}{create
  a new environment} by selecting \emph{Add Environment}.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-registration-select-environment.png}}
  \caption{You must register your server in an LCS environment. The red
  box in this screenshot highlights environments.}
  \end{figure}
\item
  Select the environment's \emph{Registration} tab. This is where you
  manage and download the
  \href{/docs/7-2/deploy/-/knowledge_base/d/understanding-environment-tokens}{environment's
  token file}, that registers servers in the environment.

  In the Registration tab's \emph{Services} section, change the Liferay
  Instance Activation setting, if needed. Note that if you change this
  option and there are servers already registered in the environment,
  you must regenerate the token file and use it to reconnect those
  servers to LCS. You'll regenerate and/or download the token in the
  next step.

  Additionally, If you disable this service, you must activate via an
  XML file from Liferay support, and such instances must run version
  5.0.0 or newer of the LCS client app.

  Liferay Instance Activation is either enabled or disabled for all
  servers that connect to this environment. If Portal Property Analysis
  is selected, you can prevent LCS environment.

  \begin{figure}
  \centering
  \pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-registration.png}}
  \caption{An environment's Registration tab lets you manage the token
  file used to register your server in the environment.}
  \end{figure}
\item
  What you do now depends on what you did in the previous step:

  \textbf{Changes to Liferay Instance Activation:} Regenerate and
  download the token. Regenerating a token causes all servers using the
  old token to disconnect from LCS. You must reconnect them using the
  new token.

  \textbf{No changes to LCS service selections:} Download the token.
\item
  Place the token file in your server's
  \texttt{{[}Liferay\ Home{]}/data} folder. Note that
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  is usually the parent folder of the application server's folder. If
  your server is running, it should connect to LCS in about one minute.
  If your server isn't running, it connects to LCS on startup.
\item
  Celebrate! Your Liferay DXP server is registered in LCS. If for some
  reason it isn't, see the
  \href{/docs/7-2/deploy/-/knowledge_base/d/troubleshooting-your-lcs-connection}{LCS
  troubleshooting article}.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} You may be wondering what happens if LCS goes offline.
Don't worry, this doesn't cause a rift in the space-time continuum. LCS
is deployed on a global cloud infrastructure set up for automatic
failure recovery. The potential for non-availability is very low. In the
event of an outage, however, registered servers maintain a local copy of
their uptime information to transmit to LCS when it comes back online.
If you use LCS for activation, active subscriptions have a 30-day grace
period to re-establish connectivity and remain valid. This is ample time
for LCS to come back online.

\noindent\hrulefill

\section{Determining Your Server's LCS Connection
Status}\label{determining-your-servers-lcs-connection-status}

In Liferay DXP, you can view your LCS connection status in the LCS
client app. Access the client by clicking \emph{Control Panel} →
\emph{Configuration} → \emph{Liferay Connected Services}.

Here's a full description of what a connected LCS client app displays:

\textbf{Connection Uptime:} The duration of the client's connection with
LCS.

\textbf{Last Message Received:} The time the LCS client received the
latest connection message from LCS. These messages occur only upon
connection/reconnection and are unrelated to server metrics. It's
therefore common for a long period of time to pass before the client
receives another such message for a reconnection event.

\textbf{Services:} The LCS services enabled for this server. Note that
all servers in an environment use the same set of LCS services. LCS
services can't be controlled on a server-by-server basis.

Note: Portal Analytics, Fix Pack Management and Portal Properties
Analysis have been removed from the list of available services. For more
information about this change, please read
\href{https://help.liferay.com/hc/en-us/articles/360037317691-Liferay-Connected-Services-Feature-Deprecation-Update-March-2020}{this
article}

\textbf{Project Home:} A link to this server's LCS project.

\textbf{Environment:} A link to this server's LCS environment.

\textbf{Server Dashboard:} A link to the server on LCS.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-connected.png}}
\caption{The server is connected to LCS.}
\end{figure}

\chapter{Using LCS}\label{using-lcs}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

Once your Liferay DXP server is connected to LCS, you can get down to
the business that LCS is designed for---managing your servers. If you're
not already there, log in with your account on
\href{https://lcs.liferay.com}{lcs.liferay.com}. This is where you'll
manage environments, register servers and more.

This articles in this section each detail one or more of LCS's features:

\begin{itemize}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/what-lcs-stores-about-your-liferay-dxp-servers}{\textbf{What
  LCS Stores About Your Liferay DXP Servers:}} For LCS to work, the LCS
  servers must store certain information about your servers. Sensitive
  data, however, isn't stored on the LCS servers. This article describes
  the data that LCS does and doesn't store.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-users-in-your-project}{\textbf{Managing
  LCS Users in Your Project:}} Learn how to manage your LCS project's
  users by assigning them roles.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/using-the-dashboard}{\textbf{Using
  the Dashboard:}} Learn how to manage your LCS projects and access your
  environments and servers in LCS.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-environments}{\textbf{Managing
  LCS Environments:}} Learn how to create and manage your LCS project's
  environments. This includes instructions on generating tokens for an
  environment's servers.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-servers}{\textbf{Managing
  LCS Servers:}} Learn how to manage your servers in LCS. This includes
  viewing server status and editing server settings.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-your-lcs-account}{\textbf{Managing
  Your LCS Account:}} Learn how to manage your LCS account. This
  includes setting general account preferences, managing LCS web
  notifications, and configuring LCS to send you notification emails
  when specific events occur in your LCS projects.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-liferay-dxp-subscriptions}{\textbf{Managing
  Liferay DXP Subscriptions:}} Learn how to view and manage your Liferay
  DXP subscriptions for the servers in your LCS project.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/understanding-environment-tokens}{\textbf{Understanding
  Environment Tokens:}} Learn about the environment tokens that you use
  to connect your servers to LCS.
\end{itemize}

\chapter{What LCS Stores About Your Liferay DXP
Servers}\label{what-lcs-stores-about-your-liferay-dxp-servers}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

To protect your users' privacy, LCS only stores system-specific data.
LCS doesn't gather or store data on your users.

By default, LCS stores the following information about your server:

\begin{itemize}
\tightlist
\item
  Portal build number and edition
\item
  Patching Tool Version
\item
  LCS Client Build Number
\item
  Application Server Name
\item
  Database Name
\item
  File Encoding
\item
  OS Name and Version
\item
  Timezone
\item
  IP Address
\item
  Java Version and Java Options
\item
  Number of Processor Cores
\item
  File System Usage
\item
  Memory Usage
\end{itemize}

The other data LCS stores depends on the services you enabled in your
environment token, and whether your server was connected before certain
services were removed. For more information on this, see
\href{/docs/7-2/deploy/-/knowledge_base/d/activating-your-liferay-dxp-server-with-lcs}{Registering
Servers with LCS}. If you enabled the following services, LCS gathered
and stored the data listed for each:

\begin{itemize}
\item
  \textbf{Portal analytics:}

  \begin{itemize}
  \tightlist
  \item
    Portal and portlet metrics
  \item
    JVM metrics
  \item
    Cache and server metrics
  \end{itemize}
\item
  \textbf{Fix pack management:}

  \begin{itemize}
  \tightlist
  \item
    Patches installed on the server
  \end{itemize}
\item
  \textbf{Portal properties analysis:}

  \begin{itemize}
  \tightlist
  \item
    \texttt{portal.properties} (except sensitive data)
  \end{itemize}
\end{itemize}

Sensitive data is any key-value pair that contains user names or
passwords. For example, LCS did not store the following properties
because they contain sensitive data:

\begin{verbatim}
omniadmin.users
ldap.security.credentials.0, ldap.security.credentials.1, ldap.security.credentials.2 ...
facebook.connect.app.secret
auth.token.shared.secret
auth.mac.shared.key
captcha.engine.recaptcha.key.private
amazon.secret.access.key
tunneling.servlet.shared.secret
microsoft.translator.client.secret
dl.store.s3.secret.key
auto.deploy.glassfish.jee.dm.passwd
\end{verbatim}

LCS also did not store properties that end in \texttt{.password},
besides the following non-sensitive properties:

\begin{verbatim}
portal.jaas.plain.password
portal.jaas.strict.password
login.create.account.allow.custom.password
\end{verbatim}

LCS also allowed you to prevent it from analyzing specific properties of
your choosing, by defining blacklisted properties.

LCS is no longer gathering or storing the data listed above, that was
associated with enabled services.

\chapter{Managing LCS Users in Your
Project}\label{managing-lcs-users-in-your-project}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

The Users section of LCS is where you manage the LCS users that are part
of your project. It's here that you can grant or revoke LCS Roles. To
manage users, first click the \emph{Users} tab just below the Dashboard
tab on the upper-left of your screen.

\noindent\hrulefill

\textbf{Note:} You can't add users to your project via the LCS UI or the
LCS client app. To add users to your project, you must contact Liferay
support.

\noindent\hrulefill

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-users.png}}
\caption{The Users tab lets you manage the LCS users in your project.}
\end{figure}

The \emph{Users} tab displays a list of the users in your project. This
list includes each user's name, email, image, LCS Roles, and a
\emph{Manage Roles} button. Each LCS user must have an assigned Role.
The following Roles are available:

\textbf{LCS Administrator:} All LCS functionality is available to
administrators. This is the only Role that can manage other users'
Roles.

\textbf{LCS Environment Manager:} All LCS functionality is available in
the scope of an environment, with the exception of managing other users.

\textbf{LCS Environment Viewer:} Has read-only access in the scope of an
environment.

You should note that each of these LCS Roles assume users already have
the LCS User Role in their Liferay.com accounts. The LCS User Role is
granted automatically the first time a user logs into LCS. The actions
that can be performed by each of the LCS Roles are detailed in the below
permissions matrix.

\textbf{LCS Permissions Matrix}

Action \textbar{} ~LCS Administrator \textbar{} ~LCS Environment Manager
\textbar{} ~LCS Environment Viewer \textbar{} Access LCS \textbar{} true
\textbar{} true \textbar{} true \textbar{} Access Any Environment
\textbar{} true \textbar{} false \textbar{} false \textbar{} Access a
Particular Environment \textbar{} true \textbar{} true \textbar{} true
\textbar{} Manage Users \textbar{} true \textbar{} false \textbar{}
false \textbar{} Create and Delete Environments \textbar{} true
\textbar{} false \textbar{} false \textbar{} Edit Any Environment
\textbar{} true \textbar{} false \textbar{} false \textbar{} Edit a
Particular Environment \textbar{} true \textbar{} true \textbar{} false
\textbar{} Server Registration in Any Environment \textbar{} true
\textbar{} false \textbar{} false \textbar{} Server Registration in a
Particular Environment \textbar{} true \textbar{} true \textbar{} false
\textbar{} Install Fix Packs in Any Environment \textbar{} true
\textbar{} false \textbar{} false \textbar{} Install Fix Packs in a
Particular Environment \textbar{} true \textbar{} true \textbar{} false
\textbar{}

Now that you know what Roles are available in an LCS project and what
they do, you're ready to learn how to manage them.

\section{Managing LCS Roles}\label{managing-lcs-roles}

Follow these steps to manage a user's LCS Roles:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click the user's \emph{Manage Roles} button.
\item
  To revoke a Role, click \emph{Revoke Role} for that Role.
\item
  To assign a Role, choose the Role (and environment, if applicable) and
  click \emph{Assign}.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} A user can't have an environment Role (e.g., LCS
Environment Manager, LCS Environment Viewer) and the LCS Administrator
Role at the same time.

\noindent\hrulefill

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-user-roles.png}}
\caption{You can assign or revoke a user's LCS Roles.}
\end{figure}

\chapter{Using the Dashboard}\label{using-the-dashboard}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

The LCS Dashboard shows a project's environments and servers. If you're
not already at the Dashboard, click it near the upper left-hand corner
of your LCS site. Clicking \emph{Dashboard} takes you to the project
view. From there, you can get to the environment view and the server
view. Each of these views gives you a different look into certain
aspects of your LCS project. You'll start with the project view.

\section{Using the Project View}\label{using-the-project-view}

You can get to the project view at any time by clicking the
\emph{Dashboard} tab near the upper left-hand corner of your LCS site.
The project appears to the right of this tab, with a drop-down arrow for
switching between projects if you have more than one. You can also
switch between projects from the user menu at the top right of the
Dockbar. The project view contains a Status table that lists status
messages for each server in your project. For example, a status message
appears for a server when the server is offline. Status messages also
appear for servers when fix packs are available, monitoring is
unavailable, the patching tool is unavailable, or other events occur
that relate to LCS.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-project-view.png}}
\caption{The LCS project view shows an overview of your LCS project.}
\end{figure}

LCS lists the environments in your project on the left side of the
screen. You can also create new environments here by clicking the
\emph{Add Environment} tab (more on this shortly). To view an
environment's settings, click the environment's gear icon. Clicking an
environment shows more information about it. This takes you to the
environment view. Also note that each environment's icon indicates the
environment's type and status:

\textbf{Red icon:} There's a problem with one or more of the
environment's servers.

\textbf{Green icon:} The environment's servers are operating properly.

\textbf{Icon with a circle:} The environment's servers are clustered.

\chapter{Managing LCS Environments}\label{managing-lcs-environments}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

Environments are the key components of your LCS project. When you
register a server in LCS, you do so in an environment. An environment is
therefore the gateway to managing and monitoring your servers in LCS.

\section{Creating Environments}\label{creating-environments}

The first time you log in to LCS, a wizard walks you through each step
required to create your project's first environment. The
\href{/docs/7-2/deploy/-/knowledge_base/d/getting-started-with-lcs}{getting
started article} explains this in detail. You can create additional
environments via the same wizard or a simple form.

To create an environment, click the \emph{Add Environment} button from
the Dashboard. This opens the New Environment form. Each section in this
form corresponds to a step in the wizard. If you want to use the wizard
instead, click the \emph{Open Wizard} link at the top of the form. See
the
\href{/docs/7-2/deploy/-/knowledge_base/d/getting-started-with-lcs}{getting
started article} for a description of each setting in the form and
wizard.

\noindent\hrulefill

\textbf{Note:} When creating an environment, make your selections
carefully for the \emph{Subscription Type}, \emph{Cluster}, and
\emph{Elastic} fields. You can't change them after creating the
environment.

\noindent\hrulefill

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-new-environment.png}}
\caption{The New Environment form lets you create environments.}
\end{figure}

\section{Working with Environments}\label{working-with-environments}

Clicking an environment on the left-hand side of the Dashboard takes you
to the environment view, which lets you manage an environment in your
LCS project.

The UI is segmented into three tabs:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Fix Packs:} View and apply fix packs for the environment's
  servers. This tab only appears if a server is registered in the
  environment. A table displays the following information for each fix
  pack:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Name:} The fix pack's name.
  \item
    \textbf{Status:} The fix pack's status.
  \item
    \textbf{Server:} The server the fix pack can be applied to.
  \item
    \textbf{Size:} The fix pack's size. This only appears if the server
    is running.
  \item
    \textbf{Download:} A button to download the fix pack to the server.
    This only appears if the server is running.
  \end{itemize}

  Once a fix pack downloads, LCS prompts you to restart your server,
  which installs any downloaded fix packs. Note that you must start your
  server with the privileges required to write to the disk location
  where patches are stored and processed (the \texttt{patching-tool}
  folder). To use LCS to install fix packs across a cluster, follow the
  same procedure. LCS downloads and installs fix packs simultaneously
  across all nodes---you don't have to handle each separately.
\item
  \textbf{Registration:} Generate and download
  \href{/docs/7-2/deploy/-/knowledge_base/d/understanding-environment-tokens}{\emph{environment
  tokens}} that connect your servers to LCS.
\item
  \textbf{Environment Settings:} Change the environment's name,
  location, and description. You can also see if the environment allows
  clustered servers and view the environment's subscription type. Click
  the \emph{Save} button to save any changes you make in the Environment
  Settings tab. You can also delete the environment by clicking
  \emph{Delete Environment}.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-environment-view.png}}
\caption{The LCS environment view shows an overview of an LCS
environment.}
\end{figure}

\chapter{Managing LCS Servers}\label{managing-lcs-servers}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

Clicking a server in the Dashboard or environment view takes you to the
server view. Server view provides detailed information about a server.
To protect your users' privacy, LCS doesn't gather, store, or analyze
user data.

Server view is segmented into six tabs:

\textbf{Page Analytics:} This service has been disabled, if you enabled
it earlier you can see here the past history for metrics on page views
and load times.

\textbf{Snapshot Metrics:} This service has been disabled, if you
enabled it earlier you can see here the past history for application,
JVM, and server metrics.

\textbf{Fix Packs:} This service has been disabled, if you enabled it
earlier you can see here the past history for the server's available and
installed fix packs.

\textbf{Portal Properties:} This service has been disabled, if you
enabled it earlier you can see here the past history for your portal's
properties and their settings.

\textbf{Details:} Displays general information about your Liferay DXP
installation, Java version, and hardware.

\textbf{Server Settings:} View or change your server's name, location,
and description. You can also unregister the server from LCS.

\noindent\hrulefill

\textbf{Note:} LCS only supported Snapshot Metrics for servers running
on Tomcat or WebLogic. On other application servers you may see a
console message indicating that LCS doesn't support server metrics for
your application server. You may also see a benign
\texttt{NullPointerException} for the LCS
\texttt{TaskSchedulerServiceImpl} and \texttt{ScheduleTasksCommand}.

\noindent\hrulefill

\section{Details}\label{details}

The \emph{Details} tab shows general information about your server.
There are three tabs under Details: \emph{Software}, \emph{Java}, and
\emph{Hardware}. Each shows information, respectively, about your
Liferay DXP installation, Java installation, and hardware. This
information is useful to the Liferay Support team in the event you need
their assistance.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-details.png}}
\caption{The Details tab shows information about your server.}
\end{figure}

\section{Server Settings}\label{server-settings}

Finally, the \emph{Server Settings} tab lets you view and edit your
server's name, location, and description. You can also unregister your
server from LCS.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-settings.png}}
\caption{You can use the Server Settings tab to give your server a fun
name.}
\end{figure}

\section{Page Analytics}\label{page-analytics}

Page Analytics appears by default when you enter server view. Page
Analytics shows page views and load times for the selected site and time
period. By default, all sites are selected. You can select a specific
site from the \emph{Site} selector menu. You can also select a different
time period in the \emph{Period} and \emph{Ending At} fields. The arrows
next to the \emph{Ending At} field move the selected time period up or
down, respectively, by one period. For example, if you select \emph{One
Hour} in the \emph{Period} field, pressing the right arrow next to
\emph{Ending At} moves the selected time period up by one hour. Note
that at the beginning of the current time period, it can take up to 15
minutes for data to become available. Also note that data is available
for three months from the time LCS collected it.

By default, load times and page views for all pages are plotted against
time in separate graphs. Below these graphs, a table displays summary
statistics of data over the same time period, for each page. If you
click a page in the table, the graphs plot the data for just that page.
If you can't find the page you're looking for, you can search for it in
the \emph{Search} box at the top of the table. To plot data for all
pages again, click the \emph{All Pages} row at the bottom of the table.

Load times are also color coded to indicate speed. The \emph{Load Times}
graph's background is red for values above 3,000 ms, orange for values
from 2,000 to 3,000 ms, and green for values less than 2,000 ms.
Likewise, the table displays all load times greater than 3,000 ms in red
text.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-page-analytics-01.png}}
\caption{The Page Analytics interface in the LCS Server view.}
\end{figure}

\section{Snapshot Metrics}\label{snapshot-metrics}

To view other metrics and statistics of your server's performance, click
the \emph{Snapshot Metrics} tab near the top of the page. These metrics
are broken down into three main categories: \emph{Application},
\emph{JVM}, and \emph{Server}. Application is selected by default when
you click the Snapshot Metrics button.

The Application category also has three other categories: \emph{Pages},
\emph{Portlets}, and \emph{Cache}. Pages lists the frequency that
specific pages load, along with their average load times. Portlets lists
the same statistics, but for specific portlets in your server. The Cache
category lists Liferay Single VM metrics and Hibernate metrics. The
following screenshot shows the statistics in the Portlets category.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-metrics-application-portlets.png}}
\caption{The LCS application metrics show portlet performance
statistics, like frequency of use and average load time.}
\end{figure}

The JVM category, as its name indicates, shows statistics about the JVM
running on your server. This includes data on the garbage collector and
memory. The number of runs, total time, and average time are listed for
each garbage collector item. The memory metrics are presented in a bar
chart that shows the usage of the PS Eden Space, Code Cache, Compressed
Class Space, PS Old Gen, PS Survivor Space, and Metaspace.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-metrics-jvm.png}}
\caption{The LCS JVM metrics show performance data for memory and the
garbage collector.}
\end{figure}

Server is the third category in Snapshot Metrics. The Server category
shows additional information about how your server is running. For
example, horizontal bar graphs show the number of current threads
running on your server, as well as the JDBC connection pools.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-metrics-server.png}}
\caption{The LCS server metrics show current threads and JDBC connection
pools.}
\end{figure}

Note that in Snapshot Metrics, the application and garbage collector
metrics are based on data collected by LCS from server registration to
the present. Memory and server metrics, however, show only the current
state.

\section{Fix Packs}\label{fix-packs-1}

To view your server's fix packs, click the Fix Packs tab near the top of
the page. The available and installed fix packs appear in separate
tables. The available fix packs table functions exactly like the Fix
Packs table in environment view for downloading and installing fix
packs.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-fix-packs.png}}
\caption{The Fix Packs tab displays your server's available and
installed fix packs.}
\end{figure}

\section{Portal Properties}\label{portal-properties}

The \emph{Portal Properties} tab lets you view your portal's property
values in a searchable table. This gives you a convenient display for
your portal property settings. The properties in this table are
organized into the following categories:

\textbf{Default Values:} The default values for your portal's
properties.

\textbf{Custom Values:} Any custom values you've set for your portal's
properties. This includes any property values you change via a
\texttt{portal-ext.properties} file.

\textbf{Dynamic Properties:} Any property values set at runtime. For
example, the
\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
folder's location depends on your configuration. To specify this folder
when setting any properties that require it, use
\texttt{\$\{liferay.home\}} instead of an absolute directory path.

You can display any combination of these categories by selecting the
corresponding checkboxes from the gear icon next to the search box at
the top-right of the table. For example, by checking the \emph{Show
Default Values} and \emph{Show Custom Values} checkboxes, the table
shows your portal's default and custom property values. To show only the
custom values, select only \emph{Show Custom Values}.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-server-portal-properties.png}}
\caption{Click the gear icon to select the type of portal properties to
show in the table.}
\end{figure}

\chapter{Managing Your LCS Account}\label{managing-your-lcs-account}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

To manage your LCS account, select \emph{My Account} from the user menu
in the Dockbar. This takes you to a UI with four tabs:

\textbf{Projects:} Displays your LCS projects in a searchable table that
lists the administrator's email address for each project.

\textbf{Email Notifications:} Configure LCS to send you emails when
specific events occur in your LCS projects by adding rules that define
what events trigger a notification. There are no rules by default. Click
the \emph{Add Rule} button to define one.

First specify the project, environment, and server for the notification.
Note that you have the option of selecting all environments and servers
in a project. Then check the checkbox for each event that you want to
trigger an email notification. For example, if you create a notification
rule with \emph{The server unexpectedly shuts down} selected for all
servers and environments in your project, then LCS sends you an email if
any server in your project goes offline without a normal shut down
event. Click \emph{Save} when you're done defining the notification
rule. It then appears in a table along with other existing rules. Each
has Edit and Delete Action buttons.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-add-notification-rule.png}}
\caption{You can add rules to determine the events that trigger
notifications.}
\end{figure}

\textbf{Notification History:} Displays your web notification history in
a searchable table. You can also select the date range from which to
display notifications.

\textbf{Preferences:} Manage your LCS account's preferences. You can
change your account's language, time zone, and default LCS project. Your
default LCS project is the one shown each time you log in to LCS.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-account-preferences.png}}
\caption{You can change your LCS account's general preferences.}
\end{figure}

\section{Using Web Notifications}\label{using-web-notifications}

LCS also displays web notifications under the bell icon in the Dockbar.
A red badge on this icon shows your unread notification count. LCS and
Liferay Support send these notifications. For example, LCS generates
notifications when a server shuts down or some other event requiring
your attention occurs. To mark a notification as read, click the small
\emph{x} icon next to it. To mark all notifications as read, click the
\emph{Mark All as Read} button. To mark notifications as unread again,
click the \emph{Undo} button that appears. To see your notification
history, click the \emph{Notifications History} button. You can also
access your notification history by selecting \emph{My Account} from the
user menu in the Dockbar.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-user-web-notifications.png}}
\caption{Web notifications let you know what's happening in your LCS
projects.}
\end{figure}

\chapter{Managing Liferay DXP
Subscriptions}\label{managing-liferay-dxp-subscriptions}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

LCS lets you use and view your Liferay DXP subscriptions. Recall that
when you
\href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-environments\#creating-environments}{create
an environment}, you assign its subscription type and choose whether LCS
activates servers that connect to that environment. If you use LCS for
activation, registering a server in that environment consumes an
activation key from the environment's subscription type. You can also
view your project's available activation keys and see how they're being
used.

Depending on your subscription agreement, LCS also lets you register
servers via \emph{elastic subscriptions}. Elastic subscriptions let you
register an unlimited number servers. This is invaluable in auto-scaling
environments, where servers are automatically created and destroyed in
response to load. Note that to use elastic subscriptions, you must set
the environment as elastic when you create it. Also note that LCS only
uses elastic subscriptions for servers that exceed the number that the
environment's subscription type allows. In other words, LCS uses the
environment's regular subscriptions before any elastic subscriptions.

You can access these features from the \emph{Subscriptions} tab on the
upper-left of the LCS site. This tab contains two other tabs:
\emph{Details} and \emph{Elastic Subscriptions}.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-subscriptions.png}}
\caption{LCS lets you view and manage your subscriptions.}
\end{figure}

There are four tables in the \emph{Details} tab:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Subscriptions:} Shows a list of the available subscriptions in
  your LCS project. For each subscription, this table shows the
  following information:

  \begin{itemize}
  \tightlist
  \item
    Subscription Type
  \item
    Start Date
  \item
    Expiration Date
  \item
    Support End Date
  \item
    Platform
  \item
    Product
  \item
    Processor Cores Allowed
  \item
    Activation Keys
  \item
    Used Activation Keys
  \end{itemize}

  Note that \emph{Processor Cores Allowed} shows the number of processor
  cores that the subscription allows for each server.
\item
  \textbf{Subscriptions Summary:} Shows how your subscriptions are
  currently used in your project. For each subscription type, this table
  shows the number of activation keys allowed, used, and available.
\item
  \textbf{Project Environments:} Shows your project's environments and
  their assigned subscription types. Each environment must have a
  subscription type.
\item
  \textbf{Project Servers:} Shows the environment and subscription type
  for each server in your LCS project.
\end{enumerate}

If any of the information in these tables is missing or incorrect,
contact Liferay Support.

\noindent\hrulefill

\textbf{Note:} If you don't use LCS for activating your servers, then
you can register as many servers as you want in LCS.

\noindent\hrulefill

\noindent\hrulefill

\textbf{Note:} If you try to activate a server that exceeds the number
of processor cores that your subscription allows per server, the
activation fails and the server is locked down. A console error also
indicates the server's core count. You can compare this with your
subscription's processor cores allowed in LCS's Subscriptions table. To
activate the server, you can either reduce the number of cores it uses
(e.g., by deploying to different server hardware, or reducing the number
of virtual processors in a VM or container), or contact Liferay Sales to
increase the number of processor cores that your subscription allows per
server.

\noindent\hrulefill

\section{Decommissioning Servers}\label{decommissioning-servers}

To decommission a server and free its activation key for reuse, select
the server's environment on the left and then select the server. In the
server's \emph{Server Settings} tab, select \emph{Unregister}. Also note
that when you shut down a server normally, its activation key is
immediately freed for reuse. If the server crashes or its shutdown is
forced (e.g., kill), its activation key is freed for reuse within six
minutes.

\section{Elastic Subscriptions}\label{elastic-subscriptions}

Elastic subscriptions let you register an unlimited number of servers.
This is crucial for auto-scaling environments where servers are created
and destroyed automatically. You can view data on your elastic servers
from the \emph{Subscriptions} tab's \emph{Elastic Subscriptions} tab.

\noindent\hrulefill

\textbf{Note:} To register elastic servers in an environment, that
environment must be set as elastic when it's created. For more
information, see the
\href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-environments\#creating-environments}{documentation
on creating environments}.

\noindent\hrulefill

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-elastic-subscriptions.png}}
\caption{The \emph{Elastic Subscriptions} tab shows details about your
project's elastic servers.}
\end{figure}

The \emph{Elastic Subscriptions} tab displays the number of elastic
servers online and the uptime details for each. A graph shows the number
of elastic servers online each day, while a table lists each elastic
server's start time, end time, and duration. The total duration for
servers is below the table. To download a report of the table's data,
click \emph{Download Report}. Also, you can use the \emph{Environment}
and \emph{Month} selectors above the graph to select the environment and
month to show data from, respectively. The data in both the graph and
the table reflect your selections here.

\chapter{Understanding Environment
Tokens}\label{understanding-environment-tokens}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

To register a server in an environment, you must use that environment's
token file. LCS Administrators and Environment Managers can generate and
distribute this file. It contains all the information the LCS client app
needs to register the server in the environment. When the server starts
up, it uses the token to connect to LCS. If you use LCS for activation,
the server automatically consumes an activation key from the
environment's subscription upon connection. This makes it possible to
activate servers automatically on startup with no interaction required.

\noindent\hrulefill

\textbf{Note:} For instructions on using and managing your environment
tokens, see the instructions on
\href{/docs/7-2/deploy/-/knowledge_base/d/activating-your-liferay-dxp-server-with-lcs}{registering
your server with LCS}.

\noindent\hrulefill

There are a few things to keep in mind when using environment tokens:

\begin{itemize}
\item
  Each environment can have only one token file. If you regenerate the
  token, servers using the old file are disconnected from LCS and can't
  reconnect until receiving the new file. If the server disconnects due
  to token regeneration and is running version 4.0.2 or later of the LCS
  client app, the server enters a 30-day grace period during which it
  functions normally. This gives the administrator time to use the new
  token file to reconnect to LCS. Servers running earlier versions of
  the LCS client app present users with an error page until the
  administrator reconnects with the new token.
\item
  Use caution when distributing the token file, as anyone can use it to
  connect to your environment (and consume an activation key in your
  subscription if you're using LCS for activation).
\item
  Minimal information (server name, location, etc\ldots) is used to
  register a server with LCS. You can change this information from
  \href{/docs/7-2/deploy/-/knowledge_base/d/managing-lcs-servers}{the
  server view in LCS} at any time.
\item
  Environment tokens connect using OAuth. Using an environment token
  overrides the OAuth authorization cycle. If LCS Administrators or
  Environment Managers have never registered servers in LCS, the first
  time they do so an OAuth authorization entry is created in LCS. If
  they've previously registered servers in LCS, their existing
  credentials are used when they create a token file.
\item
  If the credentials of the LCS user who generated the token become
  invalid, you must generate a new token and use it to reconnect to LCS.
  An LCS user's credentials become invalid if the user leaves the LCS
  project or becomes an LCS Environment Manager or LCS Environment
  Viewer in a different environment.
\end{itemize}

So why bother with environment tokens at all? Besides simplifying the
LCS connection process, environment tokens are valuable in auto-scaling
environments where algorithms create and destroy servers automatically.
In this situation, having clients that activate and configure themselves
is crucial.

\noindent\hrulefill

\textbf{Note}: If your auto-scaling environment creates new server nodes
from a server in a system image, that server can't require human
interaction during setup. When creating such an image, you must change
any portal property settings that prevent automatic setup. By default,
Liferay DXP's setup wizard requires human interaction. You must
therefore set the \texttt{setup.wizard.enabled} property to
\texttt{false} if you want your auto-scaling environment to create new
nodes from the server.

\chapter{Troubleshooting Your LCS
Connection}\label{troubleshooting-your-lcs-connection}

\noindent\hrulefill

\textbf{Note:} LCS is deprecated and will be shut down on December 31,
2021. Customers who activate LCS are advised to replace it with our
latest activation key type which is suitable for virtualized
environments.

For further information, please see
\href{https://help.liferay.com/hc/en-us/articles/4402347960845-Changes-to-Liferay-Product-Activation}{Changes
to Liferay Product Activation}.

\noindent\hrulefill

If you use LCS to activate Liferay DXP, your server must maintain its
connection to LCS at all times. If this connection is interrupted, your
server enters a grace period to allow for reconnection. Lengthy
interruptions, however, can affect your server's uptime.

\noindent\hrulefill

\textbf{Note:} You must use LCS for activation of Elastic subscriptions.
Otherwise, you don't have to use LCS for activation. You can instead
request an XML activation key from Liferay Support.

\noindent\hrulefill

The following sections in this document provide some background
information and help you troubleshoot problems with your server's LCS
connection:

\hyperref[lcs-grace-periods]{\textbf{LCS Grace Periods:}} Describes how
grace periods work in LCS. You should read this section before
attempting any troubleshooting steps.

\hyperref[troubleshooting]{\textbf{Troubleshooting:}} Presents
troubleshooting steps for specific problems.

\hyperref[increasing-log-levels]{\textbf{Increasing Log Levels:}} If you
contact Liferay Support, you'll be asked to increase your server's log
levels and then provide your log files. This section shows you how to do
this.

\noindent\hrulefill

\textbf{Note:} The odds of LCS being unavailable are low. LCS is
deployed on a global cloud infrastructure set up for automatic failure
recovery. Notifications also let the LCS team react quickly to any
downtime. During LCS updates and new version releases, however, LCS is
unavailable for a few minutes while changes are applied.

\noindent\hrulefill

\section{LCS Grace Periods}\label{lcs-grace-periods}

There are 2 grace period types in LCS:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Connection Grace Period:} Occurs when your activated LCS
  connection is interrupted. This gives you time to re-establish the
  connection.
\item
  \textbf{Subscription Grace Period:} Occurs when your subscription is
  about to expire. This gives you time to renew the subscription.
\end{enumerate}

\noindent\hrulefill

\textbf{Note:} These grace periods only apply to servers previously
connected and activated in LCS. If the subscription check or connection
fails when a server attempts to connect to LCS for the first time, that
server doesn't enter a grace period. It's therefore important to verify
that an active subscription is available before connecting a new server
to LCS. To do this, check the
\href{/docs/7-2/deploy/-/knowledge_base/d/managing-liferay-dxp-subscriptions}{Subscriptions
tab} in LCS.

\noindent\hrulefill

\section{Connection Grace Period}\label{connection-grace-period}

If your server's LCS connection is interrupted, the server continues to
run and enters a grace period that lasts for up to 30 days to allow for
reconnection. During this grace period, Liferay DXP displays a warning
message to administrators. Upon seeing this message, administrators
should contact Liferay Support and follow the troubleshooting steps
below. LCS automatically restores your server's activation upon
reconnection (you shouldn't need to restart the server). If for some
reason the connection can't be restored, Liferay Support will provide an
alternative way to activate your server.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-grace-period.png}}
\caption{A warning message is displayed to administrators if the server
can't connect to LCS to validate the subscription.}
\end{figure}

While disconnected from LCS, the LCS client app continually attempts to
reconnect. If reconnection continues to fail, ensure that your server
can access \texttt{lcs.liferay.com} and
\texttt{lcs-gateway.liferay.com}. If the LCS client app stops attempting
to reconnect, there will be no activity in the logs. In this case, you
can force reconnection by redeploying the app. Follow these steps to do
so:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In your server's
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder (usually the parent folder of the application server's folder),
  remove this file:

\begin{verbatim}
osgi/marketplace/Liferay Connected Services Client.lpkg
\end{verbatim}
\item
  Place \texttt{Liferay\ Connected\ Services\ Client.lpkg} in
  \texttt{{[}Liferay\ Home{]}/deploy}. If you
  \href{/docs/7-2/deploy/-/knowledge_base/d/lcs-preconfiguration\#preconfiguring-lcs-to-connect-through-a-proxy}{connect
  to LCS through a proxy}, and configured this inside the LCS client
  app, make sure the app you deploy is also configured to do so.
\end{enumerate}

You should also ensure that you've enabled email notifications in LCS
for server disconnection events. To do this, you must create a
notification rule that sends an email whenever the server shuts down
unexpectedly. The documentation on
\href{/docs/7-2/deploy/-/knowledge_base/d/managing-your-lcs-account}{managing
your LCS account} explains how to do this.

\section{Subscription Grace Period}\label{subscription-grace-period}

At least 90 days before the subscription expires, Liferay will reach out
to begin the renewal process. 30 days before expiration, Liferay Support
sends warning messages through the Help Center,
\href{https://lcs.liferay.com}{the LCS site}, and
\href{https://www.liferay.com/group/customer}{the Customer Portal}.
After the expiration date, your servers may be placed in an additional
grace period, which is communicated through the same support channels.
If the renewal isn't completed during this grace period, then the
subscription becomes inactive and the Liferay DXP instance enters the
30-day grace period. As soon as the renewal is processed, the instance
activates and any error or warning messages disappear within 24 hours.
Note that by using XML activation keys (provided by Liferay Support upon
request), you can continue to use your Liferay DXP instances even after
a subscription has expired.

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/lcs-support-expiration.png}}
\caption{LCS sends you a notification prior to the expiration of your
subscription.}
\end{figure}

\section{Troubleshooting}\label{troubleshooting}

If you encounter issues with LCS, the Liferay Support team is here to
help. If you need support, open a
\href{https://help.liferay.com/hc}{Help Center} ticket. You can begin
troubleshooting the following scenarios, which the Liferay Support team
can also assist you with.

\noindent\hrulefill

\textbf{Note:} Before troubleshooting specific issues or contacting
Liferay Support, make sure that you've followed the LCS
\href{/docs/7-2/deploy/-/knowledge_base/d/lcs-preconfiguration}{preconfiguration}
and
\href{/docs/7-2/deploy/-/knowledge_base/d/activating-your-liferay-dxp-server-with-lcs}{registration}
steps correctly.

\noindent\hrulefill

\section{Server Can't Reach LCS}\label{server-cant-reach-lcs}

If your server can't reach LCS, verify that you can access the public
sites required by LCS:

\begin{itemize}
\item
  \href{https://lcs.liferay.com/}{\texttt{lcs.liferay.com}} should be
  viewable in a browser.
\item
  \texttt{lcs-gateway.liferay.com} should respond on port 443:

\begin{verbatim}
curl -vk -I "https://lcs-gateway.liferay.com"
telnet lcs-gateway.liferay.com 443
\end{verbatim}
\end{itemize}

\section{Subscription Issues}\label{subscription-issues}

For issues related to your subscription, first review the documentation
on
\href{/docs/7-2/deploy/-/knowledge_base/d/managing-liferay-dxp-subscriptions}{managing
your subscription}. Subscription errors usually involve one of these
problems:

\begin{itemize}
\tightlist
\item
  Your server can reach LCS, but can't locate a subscription.
\item
  Your server can reach LCS and locate a subscription, but activating
  your server would exceed the subscription's number of activation keys
  or cores.
\end{itemize}

In either case, you must verify that a subscription is available and
that you're not exceeding its number of activation keys or cores. You
can find this information on the LCS site's Subscriptions page, as
described in
\href{/docs/7-2/deploy/-/knowledge_base/d/managing-liferay-dxp-subscriptions}{the
documentation on managing subscriptions}. If the environment in which
you're trying to activate a server isn't assigned the subscription you
want to use, then you must create a new environment and assign it the
correct subscription. Once assigned, you can't change an environment's
subscription. Follow
\href{/docs/7-2/deploy/-/knowledge_base/d/activating-your-liferay-dxp-server-with-lcs}{the
initial registration steps} for instructions on creating a new
environment and activating a new server.

\noindent\hrulefill

\textbf{Note:} When shutting down servers, you must ensure that the LCS
site receives the server shutdown commands. Otherwise, LCS may not
release that server's activation key for reuse and attempts to activate
additional servers may exceed the subscription's number of activation
keys. There's a higher likelihood of this happening in rolling
deployments and/or when using containers. For more information, see the
\href{https://help.liferay.com/hc/en-us/articles/360018261011}{KB
article on properly unregistering subscriptions}.

\noindent\hrulefill

\section{Invalid Token}\label{invalid-token}

If the token is invalid, first review the documentation on
\href{/docs/7-2/deploy/-/knowledge_base/d/understanding-environment-tokens}{environment
tokens}. The following table lists causes and solutions for invalid
tokens.

\noindent\hrulefill

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4400}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5600}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
~Cause
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
~Solution
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
The LCS user who generated the token no longer has permissions. This
happens when the user leaves the LCS project or becomes an LCS
Environment Manager or LCS Environment Viewer in a different
environment. & Regenerate the token. \\
The token's file name is changed after download. & Download the token
again from LCS. \\
The token is regenerated. & Use the regenerated token. \\
\end{longtable}

\noindent\hrulefill

\section{Increasing Log Levels}\label{increasing-log-levels}

If you contact Liferay Support, you're asked to increase your server's
log levels and then provide your log files. You can find these log files
in \texttt{{[}Liferay\ Home{]}/logs}
(\href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
is usually the parent folder of the application server's folder). There
are 2 types of log files in this folder:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Liferay log files:} The files \texttt{liferay.{[}date{]}.log}
  and \texttt{liferay.{[}date{]}.xml} are the logs for your Liferay DXP
  installation. Note that LOG and XML files for the same date contain
  the same information--the only difference is the file format.
\item
  \textbf{LCS log files:} The \texttt{lcs-portlet-{[}date{]}.log} files
  are the LCS client app's logs. Note that if there's only a single LCS
  log file, it may appear without a date as \texttt{lcs-portlet.log}.
  When you increase the log levels as described in the following
  sections, the additional log messages are written to these LCS log
  files.
\end{enumerate}

There are 2 ways to increase the log levels:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{In your Liferay DXP instance's Control Panel:} This is a
  temporary configuration that resets upon shutting down the server.
  Note that if the server isn't activated, you can't access the Control
  Panel. In that case, Liferay Support can provide an XML activation
  key.
\item
  \textbf{In a Log4j configuration:} This is a permanent configuration
  that persists through server shutdown and restart.
\end{enumerate}

The following sections cover both options.

\section{Control Panel}\label{control-panel}

Follow these steps to increase the log levels via the Control Panel:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Navigate to \emph{Control Panel} → \emph{Configuration} → \emph{Server
  Administration}.
\item
  Click the \emph{Log Levels} tab.
\item
  Search for ``lcs''.
\item
  Change the log level for each matching entry to DEBUG.
\item
  While in the Control Panel, you should also navigate to
  \emph{Configuration} → \emph{Liferay Connected Services} and take a
  screenshot of what you see there. This is useful to Liferay Support.
\end{enumerate}

\section{Log4j}\label{log4j}

Follow these steps to increase the log levels via Log4j:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Download the latest LCS client as instructed in the
  \href{/docs/7-2/deploy/-/knowledge_base/d/lcs-preconfiguration}{LCS
  preconfiguration article}. The app downloads as
  \texttt{Liferay\ Connected\ Services\ Client.lpkg}. If you don't want
  to download the latest client, you can use the one already installed
  in your server: it's in \texttt{{[}Liferay\ Home{]}/osgi/marketplace}
  (just make sure to shut down your server before following the rest of
  the steps in this section). Recall that the
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder is usually the parent folder of the application server's
  folder.
\item
  Expand the LPKG file, then expand the
  \texttt{lcs-portlet-{[}version{]}.war} file inside it.
\item
  Inside the \texttt{WAR} file, replace the contents of
  \texttt{WEB-INF\textbackslash{}classes\textbackslash{}META-INF\textbackslash{}portal-log4j.xml}
  with the following configuration:

\begin{verbatim}
<?xml version="1.0"?>
<!DOCTYPE log4j:configuration SYSTEM "log4j.dtd">

<log4j:configuration xmlns:log4j="http://jakarta.apache.org/log4j/">
        <appender class="org.apache.log4j.rolling.RollingFileAppender" name="RollingFileAppender">
                <rollingPolicy class="org.apache.log4j.rolling.TimeBasedRollingPolicy">
                        <param name="ActiveFileName" value="@liferay.home@/logs/lcs-portlet.log" />
                        <param name="FileNamePattern" value="@liferay.home@/logs/lcs-portlet.%d{yyyy-MM-dd}.log.zip" />
                </rollingPolicy>

                <layout class="org.apache.log4j.EnhancedPatternLayout">
                        <param name="ConversionPattern" value="%d{yyyy/MM/dd HH\:mm\:ss} %-5p [%t][%c{1}:%L] %m%n" />
                </layout>
        </appender>

        <category name="com.liferay.lcs.task.scheduler">
                <priority value="ALL" />
        </category>

        <logger additivity="false" name="com.liferay.lcs">
                <level value="ALL" />
                <appender-ref ref="RollingFileAppender" />
        </logger>
</log4j:configuration>
\end{verbatim}
\item
  Save the file and repackage the WAR and LPKG (make sure not to change
  the names of these files).
\item
  Make sure your server is shut down.
\item
  In your installation's
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder, delete the existing LCS client app:

\begin{verbatim}
osgi/marketplace/Liferay Connected Services Client.lpkg
\end{verbatim}
\item
  Place the \texttt{Liferay\ Connected\ Services\ Client.lpkg} that you
  repackaged in step 4 in \texttt{osgi/marketplace}.
\item
  Start your server.
\end{enumerate}

If you need assistance with the issues in this guide, or any other
issues with LCS, contact Liferay Support.

\chapter{Deployment Reference}\label{deployment-reference}

Here you'll find definitions, default settings, templates, and more.
Here are some of the topics:

\begin{itemize}
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}:
  From this location, Liferay DXP launches applications, applies
  configurations, loads JAR files, and generates logs.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{Portal
  properties}: Use a \texttt{portal-ext.properties} file (or another
  qualified properties file) to configure Liferay DXP and override
  features.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/system-properties}{System
  properties}: Examine Liferay DXP default system configuration.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/database-templates}{Database
  templates}: Use these portal properties templates to specify the
  Liferay DXP database.
\item
  \href{/docs/7-2/deploy/-/knowledge_base/d/elasticsearch-connector-settings-reference}{Elasticsearch
  settings}: Examine the configuration settings for Liferay's default
  Elasticsearch adapter.
\end{itemize}

\chapter{Liferay Home}\label{liferay-home}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

\emph{Liferay Home} is the location from which Liferay DXP launches
applications, applies configurations, loads JAR files, and generates
logs.

\begin{itemize}
\item
  \emph{In a Liferay DXP bundle,} Liferay Home is the installation's
  top-level folder and it contains the application server.
\item
  \emph{In a manual installation,} the Liferay Home folder varies by
  application server. If you're doing a manual installation, please
  refer to the article covering that app server (e.g., \emph{Installing
  Liferay DXP on {[}app server{]}}) for the Liferay Home location.
\end{itemize}

Bundles contain this folder structure regardless of application server:

\begin{itemize}
\tightlist
\item
  \textbf{\hyperref[liferay-home]{Liferay Home}}

  \begin{itemize}
  \item
    \textbf{{[}Application Server{]}}: This folder is named after the
    application server where Liferay DXP is installed.
  \item
    \texttt{data} (if HSQL database is selected): Stores an embedded
    HSQL database, Liferay DXP's file repository, and search indexes.
    The embedded HSQL database is configured by default, but it's
    intended for demonstration and trial purposes only. The
    \href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#JDBC}{Portal
    property \texttt{jdbc.default.url}} sets the Hypersonic embedded
    HSQL database location.
  \item
    \texttt{deploy}: To auto-deploy plugins, copy them to this folder.
    It supports application \texttt{.lpkg} files from Liferay
    Marketplace, plugin \texttt{.war} files, and plugin \texttt{.jar}
    files. The
    \href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Auto\%20Deploy}{Portal
    property \texttt{auto.deploy.deploy.dir}} sets the auto-deploy
    location.
  \item
    \texttt{license}: Liferay DXP's copyright and version files are
    here.
  \item
    \texttt{logs}: Log files go here. Examine them as you diagnose
    problems. \texttt{portal-impl.jar}'s
    \texttt{portal-impl/src/META-INF/portal-log4j.xml} file sets the log
    file location. To override the log file location, you must
    \href{/docs/7-0/tutorials/-/knowledge_base/t/advanced-customization-with-ext-plugins\#using-advanced-configuration-files}{use
    an \texttt{ext-impl/src/META-INF/portal-log4j-ext.xml} file in an
    Ext plugin}.
  \item
    \texttt{osgi}: All the JAR files and a few configuration files for
    the OSGi runtime belong in this folder. The
    \href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Module\%20Framework}{Portal
    property \texttt{module.framework.base.dir}} sets the OSGi folder
    location. Here are its subfolders:

    \begin{itemize}
    \tightlist
    \item
      \texttt{configs}: Component configuration files.
    \item
      \texttt{core}: Liferay DXP's core modules.
    \item
      \texttt{marketplace}: Marketplace applications and application
      suites.
    \item
      \texttt{modules}: Modules you've deployed.
    \item
      \texttt{portal}: Liferay DXP's non-core modules.
    \item
      \texttt{state}: Contains OSGi internal state files for such things
      as OSGi bundle installation, bundle storage, and more.
    \item
      \texttt{target-platform}: Target platform index.
    \item
      \texttt{test}: Modules that support test integration.
    \item
      \texttt{war}: WAR plugins you've deployed.
    \end{itemize}
  \item
    \texttt{patching-tool}: (Liferay DXP only) This folder contains
    patches and a utility for installing the patches.
  \item
    \texttt{tools}: For Liferay DXP upgrade and target platform indexer.
  \item
    \texttt{work}: Module Jasper work files.
  \end{itemize}
\end{itemize}

\noindent\hrulefill

\textbf{Note:} If Liferay DXP cannot create resources in the Liferay
Home folder or if it finds itself running on certain application
servers, it creates a folder called \texttt{liferay} in the home folder
of the operating system user that is running Liferay DXP. In this case,
that \texttt{liferay} folder becomes Liferay Home. For example, if the
operating system user's name is jbloggs, the \texttt{liferay} folder
path is \texttt{/home/jbloggs/liferay} or
\texttt{C:\textbackslash{}Users\textbackslash{}jbloggs\textbackslash{}liferay}.

\chapter{Portal Properties}\label{portal-properties-1}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

You can set portal properties to configure and override Liferay DXP
features. Your installation's \texttt{portal-impl.jar} embeds the
default properties file:

{ portal.properties { (Opens New Window)} }

Overriding a portal property requires creating an \emph{extension}
portal properties file that specifies the properties you're overriding.

\noindent\hrulefill

\textbf{Note:} In a portal properties extension file, specify only the
properties you're overriding.

\noindent\hrulefill

Here's an example of setting Portal's data source to a MySQL database by
adding override properties in a
\texttt{{[}Liferay\ Home{]}/portal-ext.properties} file:

\begin{verbatim}
jdbc.default.driverClassName=com.mysql.cj.jdbc.Driver
jdbc.default.url=jdbc:mysql://localhost/lportal?characterEncoding=UTF-8&dontTrackOpenResources=true&holdResultsOpenOverStatementClose=true&serverTimezone=GMT&useFastDateParsing=false&useUnicode=true
jdbc.default.username=jbloggs
jdbc.default.password=pass123
\end{verbatim}

The
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#Properties\%20Override}{\texttt{include-and-override}}
property specifies portal property files that override the defaults. It
specifies the order the files are read---the last file read takes
highest priority.

Properties file prioritization (highest to lowest):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{{[}Liferay\ Home{]}/portal-setup-wizard.properties}
\item
  \texttt{{[}user\ home{]}/portal-setup-wizard.properties}
\item
  \texttt{{[}Liferay\ Home{]}/portal-ext.properties}
\item
  \texttt{{[}user\ home{]}/portal-ext.properties}
\item
  \texttt{{[}Liferay\ Home{]}/portal-bundle.properties}
\item
  \texttt{{[}user\ home{]}/portal-bundle.properties}
\item
  \texttt{{[}Liferay\ Home{]}/portal.properties}
\item
  \texttt{portal-impl.jar/portal.properties}
\end{enumerate}

\texttt{{[}Liferay\ Home{]}/portal-ext.properties} is the most commonly
used file for overriding the defaults.

\chapter{System Properties}\label{system-properties}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

System properties configure the Liferay DXP system. Your installation's
\texttt{portal-impl.jar} embeds the default properties file:

{ system.properties { (Opens New Window)} }

\chapter{Database Templates}\label{database-templates}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Below are templates (example
\href{/docs/7-2/deploy/-/knowledge_base/d/portal-properties}{portal
properties}) for configuring various databases as a built-in data source
for Liferay DXP.

\noindent\hrulefill

\textbf{Note:} The
\href{https://web.liferay.com/documents/14/21598941/Liferay+DXP+7.2+Compatibility+Matrix/b6e0f064-db31-49b4-8317-a29d1d76abf7?}{Liferay
DXP Compatibility Matrix} specifies supported databases and
environments.

\noindent\hrulefill

\section{MariaDB}\label{mariadb-2}

\begin{verbatim}
jdbc.default.driverClassName=org.mariadb.jdbc.Driver
jdbc.default.url=jdbc:mariadb://localhost/lportal?useUnicode=true&characterEncoding=UTF-8&useFastDateParsing=false
jdbc.default.username=
jdbc.default.password=
\end{verbatim}

\section{MySQL}\label{mysql-2}

\noindent\hrulefill

\textbf{Note:} MySQL Connector/J 8.0 is highly recommended for use with
MySQL Server 8.0 and 5.7.

\noindent\hrulefill

\begin{verbatim}
jdbc.default.driverClassName=com.mysql.cj.jdbc.Driver
jdbc.default.url=jdbc:mysql://localhost/lportal?characterEncoding=UTF-8&dontTrackOpenResources=true&holdResultsOpenOverStatementClose=true&serverTimezone=GMT&useFastDateParsing=false&useUnicode=true
jdbc.default.username=
jdbc.default.password=
\end{verbatim}

\section{PostgreSQL}\label{postgresql-2}

\begin{verbatim}
jdbc.default.driverClassName=org.postgresql.Driver
jdbc.default.url=jdbc:postgresql://localhost:5432/lportal
jdbc.default.username=sa
jdbc.default.password
\end{verbatim}

See the
\href{@platform-ref@/7.2-latest/propertiesdoc/portal.properties.html\#JDBC}{default
portal properties} for more database templates.

\chapter{Comparing Patch Levels}\label{comparing-patch-levels}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

If you're a developer, the Patching Tool can show you what changed
between different Liferay DXP patches and versions. These commands show
you information about the different patch levels:

\texttt{patching-tool\ diff}: Prints the differences between two patch
levels. At least one stored patch level must be available. This command
accepts options for filtering the output:

\begin{itemize}
\tightlist
\item
  \texttt{source}: Shows the source differences between the two patch
  levels.
\item
  \texttt{files}: Shows a list of the modified files.
\item
  \texttt{fixed-issues}: Shows a list of LPS/LPE issues from our issue
  tracking system.
\item
  \texttt{html}: Specify this along with one of the filtering options
  (\texttt{source}, \texttt{files}, or \texttt{fixed-issues}) and after
  the patch levels, to write the differences to an HTML file
  (\texttt{\textless{}stored-name-1\textgreater{}-\textless{}stored-name-2\textgreater{}-{[}type{]}-diff.html})
  in the \texttt{diffs} folder. Additions are colored green and
  deletions are colored red.
\item
  \texttt{collisions}: Shows a list of modified files which collide with
  deployed plugins.
\end{itemize}

For detailed usage information, run \texttt{patching-tool\ help\ diff}.

\texttt{patching-tool\ store}: Manages patching level information for
the \texttt{diff} command. Your patches must contain source code to
store the patch level and to prepare usable information for the
\texttt{diff} command. Here are the \texttt{store} command options:

\begin{itemize}
\tightlist
\item
  \texttt{info}: Prints the list of patches which make up the stored
  patch level.
\item
  \texttt{add}: Stores the patch level that can be found in the patches
  directory.
\item
  \texttt{update}: Adds or updates patch level information.
\item
  \texttt{rm}: Removes previously stored patch level information.
\end{itemize}

For detailed usage information, run \texttt{patching-tool\ help\ store}.

\chapter{Patching Tool Configuration
Properties}\label{patching-tool-configuration-properties}

{This document has been updated and ported to Liferay Learn and is no
longer maintained here.}

Here are the Patching Tool configuration properties. See
\href{/docs/7-2/deploy/-/knowledge_base/d/configuring-the-patching-tool}{Configuring
the Patching Tool} for more information on configuring the Patching
Tool.

\textbf{patching.mode:} This can be \texttt{binary} (the default) or
\texttt{source} if you're patching a source tree. Patches contain both
binary and source patches. If your development team extends Liferay DXP,
have them patch their source tree.

\textbf{patches.folder:} Specify where to store patches. The default
location is \texttt{./patches}.

\textbf{war.path:} Specify the location of the Liferay DXP installation
inside your application server. Alternatively, you can specify a
\texttt{.war} file here, and you can patch a Liferay DXP \texttt{.war}
for installation to your application server.

\textbf{global.lib.path:} Specify the location for storing \texttt{.jar}
files on the global classpath. If you're not sure, search for
\texttt{portal-kernel.jar}; it's on the global classpath. This property
is only valid if your \texttt{patching.mode} is \texttt{binary}.

\textbf{liferay.home:} Specify the default location for the
\texttt{data}, \texttt{osgi}, and \texttt{tools} folders.

\textbf{source.path:} Specify the location of your Liferay DXP source
tree. This property is only valid if your \texttt{patching.mode} is
\texttt{source}.

Service Pack detection is available behind a proxy server. To configure
your proxy, use the following settings, making sure to replace
\texttt{{[}PROXY\_IP\_ADDRESS{]}} with your proxy server's IP address
and replace the port numbers with yours:

\begin{verbatim}
## Proxy settings

# HTTP Proxy

#proxy.http.host=[PROXY_IP_ADDRESS]
#proxy.http.port=80
#proxy.http.user=user
#proxy.http.password=password

# HTTPS Proxy

proxy.https.host=[PROXY_IP_ADDRESS]
proxy.https.port=80
proxy.https.user=user
proxy.https.password=password

# SOCKS Proxy

#proxy.socks.host=[PROXY_IP_ADDRESS]
#proxy.socks.port=1080
#proxy.socks.user=user
#proxy.socks.password=password
\end{verbatim}

\chapter{Troubleshooting Deployments}\label{troubleshooting-deployments}

When coding on any platform, you can sometimes run into issues that have
no clear resolution. This can be particularly frustrating. If you have
issues building, deploying, or running apps and modules, you want to
resolve them fast. These frequently asked questions and answers help you
troubleshoot and correct problems.

Click a question to view the answer.

{Why did the entity sort order change when I migrated to a new database
type?~{}}

\begin{verbatim}
<p><a href="/docs/7-2/deploy/-/knowledge_base/d/sort-order-changed-with-a-different-database">Your new database uses a different default query result order--you should be able to configure a different order</a>.</p>
\end{verbatim}

{How can I use files to configure components?~{}}

\begin{verbatim}
<p>See <a href="/docs/7-2/deploy/-/knowledge_base/d/using-files-to-configure-product-modules">Using Files to Configure Module Components</a>. </p>
\end{verbatim}

{The application server and database started, but Liferay DXP failed to
connect to the database. What happened and how can I fix this?~{}}

\begin{verbatim}
<p>Liferay DXP initialization can fail while attempting to connect to a database server that isn't ready. <a href="/docs/7-2/deploy/-/knowledge_base/d/portal-failed-to-initialize-because-the-database-wasnt-ready">Configuring startup to retry JDBC connections</a> facilitates connecting @product@ to databases. </p>
\end{verbatim}

\chapter{Liferay DXP Failed to Initialize Because the Database Wasn't
Ready}\label{liferay-dxp-failed-to-initialize-because-the-database-wasnt-ready}

If you start your database server and application server at the same
time, Liferay DXP might try connecting to the data source before the
database is ready. By default, Liferay DXP doesn't retry connecting to
the database; it just fails. But there is a way to avoid this situation:
database connection retries.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a \texttt{portal-ext.properties} file in your
  \href{/docs/7-1/deploy/-/knowledge_base/d/liferay-home}{Liferay Home}
  folder.
\item
  Set the property \texttt{retry.jdbc.on.startup.max.retries} equal to
  the number of times to retry connecting to the data source.
\item
  Set property \texttt{retry.jdbc.on.startup.delay} equal to the number
  of seconds to wait before retrying connection.
\end{enumerate}

If at first the connection doesn't succeed, Liferay DXP uses the retry
settings to try again.

\section{Related Topics}\label{related-topics-10}

\href{/docs/7-2/appdev/-/knowledge_base/a/connecting-to-data-sources-using-jndi}{Connecting
to JNDI Data Sources}

\chapter{Sort Order Changed with a Different
Database}\label{sort-order-changed-with-a-different-database}

If you've been using Liferay DXP, but are switching it to use a
different database type, consult your database vendor documentation to
understand your old and new database's default query result order. The
default order is either case-sensitive or case-insensitive. This affects
entity sort order in Liferay DXP.

Here are some examples of ascending alphabetical sort order.

Case-sensitive:

\begin{verbatim}
111
222
AAA
BBB
aaa
bbb
\end{verbatim}

Case-insensitive:

\begin{verbatim}
111
222
AAA
aaa
BBB
bbb
\end{verbatim}

Your new database's default query result order might differ from your
current database's order.

Consult your vendor's documentation to configure the order the way you
want.

\chapter{Using Files to Configure Module
Components}\label{using-files-to-configure-module-components}

Liferay DXP uses
\href{http://felix.apache.org/documentation/subprojects/apache-felix-file-install.html}{Felix
File Install} to monitor file system folders for new/updated
configuration files, and the \href{http://felix.apache.org/}{Felix OSGi
implementation} of
\href{http://felix.apache.org/documentation/subprojects/apache-felix-config-admin.html}{Configuration
Admin} to let you use files to configure module service components.

To learn how to work with configuration files, first review
\href{/docs/7-1/user/-/knowledge_base/u/understanding-system-configuration-files}{Understanding
System Configuration Files}.

\section{Configuration File Formats}\label{configuration-file-formats}

There are two different configuration file formats:

\begin{itemize}
\tightlist
\item
  \texttt{.cfg}: An older, simple format that only supports
  \texttt{String} values as properties.
\item
  \texttt{.config}: A format that supports strings, type information,
  and other non-string values in its properties.
\end{itemize}

Although Liferay DXP supports both formats, use \texttt{.config} files
for their flexibility and ability to use type information. Since
\texttt{.cfg} files lack type information, if you want to store anything
but a \texttt{String}, you must use properties utility classes to cast
\texttt{String}s to intended types (and you must carefully document
properties that aren't \texttt{String}s). \texttt{.config} files
eliminate this need by allowing type information. The articles below
explain the file formats:

\begin{itemize}
\tightlist
\item
  \href{/docs/7-1/user/-/knowledge_base/u/understanding-system-configuration-files}{Understanding
  System Configuration Files}
\item
  \href{https://sling.apache.org/documentation/bundles/configuration-installer-factory.html\#configuration-files-config}{Configuration
  file (\texttt{.config}) syntax}
\item
  \href{https://sling.apache.org/documentation/bundles/configuration-installer-factory.html\#property-files-cfg}{Properties
  file(\texttt{.cfg}) syntax}
\end{itemize}

\section{Naming Configuration Files}\label{naming-configuration-files}

Before you
\href{/docs/7-1/user/-/knowledge_base/u/creating-configuration-files}{create
a configuration file}, follow these steps to determine whether multiple
instances of the component can be created or if the component is
intended to be a singleton:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Deploy the component's module if you haven't done so already.
\item
  In Liferay DXP's UI, go to \emph{Control Panel} → \emph{Configuration}
  → \emph{System Settings}.
\item
  Find the component's settings by searching or browsing for the
  component.
\item
  If the component's settings page has a section called
  \emph{Configuration Entries}, you can create multiple instances of the
  component configured however you like. Otherwise, you should treat the
  component as a singleton.
\end{enumerate}

\begin{figure}
\centering
\pandocbounded{\includegraphics[keepaspectratio]{./images/system-settings-page-lists-configuration-entries.png}}
\caption{You can create multiple instances of components whose System
Settings page has a \emph{Configuration Entries} section.}
\end{figure}

\emph{All} configuration file names must start with the component's PID
(PID stands for \emph{persistent identity}) and end with
\texttt{.config} or \texttt{.cfg}.

For example, this class uses
\href{/docs/7-2/frameworks/-/knowledge_base/f/declarative-services}{Declarative
Services} to define a component:

\begin{verbatim}
package com;
@Component
class Foo {}
\end{verbatim}

The component's PID is \texttt{com.Foo}. All the component's
configuration files must start with the PID \texttt{com.Foo}.

For each non-singleton component instance you want to create or update
with a configuration, you must use a uniquely named configuration file
that starts with the component's PID and ends with \texttt{.config} or
\texttt{.cfg}. Creating configurations for multiple component instances
requires that the configuration files use different \emph{subnames}. A
subname is the part of a configuration file name after the PID and
before the suffix \texttt{.config} or \texttt{.cfg}. Here's the
configuration file name pattern for non-singleton components:

\begin{itemize}
\tightlist
\item
  \texttt{{[}PID{]}-{[}subname1{]}.config}
\item
  \texttt{{[}PID{]}-{[}subname2{]}.config}
\item
  etc.
\end{itemize}

For example, you could configure two different instances of the
component \texttt{com.Foo} by using configuration files with these
names:

\begin{itemize}
\tightlist
\item
  \texttt{com.Foo-one.config}
\item
  \texttt{com.Foo-two.config}
\end{itemize}

Each configuration file creates and/or updates an instance of the
component that matches the PID. The subname is arbitrary---it doesn't
have to match a specific component instance. This means you can use
whatever subname you like. For example, these configuration files are
just as valid as the two above:

\begin{itemize}
\tightlist
\item
  \texttt{com.Foo-puppies.config}
\item
  \texttt{com.Foo-kitties.config}
\end{itemize}

Using the subname \texttt{default}, however, is Liferay DXP's convention
for configuring a component's first instance. The file name pattern is
therefore

\begin{verbatim}
[PID]-default.config
\end{verbatim}

A singleton component's configuration file must also start with
\texttt{{[}PID{]}} and end with \texttt{.config} or \texttt{.cfg}.
Here's the common pattern used for singleton component configuration
file names:

\begin{verbatim}
[PID].config
\end{verbatim}

When you're done creating a configuration file, you can
\href{/docs/7-1/user/-/knowledge_base/u/understanding-system-configuration-files\#deploying-a-configuration-file}{deploy
it}.

\section{Resolving Configuration File Deployment
Failures}\label{resolving-configuration-file-deployment-failures}

The following \texttt{IOException} hints that the configuration file has
a syntax issue:

\begin{verbatim}
Failed to install artifact: [path to .config or .cfg file]
java.io.IOException: Unexpected token 78; expected: 61 (line=0, pos=107)
\end{verbatim}

To resolve this, fix the
\hyperref[configuration-file-formats]{configuration file's syntax}.

Great! Now you know how to configure module components using
configuration files.

\section{Related Articles}\label{related-articles}

\href{/docs/7-1/user/-/knowledge_base/u/understanding-system-configuration-files}{Understanding
System Configuration Files}
